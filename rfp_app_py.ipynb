{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP5iYSfDaZmgY1TmPsq9Qrr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TeneikaAskew/taap/blob/main/rfp_app_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 1: Install Dependencies"
      ],
      "metadata": {
        "id": "OHUpg3Kc5gDM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Colab Setup Script for RFP Proposal Intelligence Platform\n",
        "# Run this in Google Colab to set up the complete environment\n",
        "\n",
        "# ===== STEP 1: Install Dependencies =====\n",
        "print(\"Installing required packages...\")\n",
        "\n",
        "!pip install -q streamlit\n",
        "!pip install -q sentence-transformers\n",
        "!pip install -q faiss-cpu\n",
        "!pip install -q PyPDF2\n",
        "!pip install -q python-docx\n",
        "!pip install -q plotly\n",
        "!pip install -q pyngrok\n",
        "\n",
        "print(\"✅ Packages installed successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1B_-FjIt7pK",
        "outputId": "b7f5cd3b-b473-4d51-e1d2-4b1fcb170497"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing required packages...\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m128.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m120.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h✅ Packages installed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 2: Mount Google Drive"
      ],
      "metadata": {
        "id": "q416yY8g5dMf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== STEP 2: Mount Google Drive =====\n",
        "print(\"\\nMounting Google Drive...\")\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "try:\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"✅ Google Drive mounted successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error mounting drive: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9a5-nS5t-ft",
        "outputId": "79fd81e7-d9bc-4d47-fa24-9e614ab335fc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Mounting Google Drive...\n",
            "Mounted at /content/drive\n",
            "✅ Google Drive mounted successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nCreating directory structure...\")\n",
        "\n",
        "base_path = \"/content/drive/Shared drives/Leadership/rfp app\"\n",
        "rfps_path = os.path.join(base_path, \"RFP\")\n",
        "responses_path = os.path.join(base_path, \"Responses\")\n",
        "\n",
        "os.makedirs(base_path, exist_ok=True)\n",
        "os.makedirs(rfps_path, exist_ok=True)\n",
        "os.makedirs(responses_path, exist_ok=True)\n",
        "\n",
        "print(f\"✅ Directories created:\")\n",
        "print(f\"   📁 {base_path}\")\n",
        "print(f\"   📁 {rfps_path}\")\n",
        "print(f\"   📁 {responses_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTMhCFwFuA9W",
        "outputId": "09e51e17-3b5b-4850-cc5c-c7457a035733"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Creating directory structure...\n",
            "✅ Directories created:\n",
            "   📁 /content/drive/Shared drives/Leadership/rfp app\n",
            "   📁 /content/drive/Shared drives/Leadership/rfp app/RFP\n",
            "   📁 /content/drive/Shared drives/Leadership/rfp app/Responses\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 4: Create Sample Documents (Optional)"
      ],
      "metadata": {
        "id": "WmL_gyCD5ZIS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== STEP 4: Create Sample Documents (Optional) =====\n",
        "print(\"\\nCreating sample documents...\")\n",
        "\n",
        "# Sample RFP content\n",
        "sample_rfp_content = \"\"\"\n",
        "REQUEST FOR PROPOSAL\n",
        "IT MODERNIZATION SERVICES\n",
        "\n",
        "Solicitation Number: RFP-2024-IT-001\n",
        "Agency: Department of Homeland Security (DHS)\n",
        "Due Date: August 15, 2024\n",
        "NAICS Code: 541512\n",
        "\n",
        "STATEMENT OF WORK:\n",
        "The Department of Homeland Security requires comprehensive IT modernization services including:\n",
        "1. Cloud migration services for legacy systems\n",
        "2. Cybersecurity assessment and implementation\n",
        "3. System integration and data migration\n",
        "4. 24/7 technical support and maintenance\n",
        "\n",
        "REQUIREMENTS:\n",
        "- Contractor must have minimum 5 years of federal IT experience\n",
        "- Must maintain FedRAMP compliance throughout contract period\n",
        "- Shall provide dedicated project manager with PMP certification\n",
        "- Must complete security clearance requirements for key personnel\n",
        "\n",
        "EVALUATION CRITERIA:\n",
        "- Technical Approach (40 points)\n",
        "- Past Performance (30 points)\n",
        "- Management Plan (20 points)\n",
        "- Cost Proposal (10 points)\n",
        "\n",
        "CONTRACT VALUE: $2,500,000\n",
        "CONTRACT PERIOD: 18 months with option for 12-month extension\n",
        "\"\"\"\n",
        "\n",
        "# Sample Response content\n",
        "sample_response_content = \"\"\"\n",
        "TECHNICAL PROPOSAL\n",
        "IT MODERNIZATION SERVICES\n",
        "Submitted by: A3 Consulting LLC\n",
        "\n",
        "EXECUTIVE SUMMARY:\n",
        "A3 Consulting LLC is pleased to submit this proposal for IT Modernization Services.\n",
        "Our team brings over 15 years of federal IT experience, having successfully completed\n",
        "25+ cloud migration projects for federal agencies.\n",
        "\n",
        "TECHNICAL APPROACH:\n",
        "Our proven methodology includes:\n",
        "1. Comprehensive Assessment Phase\n",
        "   - Current state analysis\n",
        "   - Risk assessment\n",
        "   - Security evaluation\n",
        "\n",
        "2. Migration Planning Phase\n",
        "   - Detailed migration strategy\n",
        "   - Timeline development\n",
        "   - Resource allocation\n",
        "\n",
        "3. Implementation Phase\n",
        "   - Phased migration approach\n",
        "   - Continuous testing\n",
        "   - Quality assurance\n",
        "\n",
        "4. Support and Maintenance\n",
        "   - 24/7 monitoring\n",
        "   - Regular updates\n",
        "   - Performance optimization\n",
        "\n",
        "PAST PERFORMANCE:\n",
        "Project 1: DHS Cloud Migration (2023)\n",
        "- Migrated 12 legacy systems to AWS GovCloud\n",
        "- Completed 2 months ahead of schedule\n",
        "- Achieved 99.9% uptime\n",
        "\n",
        "Project 2: VA Cybersecurity Implementation (2022)\n",
        "- Implemented comprehensive security framework\n",
        "- Achieved FedRAMP certification\n",
        "- Zero security incidents during implementation\n",
        "\n",
        "MANAGEMENT PLAN:\n",
        "Our dedicated project team includes:\n",
        "- Project Manager: Jane Smith, PMP, 10 years federal experience\n",
        "- Technical Lead: John Doe, CISSP, 8 years cloud experience\n",
        "- Security Specialist: Mike Johnson, CISM, 12 years cybersecurity\n",
        "\n",
        "CERTIFICATIONS:\n",
        "- ISO 9001 Quality Management\n",
        "- FedRAMP Authorized\n",
        "- CMMI Level 3\n",
        "\"\"\"\n",
        "\n",
        "# Write sample files\n",
        "sample_rfp_path = os.path.join(rfps_path, \"DHS_IT_Modernization_RFP.txt\")\n",
        "sample_response_path = os.path.join(responses_path, \"A3_IT_Modernization_Response.txt\")\n",
        "\n",
        "with open(sample_rfp_path, 'w') as f:\n",
        "    f.write(sample_rfp_content)\n",
        "\n",
        "with open(sample_response_path, 'w') as f:\n",
        "    f.write(sample_response_content)\n",
        "\n",
        "print(f\"✅ Sample documents created:\")\n",
        "print(f\"   📄 {sample_rfp_path}\")\n",
        "print(f\"   📄 {sample_response_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81NiZvftuMv-",
        "outputId": "c7b027e3-09da-49ff-9ddc-2461c9b1acc3"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Creating sample documents...\n",
            "✅ Sample documents created:\n",
            "   📄 /content/drive/Shared drives/Leadership/rfp app/RFP/DHS_IT_Modernization_RFP.txt\n",
            "   📄 /content/drive/Shared drives/Leadership/rfp app/Responses/A3_IT_Modernization_Response.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 5: Create the Main Application File"
      ],
      "metadata": {
        "id": "DTzKcowT5U1A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== STEP 5: Create the Main Application File =====\n",
        "print(\"\\nCreating main application file...\")\n",
        "\n",
        "app_content = '''\n",
        "# RFP Proposal Intelligence Platform - Main Application\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import json\n",
        "from datetime import datetime, timedelta\n",
        "import re\n",
        "from typing import List, Dict, Any, Optional\n",
        "import logging\n",
        "\n",
        "# Document processing\n",
        "try:\n",
        "    import PyPDF2\n",
        "    import docx\n",
        "except ImportError:\n",
        "    st.error(\"Please install: !pip install PyPDF2 python-docx\")\n",
        "\n",
        "# ML components\n",
        "try:\n",
        "    from sentence_transformers import SentenceTransformer\n",
        "    import faiss\n",
        "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "except ImportError:\n",
        "    st.error(\"Please install: !pip install sentence-transformers faiss-cpu scikit-learn\")\n",
        "\n",
        "# Visualization\n",
        "try:\n",
        "    import plotly.express as px\n",
        "    import plotly.graph_objects as go\n",
        "except ImportError:\n",
        "    st.error(\"Please install: !pip install plotly\")\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class RFPPlatform:\n",
        "    def __init__(self, drive_path=\"/content/drive/Shared drives/Leadership/rfp app\"):\n",
        "        self.drive_path = drive_path\n",
        "        self.rfps_path = os.path.join(drive_path, \"rfps\")\n",
        "        self.responses_path = os.path.join(drive_path, \"responses\")\n",
        "\n",
        "        try:\n",
        "            self.embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "            self.vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
        "        except Exception as e:\n",
        "            st.warning(f\"AI components not loaded: {e}\")\n",
        "            self.embedder = None\n",
        "            self.vectorizer = None\n",
        "\n",
        "        self.rfp_data = []\n",
        "        self.response_data = []\n",
        "        self.embeddings = None\n",
        "        self.index = None\n",
        "\n",
        "        self.company_profile = {\n",
        "            \"name\": \"A3 Consulting LLC\",\n",
        "            \"naics_codes\": [\"541511\", \"541512\", \"541519\", \"541611\"],\n",
        "            \"capabilities\": [\n",
        "                \"Management Consulting\", \"IT Consulting\", \"Strategic Planning\",\n",
        "                \"Process Improvement\", \"Data Analytics\", \"Project Management\",\n",
        "                \"Cybersecurity Consulting\", \"Digital Transformation\"\n",
        "            ],\n",
        "            \"certifications\": [\"ISO 9001\", \"CMMI Level 3\", \"FedRAMP\"],\n",
        "            \"socioeconomic\": [\"Small Business\"],\n",
        "            \"past_performance_keywords\": [\n",
        "                \"government consulting\", \"strategic planning\", \"process optimization\",\n",
        "                \"data analysis\", \"cloud migration\", \"cybersecurity\", \"IT modernization\"\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        self.setup_directories()\n",
        "\n",
        "    def setup_directories(self):\n",
        "        try:\n",
        "            os.makedirs(self.rfps_path, exist_ok=True)\n",
        "            os.makedirs(self.responses_path, exist_ok=True)\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error creating directories: {e}\")\n",
        "\n",
        "    def extract_text_from_pdf(self, file_path):\n",
        "        try:\n",
        "            with open(file_path, 'rb') as file:\n",
        "                pdf_reader = PyPDF2.PdfReader(file)\n",
        "                text = \"\"\n",
        "                for page in pdf_reader.pages:\n",
        "                    text += page.extract_text() + \"\\\\n\"\n",
        "                return text\n",
        "        except Exception as e:\n",
        "            return \"\"\n",
        "\n",
        "    def extract_text_from_docx(self, file_path):\n",
        "        try:\n",
        "            doc = docx.Document(file_path)\n",
        "            text = \"\"\n",
        "            for paragraph in doc.paragraphs:\n",
        "                text += paragraph.text + \"\\\\n\"\n",
        "            return text\n",
        "        except Exception as e:\n",
        "            return \"\"\n",
        "\n",
        "    def load_documents(self):\n",
        "        st.info(\"Loading documents...\")\n",
        "\n",
        "        if not os.path.exists(self.drive_path):\n",
        "            st.error(f\"Drive path not found: {self.drive_path}\")\n",
        "            return\n",
        "\n",
        "        # Load RFPs\n",
        "        rfp_files = []\n",
        "        if os.path.exists(self.rfps_path):\n",
        "            rfp_files = [f for f in os.listdir(self.rfps_path)\n",
        "                        if f.endswith(('.pdf', '.docx', '.txt'))]\n",
        "\n",
        "        # Load responses\n",
        "        response_files = []\n",
        "        if os.path.exists(self.responses_path):\n",
        "            response_files = [f for f in os.listdir(self.responses_path)\n",
        "                             if f.endswith(('.pdf', '.docx', '.txt'))]\n",
        "\n",
        "        # Process RFPs\n",
        "        self.rfp_data = []\n",
        "        for file in rfp_files:\n",
        "            try:\n",
        "                file_path = os.path.join(self.rfps_path, file)\n",
        "\n",
        "                if file.endswith('.pdf'):\n",
        "                    text = self.extract_text_from_pdf(file_path)\n",
        "                elif file.endswith('.docx'):\n",
        "                    text = self.extract_text_from_docx(file_path)\n",
        "                else:\n",
        "                    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                        text = f.read()\n",
        "\n",
        "                rfp_info = self.parse_rfp_metadata(text, file)\n",
        "                rfp_info['file_path'] = file_path\n",
        "                rfp_info['text'] = text\n",
        "                self.rfp_data.append(rfp_info)\n",
        "            except Exception as e:\n",
        "                st.warning(f\"Error processing {file}: {e}\")\n",
        "\n",
        "        # Process responses\n",
        "        self.response_data = []\n",
        "        for file in response_files:\n",
        "            try:\n",
        "                file_path = os.path.join(self.responses_path, file)\n",
        "\n",
        "                if file.endswith('.pdf'):\n",
        "                    text = self.extract_text_from_pdf(file_path)\n",
        "                elif file.endswith('.docx'):\n",
        "                    text = self.extract_text_from_docx(file_path)\n",
        "                else:\n",
        "                    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                        text = f.read()\n",
        "\n",
        "                response_info = {\n",
        "                    'filename': file,\n",
        "                    'text': text,\n",
        "                    'file_path': file_path,\n",
        "                    'date_created': datetime.now()\n",
        "                }\n",
        "                self.response_data.append(response_info)\n",
        "            except Exception as e:\n",
        "                st.warning(f\"Error processing {file}: {e}\")\n",
        "\n",
        "        st.success(f\"Loaded {len(self.rfp_data)} RFPs and {len(self.response_data)} responses\")\n",
        "\n",
        "    def parse_rfp_metadata(self, text, filename):\n",
        "        return {\n",
        "            'title': filename.replace('.pdf', '').replace('.docx', '').replace('.txt', ''),\n",
        "            'filename': filename,\n",
        "            'agency': self.extract_agency(text),\n",
        "            'due_date': self.extract_due_date(text),\n",
        "            'naics_codes': self.extract_naics_codes(text),\n",
        "            'contract_value': self.extract_contract_value(text),\n",
        "            'requirements': self.extract_requirements(text),\n",
        "            'evaluation_criteria': self.extract_evaluation_criteria(text),\n",
        "            'date_loaded': datetime.now()\n",
        "        }\n",
        "\n",
        "    def extract_agency(self, text):\n",
        "        agencies = ['DHS', 'DOD', 'GSA', 'VA', 'HHS', 'DOE', 'NASA', 'USDA',\n",
        "                   'Department of Homeland Security', 'General Services Administration']\n",
        "        text_upper = text.upper()\n",
        "        for agency in agencies:\n",
        "            if agency.upper() in text_upper:\n",
        "                if 'HOMELAND SECURITY' in agency.upper():\n",
        "                    return 'DHS'\n",
        "                elif 'GENERAL SERVICES' in agency.upper():\n",
        "                    return 'GSA'\n",
        "                else:\n",
        "                    return agency\n",
        "        return \"Unknown\"\n",
        "\n",
        "    def extract_due_date(self, text):\n",
        "        import re\n",
        "        date_patterns = [\n",
        "            r'\\\\b\\\\d{1,2}/\\\\d{1,2}/\\\\d{4}\\\\b',\n",
        "            r'\\\\b\\\\d{1,2}-\\\\d{1,2}-\\\\d{4}\\\\b',\n",
        "            r'\\\\b\\\\w+ \\\\d{1,2}, \\\\d{4}\\\\b'\n",
        "        ]\n",
        "\n",
        "        for pattern in date_patterns:\n",
        "            matches = re.findall(pattern, text)\n",
        "            if matches:\n",
        "                return matches[0]\n",
        "        return \"Not found\"\n",
        "\n",
        "    def extract_naics_codes(self, text):\n",
        "        import re\n",
        "        naics_pattern = r'\\\\b\\\\d{6}\\\\b'\n",
        "        codes = re.findall(naics_pattern, text)\n",
        "        return codes[:5]\n",
        "\n",
        "    def extract_contract_value(self, text):\n",
        "        import re\n",
        "        value_patterns = [\n",
        "            r'\\\\$[\\\\d,]+(?:\\\\.\\\\d{2})?',\n",
        "            r'[\\\\d,]+ dollars?'\n",
        "        ]\n",
        "\n",
        "        for pattern in value_patterns:\n",
        "            matches = re.findall(pattern, text, re.IGNORECASE)\n",
        "            if matches:\n",
        "                return matches[0]\n",
        "        return \"Not specified\"\n",
        "\n",
        "    def extract_requirements(self, text):\n",
        "        req_keywords = ['requirement', 'shall', 'must', 'mandatory', 'criteria']\n",
        "        sentences = text.split('.')\n",
        "        requirements = []\n",
        "\n",
        "        for sentence in sentences:\n",
        "            sentence_lower = sentence.lower()\n",
        "            if any(keyword in sentence_lower for keyword in req_keywords):\n",
        "                if len(sentence.strip()) > 20:\n",
        "                    requirements.append(sentence.strip())\n",
        "\n",
        "        return requirements[:10]\n",
        "\n",
        "    def extract_evaluation_criteria(self, text):\n",
        "        criteria_keywords = ['evaluation', 'scoring', 'points', 'weight', 'factor']\n",
        "        sentences = text.split('.')\n",
        "        criteria = []\n",
        "\n",
        "        for sentence in sentences:\n",
        "            sentence_lower = sentence.lower()\n",
        "            if any(keyword in sentence_lower for keyword in criteria_keywords):\n",
        "                if len(sentence.strip()) > 20:\n",
        "                    criteria.append(sentence.strip())\n",
        "\n",
        "        return criteria[:5]\n",
        "\n",
        "    def build_embeddings(self):\n",
        "        if not self.embedder or (not self.rfp_data and not self.response_data):\n",
        "            return\n",
        "\n",
        "        all_texts = []\n",
        "        for rfp in self.rfp_data:\n",
        "            all_texts.append(rfp['text'])\n",
        "        for response in self.response_data:\n",
        "            all_texts.append(response['text'])\n",
        "\n",
        "        if all_texts:\n",
        "            try:\n",
        "                self.embeddings = self.embedder.encode(all_texts)\n",
        "                dimension = self.embeddings.shape[1]\n",
        "                self.index = faiss.IndexFlatIP(dimension)\n",
        "                self.index.add(self.embeddings.astype('float32'))\n",
        "                st.success(f\"Built embeddings for {len(all_texts)} documents\")\n",
        "            except Exception as e:\n",
        "                st.error(f\"Error building embeddings: {e}\")\n",
        "\n",
        "    def calculate_opportunity_fit(self, rfp_info):\n",
        "        score = 0\n",
        "\n",
        "        # NAICS code match (30 points)\n",
        "        naics_match = any(code in self.company_profile['naics_codes']\n",
        "                         for code in rfp_info['naics_codes'])\n",
        "        if naics_match:\n",
        "            score += 30\n",
        "\n",
        "        # Capability keywords match (40 points)\n",
        "        text_lower = rfp_info['text'].lower()\n",
        "        capability_matches = sum(1 for cap in self.company_profile['capabilities']\n",
        "                               if cap.lower() in text_lower)\n",
        "        score += min(40, capability_matches * 8)\n",
        "\n",
        "        # Past performance keywords (30 points)\n",
        "        pp_matches = sum(1 for keyword in self.company_profile['past_performance_keywords']\n",
        "                        if keyword in text_lower)\n",
        "        score += min(30, pp_matches * 10)\n",
        "\n",
        "        return min(score, 100)\n",
        "\n",
        "    def generate_compliance_matrix(self, rfp_info):\n",
        "        requirements = rfp_info['requirements']\n",
        "        matrix = []\n",
        "\n",
        "        for i, req in enumerate(requirements):\n",
        "            compliant = any(cap.lower() in req.lower()\n",
        "                          for cap in self.company_profile['capabilities'])\n",
        "\n",
        "            matrix.append({\n",
        "                'requirement': req[:100] + \"...\" if len(req) > 100 else req,\n",
        "                'compliant': 'Yes' if compliant else 'Needs Review',\n",
        "                'response_section': f\"Section {i+1}\"\n",
        "            })\n",
        "\n",
        "        return matrix\n",
        "\n",
        "    def search_similar_responses(self, query, top_k=5):\n",
        "        if self.index is None or self.embedder is None:\n",
        "            return []\n",
        "\n",
        "        try:\n",
        "            query_embedding = self.embedder.encode([query])\n",
        "            scores, indices = self.index.search(query_embedding.astype('float32'), top_k)\n",
        "\n",
        "            results = []\n",
        "            for i, (score, idx) in enumerate(zip(scores[0], indices[0])):\n",
        "                if idx < len(self.rfp_data):\n",
        "                    doc_type = \"RFP\"\n",
        "                    doc = self.rfp_data[idx]\n",
        "                else:\n",
        "                    doc_type = \"Response\"\n",
        "                    doc = self.response_data[idx - len(self.rfp_data)]\n",
        "\n",
        "                results.append({\n",
        "                    'type': doc_type,\n",
        "                    'document': doc,\n",
        "                    'similarity_score': float(score),\n",
        "                    'rank': i + 1\n",
        "                })\n",
        "\n",
        "            return results\n",
        "        except Exception as e:\n",
        "            return []\n",
        "\n",
        "    def generate_proposal_outline(self, rfp_info):\n",
        "        outline = {\n",
        "            \"Executive Summary\": {\n",
        "                \"description\": \"Overview of our approach and key win themes\",\n",
        "                \"suggested_content\": \"Highlight A3's unique qualifications\"\n",
        "            },\n",
        "            \"Technical Approach\": {\n",
        "                \"description\": \"Detailed methodology and approach\",\n",
        "                \"suggested_content\": \"Address each technical requirement\"\n",
        "            },\n",
        "            \"Management Plan\": {\n",
        "                \"description\": \"Project management and organization\",\n",
        "                \"suggested_content\": \"Show project structure and timeline\"\n",
        "            },\n",
        "            \"Past Performance\": {\n",
        "                \"description\": \"Relevant experience and references\",\n",
        "                \"suggested_content\": \"Include similar projects\"\n",
        "            }\n",
        "        }\n",
        "\n",
        "        requirements = rfp_info['requirements']\n",
        "        custom_sections = []\n",
        "\n",
        "        for req in requirements:\n",
        "            if 'security' in req.lower():\n",
        "                custom_sections.append(\"Security Approach\")\n",
        "            elif 'quality' in req.lower():\n",
        "                custom_sections.append(\"Quality Assurance\")\n",
        "\n",
        "        for section in set(custom_sections):\n",
        "            outline[section] = {\n",
        "                \"description\": f\"Address {section.lower()} requirements\",\n",
        "                \"suggested_content\": f\"Detail our {section.lower()} approach\"\n",
        "            }\n",
        "\n",
        "        return outline\n",
        "\n",
        "    def analyze_win_loss_patterns(self):\n",
        "        return {\n",
        "            'overall_win_rate': 0.45,\n",
        "            'win_rate_by_agency': {'DHS': 0.6, 'GSA': 0.4, 'DOD': 0.5, 'VA': 0.3},\n",
        "            'avg_proposal_time': 25,\n",
        "            'success_factors': [\n",
        "                'Strong past performance alignment',\n",
        "                'Competitive pricing',\n",
        "                'Clear technical approach'\n",
        "            ],\n",
        "            'improvement_areas': [\n",
        "                'Faster response time',\n",
        "                'Better capture intelligence'\n",
        "            ]\n",
        "        }\n",
        "\n",
        "def create_sample_data():\n",
        "    sample_rfps = [\n",
        "        {\n",
        "            'title': 'IT_Modernization_Services',\n",
        "            'filename': 'DHS_IT_Modernization_RFP.txt',\n",
        "            'agency': 'DHS',\n",
        "            'due_date': '2024-08-15',\n",
        "            'naics_codes': ['541511', '541512'],\n",
        "            'contract_value': '$2,500,000',\n",
        "            'text': 'Department of Homeland Security requires IT modernization including cloud migration, cybersecurity assessment, and system integration.',\n",
        "            'requirements': [\n",
        "                'Must have federal cloud migration experience',\n",
        "                'Shall provide 24/7 technical support',\n",
        "                'Must maintain FedRAMP compliance'\n",
        "            ],\n",
        "            'evaluation_criteria': [\n",
        "                'Technical approach weighted 40%',\n",
        "                'Past performance weighted 30%'\n",
        "            ],\n",
        "            'date_loaded': datetime.now()\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    sample_responses = [\n",
        "        {\n",
        "            'filename': 'A3_IT_Modernization_Response.txt',\n",
        "            'text': 'A3 Consulting has extensive federal IT modernization experience with 15+ successful cloud migrations.',\n",
        "            'date_created': datetime.now()\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    return sample_rfps, sample_responses\n",
        "\n",
        "def setup_sample_environment():\n",
        "    st.info(\"Setting up sample environment...\")\n",
        "    sample_rfps, sample_responses = create_sample_data()\n",
        "\n",
        "    platform = RFPPlatform()\n",
        "    platform.rfp_data = sample_rfps\n",
        "    platform.response_data = sample_responses\n",
        "\n",
        "    try:\n",
        "        platform.build_embeddings()\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    st.session_state.platform = platform\n",
        "    st.success(\"Sample environment ready!\")\n",
        "    return platform\n",
        "\n",
        "def main():\n",
        "    st.set_page_config(\n",
        "        page_title=\"RFP Intelligence Platform\",\n",
        "        page_icon=\"📄\",\n",
        "        layout=\"wide\"\n",
        "    )\n",
        "\n",
        "    st.title(\"🚀 RFP Proposal Intelligence Platform\")\n",
        "    st.markdown(\"### AI-Powered Proposal Development for A3 Consulting LLC\")\n",
        "\n",
        "    if 'platform' not in st.session_state:\n",
        "        st.session_state.platform = RFPPlatform()\n",
        "\n",
        "    platform = st.session_state.platform\n",
        "\n",
        "    # Sidebar\n",
        "    st.sidebar.title(\"Navigation\")\n",
        "    page = st.sidebar.selectbox(\n",
        "        \"Choose a page:\",\n",
        "        [\"Setup & Data Loading\", \"Opportunity Dashboard\", \"RFP Analysis\",\n",
        "         \"Proposal Assistant\", \"Knowledge Search\", \"Analytics\"]\n",
        "    )\n",
        "\n",
        "    st.sidebar.markdown(\"---\")\n",
        "    st.sidebar.subheader(\"🧪 Demo Mode\")\n",
        "\n",
        "    if st.sidebar.button(\"Load Sample Data\"):\n",
        "        setup_sample_environment()\n",
        "\n",
        "    if st.sidebar.button(\"Reset\"):\n",
        "        for key in list(st.session_state.keys()):\n",
        "            del st.session_state[key]\n",
        "        st.rerun()\n",
        "\n",
        "    # Pages\n",
        "    if page == \"Setup & Data Loading\":\n",
        "        st.header(\"🔧 Setup & Data Loading\")\n",
        "\n",
        "        col1, col2 = st.columns(2)\n",
        "\n",
        "        with col1:\n",
        "            st.subheader(\"Google Drive Connection\")\n",
        "            drive_path = st.text_input(\"Drive Path\", \"/content/drive/Shared drives/Leadership/rfp app\")  # Use your actual path\n",
        "\n",
        "            if drive_path != platform.drive_path:\n",
        "                platform.drive_path = drive_path\n",
        "                platform.rfps_path = os.path.join(drive_path, \"rfps\")\n",
        "                platform.responses_path = os.path.join(drive_path, \"responses\")\n",
        "\n",
        "            if os.path.exists(drive_path):\n",
        "                st.success(\"✅ Drive path found\")\n",
        "            else:\n",
        "                st.error(\"❌ Drive path not found\")\n",
        "\n",
        "        with col2:\n",
        "            st.subheader(\"Data Loading\")\n",
        "            if st.button(\"Load Documents\", type=\"primary\"):\n",
        "                platform.load_documents()\n",
        "                platform.build_embeddings()\n",
        "\n",
        "            st.info(f\"\"\"\n",
        "            **Status:**\n",
        "            - RFPs: {len(platform.rfp_data)}\n",
        "            - Responses: {len(platform.response_data)}\n",
        "            - Embeddings: {'Yes' if platform.embeddings is not None else 'No'}\n",
        "            \"\"\")\n",
        "\n",
        "        st.subheader(\"📋 Company Profile\")\n",
        "        with st.expander(\"A3 Consulting Profile\"):\n",
        "            st.json(platform.company_profile)\n",
        "\n",
        "    elif page == \"Opportunity Dashboard\":\n",
        "        st.header(\"🎯 Opportunity Dashboard\")\n",
        "\n",
        "        if not platform.rfp_data:\n",
        "            st.warning(\"No RFPs loaded. Use Setup page or Sample Data.\")\n",
        "            return\n",
        "\n",
        "        # Filters\n",
        "        col1, col2, col3 = st.columns(3)\n",
        "        with col1:\n",
        "            agency_filter = st.selectbox(\"Agency\", [\"All\"] + list(set([rfp['agency'] for rfp in platform.rfp_data])))\n",
        "        with col2:\n",
        "            min_fit_score = st.slider(\"Min Fit Score\", 0, 100, 50)\n",
        "        with col3:\n",
        "            sort_by = st.selectbox(\"Sort by\", [\"Fit Score\", \"Date\", \"Agency\"])\n",
        "\n",
        "        # Filter and sort\n",
        "        rfp_opportunities = []\n",
        "        for rfp in platform.rfp_data:\n",
        "            fit_score = platform.calculate_opportunity_fit(rfp)\n",
        "            if fit_score >= min_fit_score:\n",
        "                if agency_filter == \"All\" or rfp['agency'] == agency_filter:\n",
        "                    rfp['fit_score'] = fit_score\n",
        "                    rfp_opportunities.append(rfp)\n",
        "\n",
        "        if sort_by == \"Fit Score\":\n",
        "            rfp_opportunities.sort(key=lambda x: x['fit_score'], reverse=True)\n",
        "\n",
        "        st.subheader(f\"📊 {len(rfp_opportunities)} Opportunities\")\n",
        "\n",
        "        for i, rfp in enumerate(rfp_opportunities):\n",
        "            with st.expander(f\"🎯 {rfp['title']} (Fit: {rfp['fit_score']}%)\"):\n",
        "                col1, col2 = st.columns(2)\n",
        "                with col1:\n",
        "                    st.write(f\"**Agency:** {rfp['agency']}\")\n",
        "                    st.write(f\"**Due Date:** {rfp['due_date']}\")\n",
        "                    st.write(f\"**Value:** {rfp['contract_value']}\")\n",
        "                with col2:\n",
        "                    st.metric(\"Fit Score\", f\"{rfp['fit_score']}%\")\n",
        "\n",
        "                if st.button(f\"Analyze\", key=f\"analyze_{i}\"):\n",
        "                    st.session_state.selected_rfp = rfp\n",
        "                    st.success(\"RFP selected!\")\n",
        "\n",
        "    elif page == \"RFP Analysis\":\n",
        "        st.header(\"🔍 RFP Analysis\")\n",
        "\n",
        "        if 'selected_rfp' not in st.session_state:\n",
        "            st.warning(\"Select an RFP from Dashboard first.\")\n",
        "            return\n",
        "\n",
        "        rfp = st.session_state.selected_rfp\n",
        "\n",
        "        st.subheader(f\"📄 {rfp['title']}\")\n",
        "\n",
        "        col1, col2, col3 = st.columns(3)\n",
        "        with col1:\n",
        "            st.metric(\"Fit Score\", f\"{rfp.get('fit_score', 'N/A')}%\")\n",
        "        with col2:\n",
        "            st.metric(\"Requirements\", len(rfp['requirements']))\n",
        "        with col3:\n",
        "            st.metric(\"Agency\", rfp['agency'])\n",
        "\n",
        "        # Requirements\n",
        "        st.subheader(\"📋 Requirements\")\n",
        "        if rfp['requirements']:\n",
        "            for req in rfp['requirements']:\n",
        "                st.write(f\"• {req}\")\n",
        "        else:\n",
        "            st.info(\"No requirements extracted.\")\n",
        "\n",
        "        # Compliance Matrix\n",
        "        st.subheader(\"✅ Compliance Matrix\")\n",
        "        compliance_matrix = platform.generate_compliance_matrix(rfp)\n",
        "        if compliance_matrix:\n",
        "            st.dataframe(pd.DataFrame(compliance_matrix))\n",
        "\n",
        "        # Q&A\n",
        "        st.subheader(\"❓ Q&A Assistant\")\n",
        "        question = st.text_input(\"Ask about this RFP:\")\n",
        "        if question and st.button(\"Answer\"):\n",
        "            sentences = rfp['text'].split('.')\n",
        "            relevant = [s.strip() for s in sentences\n",
        "                       if any(word in s.lower() for word in question.lower().split())]\n",
        "            if relevant:\n",
        "                st.success(\"**Relevant content:**\")\n",
        "                for sentence in relevant[:3]:\n",
        "                    st.write(f\"• {sentence}\")\n",
        "            else:\n",
        "                st.warning(\"No relevant content found.\")\n",
        "\n",
        "    elif page == \"Proposal Assistant\":\n",
        "        st.header(\"✍️ Proposal Assistant\")\n",
        "\n",
        "        if 'selected_rfp' not in st.session_state:\n",
        "            st.warning(\"Select an RFP first.\")\n",
        "            return\n",
        "\n",
        "        rfp = st.session_state.selected_rfp\n",
        "        st.subheader(f\"📝 Proposal for: {rfp['title']}\")\n",
        "\n",
        "        if st.button(\"Generate Outline\", type=\"primary\"):\n",
        "            outline = platform.generate_proposal_outline(rfp)\n",
        "            st.session_state.proposal_outline = outline\n",
        "\n",
        "        if 'proposal_outline' in st.session_state:\n",
        "            st.subheader(\"📋 Proposal Outline\")\n",
        "            outline = st.session_state.proposal_outline\n",
        "\n",
        "            for section, details in outline.items():\n",
        "                with st.expander(f\"📄 {section}\"):\n",
        "                    st.write(f\"**Description:** {details['description']}\")\n",
        "                    st.write(f\"**Content:** {details['suggested_content']}\")\n",
        "\n",
        "                    if st.button(f\"Generate Content\", key=f\"gen_{section}\"):\n",
        "                        sample_content = f\"\"\"\n",
        "**{section} - Draft Content:**\n",
        "\n",
        "This section addresses the {section.lower()} requirements. A3 Consulting brings\n",
        "extensive experience in delivering similar solutions for federal agencies.\n",
        "\n",
        "Key points:\n",
        "- Understanding of client needs\n",
        "- Proven methodology\n",
        "- Risk mitigation strategies\n",
        "- Quality assurance\n",
        "\n",
        "[AI-generated content would be more specific and tailored to RFP requirements]\n",
        "\"\"\"\n",
        "                        st.text_area(\"Generated Content:\", sample_content, height=200, key=f\"content_{section}\")\n",
        "\n",
        "        # Similar Responses\n",
        "        st.subheader(\"🔍 Find Similar Responses\")\n",
        "        search_query = st.text_input(\"Search past responses:\")\n",
        "        if search_query and st.button(\"Search\"):\n",
        "            results = platform.search_similar_responses(search_query)\n",
        "            if results:\n",
        "                for result in results:\n",
        "                    with st.expander(f\"{result['type']}: {result['document'].get('filename', 'Unknown')}\"):\n",
        "                        st.text(result['document']['text'][:500] + \"...\")\n",
        "            else:\n",
        "                st.warning(\"No similar responses found.\")\n",
        "\n",
        "    elif page == \"Knowledge Search\":\n",
        "        st.header(\"🔍 Knowledge Search\")\n",
        "\n",
        "        if not platform.response_data:\n",
        "            st.warning(\"No response documents loaded.\")\n",
        "            return\n",
        "\n",
        "        st.subheader(\"🧠 Search Knowledge Base\")\n",
        "        search_query = st.text_input(\"Search query:\")\n",
        "        search_type = st.radio(\"Search Type:\", [\"Semantic Search\", \"Keyword Search\"])\n",
        "\n",
        "        if search_query and st.button(\"Search\"):\n",
        "            if search_type == \"Semantic Search\" and platform.embedder:\n",
        "                results = platform.search_similar_responses(search_query)\n",
        "            else:\n",
        "                results = []\n",
        "                for i, doc in enumerate(platform.response_data):\n",
        "                    if search_query.lower() in doc['text'].lower():\n",
        "                        results.append({\n",
        "                            'type': 'Response',\n",
        "                            'document': doc,\n",
        "                            'similarity_score': 1.0,\n",
        "                            'rank': i + 1\n",
        "                        })\n",
        "\n",
        "            if results:\n",
        "                st.success(f\"Found {len(results)} documents:\")\n",
        "                for result in results:\n",
        "                    with st.expander(f\"📄 {result['document']['filename']}\"):\n",
        "                        st.text(result['document']['text'][:800] + \"...\")\n",
        "            else:\n",
        "                st.warning(\"No documents found.\")\n",
        "\n",
        "        # Statistics\n",
        "        st.subheader(\"📊 Knowledge Base Stats\")\n",
        "        col1, col2, col3 = st.columns(3)\n",
        "        with col1:\n",
        "            st.metric(\"Documents\", len(platform.response_data))\n",
        "        with col2:\n",
        "            total_words = sum(len(doc['text'].split()) for doc in platform.response_data)\n",
        "            st.metric(\"Total Words\", f\"{total_words:,}\")\n",
        "        with col3:\n",
        "            avg_length = total_words // len(platform.response_data) if platform.response_data else 0\n",
        "            st.metric(\"Avg Length\", f\"{avg_length:,} words\")\n",
        "\n",
        "    elif page == \"Analytics\":\n",
        "        st.header(\"📈 Analytics Dashboard\")\n",
        "\n",
        "        analysis = platform.analyze_win_loss_patterns()\n",
        "\n",
        "        col1, col2 = st.columns(2)\n",
        "\n",
        "        with col1:\n",
        "            st.subheader(\"🎯 Performance\")\n",
        "            try:\n",
        "                fig = go.Figure(go.Indicator(\n",
        "                    mode = \"gauge+number\",\n",
        "                    value = analysis['overall_win_rate'] * 100,\n",
        "                    title = {'text': \"Win Rate (%)\"},\n",
        "                    gauge = {\n",
        "                        'axis': {'range': [None, 100]},\n",
        "                        'bar': {'color': \"darkblue\"},\n",
        "                        'steps': [\n",
        "                            {'range': [0, 50], 'color': \"lightgray\"},\n",
        "                            {'range': [50, 100], 'color': \"green\"}\n",
        "                        ]\n",
        "                    }\n",
        "                ))\n",
        "                fig.update_layout(height=300)\n",
        "                st.plotly_chart(fig, use_container_width=True)\n",
        "            except:\n",
        "                st.metric(\"Win Rate\", f\"{analysis['overall_win_rate']*100:.1f}%\")\n",
        "\n",
        "            st.metric(\"Avg Proposal Time\", f\"{analysis['avg_proposal_time']} days\")\n",
        "\n",
        "        with col2:\n",
        "            st.subheader(\"🏛️ Win Rate by Agency\")\n",
        "            try:\n",
        "                agencies = list(analysis['win_rate_by_agency'].keys())\n",
        "                rates = [r * 100 for r in analysis['win_rate_by_agency'].values()]\n",
        "                fig = px.bar(x=agencies, y=rates, title=\"Win Rate by Agency (%)\")\n",
        "                st.plotly_chart(fig, use_container_width=True)\n",
        "            except:\n",
        "                agency_df = pd.DataFrame({\n",
        "                    'Agency': list(analysis['win_rate_by_agency'].keys()),\n",
        "                    'Win Rate': [f\"{r*100:.1f}%\" for r in analysis['win_rate_by_agency'].values()]\n",
        "                })\n",
        "                st.dataframe(agency_df)\n",
        "\n",
        "        # Success factors\n",
        "        col1, col2 = st.columns(2)\n",
        "        with col1:\n",
        "            st.subheader(\"✅ Success Factors\")\n",
        "            for factor in analysis['success_factors']:\n",
        "                st.write(f\"• {factor}\")\n",
        "        with col2:\n",
        "            st.subheader(\"🎯 Improvement Areas\")\n",
        "            for area in analysis['improvement_areas']:\n",
        "                st.write(f\"• {area}\")\n",
        "\n",
        "        # RFP trends\n",
        "        if platform.rfp_data:\n",
        "            st.subheader(\"📊 RFP Trends\")\n",
        "\n",
        "            # Agency distribution\n",
        "            agency_counts = {}\n",
        "            for rfp in platform.rfp_data:\n",
        "                agency = rfp['agency']\n",
        "                agency_counts[agency] = agency_counts.get(agency, 0) + 1\n",
        "\n",
        "            if agency_counts:\n",
        "                try:\n",
        "                    fig = px.pie(values=list(agency_counts.values()),\n",
        "                               names=list(agency_counts.keys()), title=\"RFPs by Agency\")\n",
        "                    st.plotly_chart(fig, use_container_width=True)\n",
        "                except:\n",
        "                    st.dataframe(pd.DataFrame({\n",
        "                        'Agency': list(agency_counts.keys()),\n",
        "                        'Count': list(agency_counts.values())\n",
        "                    }))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "'''\n",
        "\n",
        "# Write the app file\n",
        "with open('/content/rfp_app.py', 'w') as f:\n",
        "    f.write(app_content)\n",
        "\n",
        "print(\"✅ Main application file created at /content/rfp_app.py\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0A2ELDoPzvca",
        "outputId": "bb906a51-58b6-4441-e9f5-6eda03a4a5bf"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Creating main application file...\n",
            "✅ Main application file created at /content/rfp_app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====  IMPORTS - ADD THESE AT THE TOP =====\n",
        "import os\n",
        "import json\n",
        "import threading\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "\n",
        "# ===== STEP 6: Setup Ngrok and Launch (FIXED) =====\n",
        "print(\"\\n🌐 Setting up public access...\")\n",
        "\n",
        "def run_streamlit():\n",
        "    subprocess.run([\n",
        "        \"streamlit\", \"run\", \"/content/rfp_app.py\",\n",
        "        \"--server.port\", \"8501\",\n",
        "        \"--server.address\", \"0.0.0.0\",\n",
        "        \"--server.headless\", \"true\",\n",
        "        \"--server.fileWatcherType\", \"none\"\n",
        "    ])\n",
        "\n",
        "# Start Streamlit\n",
        "print(\"🚀 Starting Streamlit...\")\n",
        "streamlit_thread = threading.Thread(target=run_streamlit, daemon=True)\n",
        "streamlit_thread.start()\n",
        "\n",
        "# Wait for startup\n",
        "time.sleep(15)\n",
        "\n",
        "# Setup ngrok with authentication\n",
        "try:\n",
        "    from pyngrok import ngrok\n",
        "    from google.colab import userdata\n",
        "\n",
        "    # Get your ngrok authtoken from Colab secrets\n",
        "    try:\n",
        "        NGROK_API_KEY = userdata.get('NGROK_API_KEY')\n",
        "    except:\n",
        "        # Fallback - replace with your actual token\n",
        "        NGROK_API_KEY = \"YOUR_ACTUAL_NGROK_TOKEN_HERE\"  # Replace this!\n",
        "\n",
        "    if not NGROK_API_KEY or NGROK_API_KEY == \"YOUR_ACTUAL_NGROK_TOKEN_HERE\":\n",
        "        print(\"⚠️  Please add your ngrok token to Colab secrets or update the code\")\n",
        "        print(\"🔧 Running without ngrok...\")\n",
        "        print(\"📱 Streamlit is running on http://localhost:8501\")\n",
        "    else:\n",
        "        print(\"🔐 Authenticating with ngrok...\")\n",
        "        ngrok.set_auth_token(NGROK_API_KEY)\n",
        "\n",
        "        print(\"🌐 Creating public tunnel...\")\n",
        "        public_url = ngrok.connect(8501)\n",
        "\n",
        "        print(f\"\\n🎉 SUCCESS! Your RFP Platform is ready!\")\n",
        "        print(f\"🌐 Access your platform at: {public_url}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n⚠️  Ngrok issue: {e}\")\n",
        "    print(\"🔧 Try accessing via Colab's port forwarding instead\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ajGAl_31xcm",
        "outputId": "5b97e6be-619d-4e76-e266-4758c21726e4"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🌐 Setting up public access...\n",
            "🚀 Starting Streamlit...\n",
            "🔐 Authenticating with ngrok...\n",
            "🌐 Creating public tunnel...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2025-05-30T20:51:40+0000 lvl=warn msg=\"failed to start tunnel\" pg=/api/tunnels id=9a2434711fc8403c err=\"failed to start tunnel: Your account may not run more than 3 tunnels over a single ngrok agent session.\\nThe tunnels already running on this session are:\\ntn_2xpXkCQqPbP9q30ypnsfNUFqIPL, tn_2xpXzVuqN54idDZYU2fimL5Dfoo, tn_2xpYBitbMzJxluHD41P36wxuZv0\\n\\r\\n\\r\\nERR_NGROK_324\\r\\n\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⚠️  Ngrok issue: ngrok client exception, API returned 502: {\"error_code\":103,\"status_code\":502,\"msg\":\"failed to start tunnel\",\"details\":{\"err\":\"failed to start tunnel: Your account may not run more than 3 tunnels over a single ngrok agent session.\\nThe tunnels already running on this session are:\\ntn_2xpXkCQqPbP9q30ypnsfNUFqIPL, tn_2xpXzVuqN54idDZYU2fimL5Dfoo, tn_2xpYBitbMzJxluHD41P36wxuZv0\\n\\r\\n\\r\\nERR_NGROK_324\\r\\n\"}}\n",
            "\n",
            "🔧 Try accessing via Colab's port forwarding instead\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NQFKBcnw8f4D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}