{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNg1vbuW3JLwYiMYVAEB/dr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TeneikaAskew/taap/blob/main/rfp_app_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 1: Install Dependencies"
      ],
      "metadata": {
        "id": "OHUpg3Kc5gDM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Colab Setup Script for RFP Proposal Intelligence Platform\n",
        "# Run this in Google Colab to set up the complete environment\n",
        "\n",
        "# ===== STEP 1: Install Dependencies =====\n",
        "print(\"Installing required packages...\")\n",
        "\n",
        "!pip install -q streamlit\n",
        "!pip install -q sentence-transformers\n",
        "!pip install -q faiss-cpu\n",
        "!pip install -q PyPDF2\n",
        "!pip install -q python-docx\n",
        "!pip install -q plotly\n",
        "!pip install -q pyngrok\n",
        "\n",
        "print(\"✅ Packages installed successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1B_-FjIt7pK",
        "outputId": "b7f5cd3b-b473-4d51-e1d2-4b1fcb170497"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing required packages...\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m128.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m120.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h✅ Packages installed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 2: Mount Google Drive"
      ],
      "metadata": {
        "id": "q416yY8g5dMf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== STEP 2: Mount Google Drive =====\n",
        "print(\"\\nMounting Google Drive...\")\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "try:\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"✅ Google Drive mounted successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error mounting drive: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9a5-nS5t-ft",
        "outputId": "79fd81e7-d9bc-4d47-fa24-9e614ab335fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Mounting Google Drive...\n",
            "Mounted at /content/drive\n",
            "✅ Google Drive mounted successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nCreating directory structure...\")\n",
        "\n",
        "base_path = \"/content/drive/Shared drives/Leadership/rfp app\"\n",
        "rfps_path = os.path.join(base_path, \"RFP\")\n",
        "responses_path = os.path.join(base_path, \"Responses\")\n",
        "\n",
        "os.makedirs(base_path, exist_ok=True)\n",
        "os.makedirs(rfps_path, exist_ok=True)\n",
        "os.makedirs(responses_path, exist_ok=True)\n",
        "\n",
        "print(f\"✅ Directories created:\")\n",
        "print(f\"   📁 {base_path}\")\n",
        "print(f\"   📁 {rfps_path}\")\n",
        "print(f\"   📁 {responses_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTMhCFwFuA9W",
        "outputId": "09e51e17-3b5b-4850-cc5c-c7457a035733"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Creating directory structure...\n",
            "✅ Directories created:\n",
            "   📁 /content/drive/Shared drives/Leadership/rfp app\n",
            "   📁 /content/drive/Shared drives/Leadership/rfp app/RFP\n",
            "   📁 /content/drive/Shared drives/Leadership/rfp app/Responses\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 4: Create Sample Documents (Optional)"
      ],
      "metadata": {
        "id": "WmL_gyCD5ZIS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== STEP 4: Create Sample Documents (Optional) =====\n",
        "print(\"\\nCreating sample documents...\")\n",
        "\n",
        "# Sample RFP content\n",
        "sample_rfp_content = \"\"\"\n",
        "REQUEST FOR PROPOSAL\n",
        "IT MODERNIZATION SERVICES\n",
        "\n",
        "Solicitation Number: RFP-2024-IT-001\n",
        "Agency: Department of Homeland Security (DHS)\n",
        "Due Date: August 15, 2024\n",
        "NAICS Code: 541512\n",
        "\n",
        "STATEMENT OF WORK:\n",
        "The Department of Homeland Security requires comprehensive IT modernization services including:\n",
        "1. Cloud migration services for legacy systems\n",
        "2. Cybersecurity assessment and implementation\n",
        "3. System integration and data migration\n",
        "4. 24/7 technical support and maintenance\n",
        "\n",
        "REQUIREMENTS:\n",
        "- Contractor must have minimum 5 years of federal IT experience\n",
        "- Must maintain FedRAMP compliance throughout contract period\n",
        "- Shall provide dedicated project manager with PMP certification\n",
        "- Must complete security clearance requirements for key personnel\n",
        "\n",
        "EVALUATION CRITERIA:\n",
        "- Technical Approach (40 points)\n",
        "- Past Performance (30 points)\n",
        "- Management Plan (20 points)\n",
        "- Cost Proposal (10 points)\n",
        "\n",
        "CONTRACT VALUE: $2,500,000\n",
        "CONTRACT PERIOD: 18 months with option for 12-month extension\n",
        "\"\"\"\n",
        "\n",
        "# Sample Response content\n",
        "sample_response_content = \"\"\"\n",
        "TECHNICAL PROPOSAL\n",
        "IT MODERNIZATION SERVICES\n",
        "Submitted by: A3 Consulting LLC\n",
        "\n",
        "EXECUTIVE SUMMARY:\n",
        "A3 Consulting LLC is pleased to submit this proposal for IT Modernization Services.\n",
        "Our team brings over 15 years of federal IT experience, having successfully completed\n",
        "25+ cloud migration projects for federal agencies.\n",
        "\n",
        "TECHNICAL APPROACH:\n",
        "Our proven methodology includes:\n",
        "1. Comprehensive Assessment Phase\n",
        "   - Current state analysis\n",
        "   - Risk assessment\n",
        "   - Security evaluation\n",
        "\n",
        "2. Migration Planning Phase\n",
        "   - Detailed migration strategy\n",
        "   - Timeline development\n",
        "   - Resource allocation\n",
        "\n",
        "3. Implementation Phase\n",
        "   - Phased migration approach\n",
        "   - Continuous testing\n",
        "   - Quality assurance\n",
        "\n",
        "4. Support and Maintenance\n",
        "   - 24/7 monitoring\n",
        "   - Regular updates\n",
        "   - Performance optimization\n",
        "\n",
        "PAST PERFORMANCE:\n",
        "Project 1: DHS Cloud Migration (2023)\n",
        "- Migrated 12 legacy systems to AWS GovCloud\n",
        "- Completed 2 months ahead of schedule\n",
        "- Achieved 99.9% uptime\n",
        "\n",
        "Project 2: VA Cybersecurity Implementation (2022)\n",
        "- Implemented comprehensive security framework\n",
        "- Achieved FedRAMP certification\n",
        "- Zero security incidents during implementation\n",
        "\n",
        "MANAGEMENT PLAN:\n",
        "Our dedicated project team includes:\n",
        "- Project Manager: Jane Smith, PMP, 10 years federal experience\n",
        "- Technical Lead: John Doe, CISSP, 8 years cloud experience\n",
        "- Security Specialist: Mike Johnson, CISM, 12 years cybersecurity\n",
        "\n",
        "CERTIFICATIONS:\n",
        "- ISO 9001 Quality Management\n",
        "- FedRAMP Authorized\n",
        "- CMMI Level 3\n",
        "\"\"\"\n",
        "\n",
        "# Write sample files\n",
        "sample_rfp_path = os.path.join(rfps_path, \"DHS_IT_Modernization_RFP.txt\")\n",
        "sample_response_path = os.path.join(responses_path, \"A3_IT_Modernization_Response.txt\")\n",
        "\n",
        "with open(sample_rfp_path, 'w') as f:\n",
        "    f.write(sample_rfp_content)\n",
        "\n",
        "with open(sample_response_path, 'w') as f:\n",
        "    f.write(sample_response_content)\n",
        "\n",
        "print(f\"✅ Sample documents created:\")\n",
        "print(f\"   📄 {sample_rfp_path}\")\n",
        "print(f\"   📄 {sample_response_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81NiZvftuMv-",
        "outputId": "c7b027e3-09da-49ff-9ddc-2461c9b1acc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Creating sample documents...\n",
            "✅ Sample documents created:\n",
            "   📄 /content/drive/Shared drives/Leadership/rfp app/RFP/DHS_IT_Modernization_RFP.txt\n",
            "   📄 /content/drive/Shared drives/Leadership/rfp app/Responses/A3_IT_Modernization_Response.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 5: Create the Main Application File"
      ],
      "metadata": {
        "id": "DTzKcowT5U1A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # ===== STEP 5: Create the Main Application File =====\n",
        "# print(\"\\nCreating main application file...\")\n",
        "\n",
        "# app_content = '''\n",
        "# # RFP Proposal Intelligence Platform - Main Application\n",
        "\n",
        "# import streamlit as st\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import os\n",
        "# import json\n",
        "# from datetime import datetime, timedelta\n",
        "# import re\n",
        "# from typing import List, Dict, Any, Optional\n",
        "# import logging\n",
        "\n",
        "# # Document processing\n",
        "# try:\n",
        "#     import PyPDF2\n",
        "#     import docx\n",
        "# except ImportError:\n",
        "#     st.error(\"Please install: !pip install PyPDF2 python-docx\")\n",
        "\n",
        "# # ML components\n",
        "# try:\n",
        "#     from sentence_transformers import SentenceTransformer\n",
        "#     import faiss\n",
        "#     from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# except ImportError:\n",
        "#     st.error(\"Please install: !pip install sentence-transformers faiss-cpu scikit-learn\")\n",
        "\n",
        "# # Visualization\n",
        "# try:\n",
        "#     import plotly.express as px\n",
        "#     import plotly.graph_objects as go\n",
        "# except ImportError:\n",
        "#     st.error(\"Please install: !pip install plotly\")\n",
        "\n",
        "# logging.basicConfig(level=logging.INFO)\n",
        "# logger = logging.getLogger(__name__)\n",
        "\n",
        "# class RFPPlatform:\n",
        "#     def __init__(self, drive_path=\"/content/drive/Shared drives/Leadership/rfp app\"):\n",
        "#         self.drive_path = drive_path\n",
        "#         self.rfps_path = os.path.join(drive_path, \"rfps\")\n",
        "#         self.responses_path = os.path.join(drive_path, \"responses\")\n",
        "\n",
        "#         try:\n",
        "#             self.embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "#             self.vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
        "#         except Exception as e:\n",
        "#             st.warning(f\"AI components not loaded: {e}\")\n",
        "#             self.embedder = None\n",
        "#             self.vectorizer = None\n",
        "\n",
        "#         self.rfp_data = []\n",
        "#         self.response_data = []\n",
        "#         self.embeddings = None\n",
        "#         self.index = None\n",
        "\n",
        "#         self.company_profile = {\n",
        "#             \"name\": \"A3 Consulting LLC\",\n",
        "#             \"naics_codes\": [\"541511\", \"541512\", \"541519\", \"541611\"],\n",
        "#             \"capabilities\": [\n",
        "#                 \"Management Consulting\", \"IT Consulting\", \"Strategic Planning\",\n",
        "#                 \"Process Improvement\", \"Data Analytics\", \"Project Management\",\n",
        "#                 \"Cybersecurity Consulting\", \"Digital Transformation\"\n",
        "#             ],\n",
        "#             \"certifications\": [\"ISO 9001\", \"CMMI Level 3\", \"FedRAMP\"],\n",
        "#             \"socioeconomic\": [\"Small Business\"],\n",
        "#             \"past_performance_keywords\": [\n",
        "#                 \"government consulting\", \"strategic planning\", \"process optimization\",\n",
        "#                 \"data analysis\", \"cloud migration\", \"cybersecurity\", \"IT modernization\"\n",
        "#             ]\n",
        "#         }\n",
        "\n",
        "#         self.setup_directories()\n",
        "\n",
        "#     def setup_directories(self):\n",
        "#         try:\n",
        "#             os.makedirs(self.rfps_path, exist_ok=True)\n",
        "#             os.makedirs(self.responses_path, exist_ok=True)\n",
        "#         except Exception as e:\n",
        "#             st.error(f\"Error creating directories: {e}\")\n",
        "\n",
        "#     def extract_text_from_pdf(self, file_path):\n",
        "#         try:\n",
        "#             with open(file_path, 'rb') as file:\n",
        "#                 pdf_reader = PyPDF2.PdfReader(file)\n",
        "#                 text = \"\"\n",
        "#                 for page in pdf_reader.pages:\n",
        "#                     text += page.extract_text() + \"\\\\n\"\n",
        "#                 return text\n",
        "#         except Exception as e:\n",
        "#             return \"\"\n",
        "\n",
        "#     def extract_text_from_docx(self, file_path):\n",
        "#         try:\n",
        "#             doc = docx.Document(file_path)\n",
        "#             text = \"\"\n",
        "#             for paragraph in doc.paragraphs:\n",
        "#                 text += paragraph.text + \"\\\\n\"\n",
        "#             return text\n",
        "#         except Exception as e:\n",
        "#             return \"\"\n",
        "\n",
        "#     def load_documents(self):\n",
        "#         st.info(\"Loading documents...\")\n",
        "\n",
        "#         if not os.path.exists(self.drive_path):\n",
        "#             st.error(f\"Drive path not found: {self.drive_path}\")\n",
        "#             return\n",
        "\n",
        "#         # Load RFPs\n",
        "#         rfp_files = []\n",
        "#         if os.path.exists(self.rfps_path):\n",
        "#             rfp_files = [f for f in os.listdir(self.rfps_path)\n",
        "#                         if f.endswith(('.pdf', '.docx', '.txt'))]\n",
        "\n",
        "#         # Load responses\n",
        "#         response_files = []\n",
        "#         if os.path.exists(self.responses_path):\n",
        "#             response_files = [f for f in os.listdir(self.responses_path)\n",
        "#                              if f.endswith(('.pdf', '.docx', '.txt'))]\n",
        "\n",
        "#         # Process RFPs\n",
        "#         self.rfp_data = []\n",
        "#         for file in rfp_files:\n",
        "#             try:\n",
        "#                 file_path = os.path.join(self.rfps_path, file)\n",
        "\n",
        "#                 if file.endswith('.pdf'):\n",
        "#                     text = self.extract_text_from_pdf(file_path)\n",
        "#                 elif file.endswith('.docx'):\n",
        "#                     text = self.extract_text_from_docx(file_path)\n",
        "#                 else:\n",
        "#                     with open(file_path, 'r', encoding='utf-8') as f:\n",
        "#                         text = f.read()\n",
        "\n",
        "#                 rfp_info = self.parse_rfp_metadata(text, file)\n",
        "#                 rfp_info['file_path'] = file_path\n",
        "#                 rfp_info['text'] = text\n",
        "#                 self.rfp_data.append(rfp_info)\n",
        "#             except Exception as e:\n",
        "#                 st.warning(f\"Error processing {file}: {e}\")\n",
        "\n",
        "#         # Process responses\n",
        "#         self.response_data = []\n",
        "#         for file in response_files:\n",
        "#             try:\n",
        "#                 file_path = os.path.join(self.responses_path, file)\n",
        "\n",
        "#                 if file.endswith('.pdf'):\n",
        "#                     text = self.extract_text_from_pdf(file_path)\n",
        "#                 elif file.endswith('.docx'):\n",
        "#                     text = self.extract_text_from_docx(file_path)\n",
        "#                 else:\n",
        "#                     with open(file_path, 'r', encoding='utf-8') as f:\n",
        "#                         text = f.read()\n",
        "\n",
        "#                 response_info = {\n",
        "#                     'filename': file,\n",
        "#                     'text': text,\n",
        "#                     'file_path': file_path,\n",
        "#                     'date_created': datetime.now()\n",
        "#                 }\n",
        "#                 self.response_data.append(response_info)\n",
        "#             except Exception as e:\n",
        "#                 st.warning(f\"Error processing {file}: {e}\")\n",
        "\n",
        "#         st.success(f\"Loaded {len(self.rfp_data)} RFPs and {len(self.response_data)} responses\")\n",
        "\n",
        "#     def parse_rfp_metadata(self, text, filename):\n",
        "#         return {\n",
        "#             'title': filename.replace('.pdf', '').replace('.docx', '').replace('.txt', ''),\n",
        "#             'filename': filename,\n",
        "#             'agency': self.extract_agency(text),\n",
        "#             'due_date': self.extract_due_date(text),\n",
        "#             'naics_codes': self.extract_naics_codes(text),\n",
        "#             'contract_value': self.extract_contract_value(text),\n",
        "#             'requirements': self.extract_requirements(text),\n",
        "#             'evaluation_criteria': self.extract_evaluation_criteria(text),\n",
        "#             'date_loaded': datetime.now()\n",
        "#         }\n",
        "\n",
        "#     def extract_agency(self, text):\n",
        "#         agencies = ['DHS', 'DOD', 'GSA', 'VA', 'HHS', 'DOE', 'NASA', 'USDA',\n",
        "#                    'Department of Homeland Security', 'General Services Administration']\n",
        "#         text_upper = text.upper()\n",
        "#         for agency in agencies:\n",
        "#             if agency.upper() in text_upper:\n",
        "#                 if 'HOMELAND SECURITY' in agency.upper():\n",
        "#                     return 'DHS'\n",
        "#                 elif 'GENERAL SERVICES' in agency.upper():\n",
        "#                     return 'GSA'\n",
        "#                 else:\n",
        "#                     return agency\n",
        "#         return \"Unknown\"\n",
        "\n",
        "#     def extract_due_date(self, text):\n",
        "#         import re\n",
        "#         date_patterns = [\n",
        "#             r'\\\\b\\\\d{1,2}/\\\\d{1,2}/\\\\d{4}\\\\b',\n",
        "#             r'\\\\b\\\\d{1,2}-\\\\d{1,2}-\\\\d{4}\\\\b',\n",
        "#             r'\\\\b\\\\w+ \\\\d{1,2}, \\\\d{4}\\\\b'\n",
        "#         ]\n",
        "\n",
        "#         for pattern in date_patterns:\n",
        "#             matches = re.findall(pattern, text)\n",
        "#             if matches:\n",
        "#                 return matches[0]\n",
        "#         return \"Not found\"\n",
        "\n",
        "#     def extract_naics_codes(self, text):\n",
        "#         import re\n",
        "#         naics_pattern = r'\\\\b\\\\d{6}\\\\b'\n",
        "#         codes = re.findall(naics_pattern, text)\n",
        "#         return codes[:5]\n",
        "\n",
        "#     def extract_contract_value(self, text):\n",
        "#         import re\n",
        "#         value_patterns = [\n",
        "#             r'\\\\$[\\\\d,]+(?:\\\\.\\\\d{2})?',\n",
        "#             r'[\\\\d,]+ dollars?'\n",
        "#         ]\n",
        "\n",
        "#         for pattern in value_patterns:\n",
        "#             matches = re.findall(pattern, text, re.IGNORECASE)\n",
        "#             if matches:\n",
        "#                 return matches[0]\n",
        "#         return \"Not specified\"\n",
        "\n",
        "#     def extract_requirements(self, text):\n",
        "#         req_keywords = ['requirement', 'shall', 'must', 'mandatory', 'criteria']\n",
        "#         sentences = text.split('.')\n",
        "#         requirements = []\n",
        "\n",
        "#         for sentence in sentences:\n",
        "#             sentence_lower = sentence.lower()\n",
        "#             if any(keyword in sentence_lower for keyword in req_keywords):\n",
        "#                 if len(sentence.strip()) > 20:\n",
        "#                     requirements.append(sentence.strip())\n",
        "\n",
        "#         return requirements[:10]\n",
        "\n",
        "#     def extract_evaluation_criteria(self, text):\n",
        "#         criteria_keywords = ['evaluation', 'scoring', 'points', 'weight', 'factor']\n",
        "#         sentences = text.split('.')\n",
        "#         criteria = []\n",
        "\n",
        "#         for sentence in sentences:\n",
        "#             sentence_lower = sentence.lower()\n",
        "#             if any(keyword in sentence_lower for keyword in criteria_keywords):\n",
        "#                 if len(sentence.strip()) > 20:\n",
        "#                     criteria.append(sentence.strip())\n",
        "\n",
        "#         return criteria[:5]\n",
        "\n",
        "#     def build_embeddings(self):\n",
        "#         if not self.embedder or (not self.rfp_data and not self.response_data):\n",
        "#             return\n",
        "\n",
        "#         all_texts = []\n",
        "#         for rfp in self.rfp_data:\n",
        "#             all_texts.append(rfp['text'])\n",
        "#         for response in self.response_data:\n",
        "#             all_texts.append(response['text'])\n",
        "\n",
        "#         if all_texts:\n",
        "#             try:\n",
        "#                 self.embeddings = self.embedder.encode(all_texts)\n",
        "#                 dimension = self.embeddings.shape[1]\n",
        "#                 self.index = faiss.IndexFlatIP(dimension)\n",
        "#                 self.index.add(self.embeddings.astype('float32'))\n",
        "#                 st.success(f\"Built embeddings for {len(all_texts)} documents\")\n",
        "#             except Exception as e:\n",
        "#                 st.error(f\"Error building embeddings: {e}\")\n",
        "\n",
        "#     def calculate_opportunity_fit(self, rfp_info):\n",
        "#         score = 0\n",
        "\n",
        "#         # NAICS code match (30 points)\n",
        "#         naics_match = any(code in self.company_profile['naics_codes']\n",
        "#                          for code in rfp_info['naics_codes'])\n",
        "#         if naics_match:\n",
        "#             score += 30\n",
        "\n",
        "#         # Capability keywords match (40 points)\n",
        "#         text_lower = rfp_info['text'].lower()\n",
        "#         capability_matches = sum(1 for cap in self.company_profile['capabilities']\n",
        "#                                if cap.lower() in text_lower)\n",
        "#         score += min(40, capability_matches * 8)\n",
        "\n",
        "#         # Past performance keywords (30 points)\n",
        "#         pp_matches = sum(1 for keyword in self.company_profile['past_performance_keywords']\n",
        "#                         if keyword in text_lower)\n",
        "#         score += min(30, pp_matches * 10)\n",
        "\n",
        "#         return min(score, 100)\n",
        "\n",
        "#     def generate_compliance_matrix(self, rfp_info):\n",
        "#         requirements = rfp_info['requirements']\n",
        "#         matrix = []\n",
        "\n",
        "#         for i, req in enumerate(requirements):\n",
        "#             compliant = any(cap.lower() in req.lower()\n",
        "#                           for cap in self.company_profile['capabilities'])\n",
        "\n",
        "#             matrix.append({\n",
        "#                 'requirement': req[:100] + \"...\" if len(req) > 100 else req,\n",
        "#                 'compliant': 'Yes' if compliant else 'Needs Review',\n",
        "#                 'response_section': f\"Section {i+1}\"\n",
        "#             })\n",
        "\n",
        "#         return matrix\n",
        "\n",
        "#     def search_similar_responses(self, query, top_k=5):\n",
        "#         if self.index is None or self.embedder is None:\n",
        "#             return []\n",
        "\n",
        "#         try:\n",
        "#             query_embedding = self.embedder.encode([query])\n",
        "#             scores, indices = self.index.search(query_embedding.astype('float32'), top_k)\n",
        "\n",
        "#             results = []\n",
        "#             for i, (score, idx) in enumerate(zip(scores[0], indices[0])):\n",
        "#                 if idx < len(self.rfp_data):\n",
        "#                     doc_type = \"RFP\"\n",
        "#                     doc = self.rfp_data[idx]\n",
        "#                 else:\n",
        "#                     doc_type = \"Response\"\n",
        "#                     doc = self.response_data[idx - len(self.rfp_data)]\n",
        "\n",
        "#                 results.append({\n",
        "#                     'type': doc_type,\n",
        "#                     'document': doc,\n",
        "#                     'similarity_score': float(score),\n",
        "#                     'rank': i + 1\n",
        "#                 })\n",
        "\n",
        "#             return results\n",
        "#         except Exception as e:\n",
        "#             return []\n",
        "\n",
        "#     def generate_proposal_outline(self, rfp_info):\n",
        "#         outline = {\n",
        "#             \"Executive Summary\": {\n",
        "#                 \"description\": \"Overview of our approach and key win themes\",\n",
        "#                 \"suggested_content\": \"Highlight A3's unique qualifications\"\n",
        "#             },\n",
        "#             \"Technical Approach\": {\n",
        "#                 \"description\": \"Detailed methodology and approach\",\n",
        "#                 \"suggested_content\": \"Address each technical requirement\"\n",
        "#             },\n",
        "#             \"Management Plan\": {\n",
        "#                 \"description\": \"Project management and organization\",\n",
        "#                 \"suggested_content\": \"Show project structure and timeline\"\n",
        "#             },\n",
        "#             \"Past Performance\": {\n",
        "#                 \"description\": \"Relevant experience and references\",\n",
        "#                 \"suggested_content\": \"Include similar projects\"\n",
        "#             }\n",
        "#         }\n",
        "\n",
        "#         requirements = rfp_info['requirements']\n",
        "#         custom_sections = []\n",
        "\n",
        "#         for req in requirements:\n",
        "#             if 'security' in req.lower():\n",
        "#                 custom_sections.append(\"Security Approach\")\n",
        "#             elif 'quality' in req.lower():\n",
        "#                 custom_sections.append(\"Quality Assurance\")\n",
        "\n",
        "#         for section in set(custom_sections):\n",
        "#             outline[section] = {\n",
        "#                 \"description\": f\"Address {section.lower()} requirements\",\n",
        "#                 \"suggested_content\": f\"Detail our {section.lower()} approach\"\n",
        "#             }\n",
        "\n",
        "#         return outline\n",
        "\n",
        "#     def analyze_win_loss_patterns(self):\n",
        "#         return {\n",
        "#             'overall_win_rate': 0.45,\n",
        "#             'win_rate_by_agency': {'DHS': 0.6, 'GSA': 0.4, 'DOD': 0.5, 'VA': 0.3},\n",
        "#             'avg_proposal_time': 25,\n",
        "#             'success_factors': [\n",
        "#                 'Strong past performance alignment',\n",
        "#                 'Competitive pricing',\n",
        "#                 'Clear technical approach'\n",
        "#             ],\n",
        "#             'improvement_areas': [\n",
        "#                 'Faster response time',\n",
        "#                 'Better capture intelligence'\n",
        "#             ]\n",
        "#         }\n",
        "\n",
        "# def create_sample_data():\n",
        "#     sample_rfps = [\n",
        "#         {\n",
        "#             'title': 'IT_Modernization_Services',\n",
        "#             'filename': 'DHS_IT_Modernization_RFP.txt',\n",
        "#             'agency': 'DHS',\n",
        "#             'due_date': '2024-08-15',\n",
        "#             'naics_codes': ['541511', '541512'],\n",
        "#             'contract_value': '$2,500,000',\n",
        "#             'text': 'Department of Homeland Security requires IT modernization including cloud migration, cybersecurity assessment, and system integration.',\n",
        "#             'requirements': [\n",
        "#                 'Must have federal cloud migration experience',\n",
        "#                 'Shall provide 24/7 technical support',\n",
        "#                 'Must maintain FedRAMP compliance'\n",
        "#             ],\n",
        "#             'evaluation_criteria': [\n",
        "#                 'Technical approach weighted 40%',\n",
        "#                 'Past performance weighted 30%'\n",
        "#             ],\n",
        "#             'date_loaded': datetime.now()\n",
        "#         }\n",
        "#     ]\n",
        "\n",
        "#     sample_responses = [\n",
        "#         {\n",
        "#             'filename': 'A3_IT_Modernization_Response.txt',\n",
        "#             'text': 'A3 Consulting has extensive federal IT modernization experience with 15+ successful cloud migrations.',\n",
        "#             'date_created': datetime.now()\n",
        "#         }\n",
        "#     ]\n",
        "\n",
        "#     return sample_rfps, sample_responses\n",
        "\n",
        "# def setup_sample_environment():\n",
        "#     st.info(\"Setting up sample environment...\")\n",
        "#     sample_rfps, sample_responses = create_sample_data()\n",
        "\n",
        "#     platform = RFPPlatform()\n",
        "#     platform.rfp_data = sample_rfps\n",
        "#     platform.response_data = sample_responses\n",
        "\n",
        "#     try:\n",
        "#         platform.build_embeddings()\n",
        "#     except:\n",
        "#         pass\n",
        "\n",
        "#     st.session_state.platform = platform\n",
        "#     st.success(\"Sample environment ready!\")\n",
        "#     return platform\n",
        "\n",
        "# def main():\n",
        "#     st.set_page_config(\n",
        "#         page_title=\"RFP Intelligence Platform\",\n",
        "#         page_icon=\"📄\",\n",
        "#         layout=\"wide\"\n",
        "#     )\n",
        "\n",
        "#     st.title(\"🚀 RFP Proposal Intelligence Platform\")\n",
        "#     st.markdown(\"### AI-Powered Proposal Development for A3 Consulting LLC\")\n",
        "\n",
        "#     if 'platform' not in st.session_state:\n",
        "#         st.session_state.platform = RFPPlatform()\n",
        "\n",
        "#     platform = st.session_state.platform\n",
        "\n",
        "#     # Sidebar\n",
        "#     st.sidebar.title(\"Navigation\")\n",
        "#     page = st.sidebar.selectbox(\n",
        "#         \"Choose a page:\",\n",
        "#         [\"Setup & Data Loading\", \"Opportunity Dashboard\", \"RFP Analysis\",\n",
        "#          \"Proposal Assistant\", \"Knowledge Search\", \"Analytics\"]\n",
        "#     )\n",
        "\n",
        "#     st.sidebar.markdown(\"---\")\n",
        "#     st.sidebar.subheader(\"🧪 Demo Mode\")\n",
        "\n",
        "#     if st.sidebar.button(\"Load Sample Data\"):\n",
        "#         setup_sample_environment()\n",
        "\n",
        "#     if st.sidebar.button(\"Reset\"):\n",
        "#         for key in list(st.session_state.keys()):\n",
        "#             del st.session_state[key]\n",
        "#         st.rerun()\n",
        "\n",
        "#     # Pages\n",
        "#     if page == \"Setup & Data Loading\":\n",
        "#         st.header(\"🔧 Setup & Data Loading\")\n",
        "\n",
        "#         col1, col2 = st.columns(2)\n",
        "\n",
        "#         with col1:\n",
        "#             st.subheader(\"Google Drive Connection\")\n",
        "#             drive_path = st.text_input(\"Drive Path\", \"/content/drive/Shared drives/Leadership/rfp app\")  # Use your actual path\n",
        "\n",
        "#             if drive_path != platform.drive_path:\n",
        "#                 platform.drive_path = drive_path\n",
        "#                 platform.rfps_path = os.path.join(drive_path, \"rfps\")\n",
        "#                 platform.responses_path = os.path.join(drive_path, \"responses\")\n",
        "\n",
        "#             if os.path.exists(drive_path):\n",
        "#                 st.success(\"✅ Drive path found\")\n",
        "#             else:\n",
        "#                 st.error(\"❌ Drive path not found\")\n",
        "\n",
        "#         with col2:\n",
        "#             st.subheader(\"Data Loading\")\n",
        "#             if st.button(\"Load Documents\", type=\"primary\"):\n",
        "#                 platform.load_documents()\n",
        "#                 platform.build_embeddings()\n",
        "\n",
        "#             st.info(f\"\"\"\n",
        "#             **Status:**\n",
        "#             - RFPs: {len(platform.rfp_data)}\n",
        "#             - Responses: {len(platform.response_data)}\n",
        "#             - Embeddings: {'Yes' if platform.embeddings is not None else 'No'}\n",
        "#             \"\"\")\n",
        "\n",
        "#         st.subheader(\"📋 Company Profile\")\n",
        "#         with st.expander(\"A3 Consulting Profile\"):\n",
        "#             st.json(platform.company_profile)\n",
        "\n",
        "#     elif page == \"Opportunity Dashboard\":\n",
        "#         st.header(\"🎯 Opportunity Dashboard\")\n",
        "\n",
        "#         if not platform.rfp_data:\n",
        "#             st.warning(\"No RFPs loaded. Use Setup page or Sample Data.\")\n",
        "#             return\n",
        "\n",
        "#         # Filters\n",
        "#         col1, col2, col3 = st.columns(3)\n",
        "#         with col1:\n",
        "#             agency_filter = st.selectbox(\"Agency\", [\"All\"] + list(set([rfp['agency'] for rfp in platform.rfp_data])))\n",
        "#         with col2:\n",
        "#             min_fit_score = st.slider(\"Min Fit Score\", 0, 100, 50)\n",
        "#         with col3:\n",
        "#             sort_by = st.selectbox(\"Sort by\", [\"Fit Score\", \"Date\", \"Agency\"])\n",
        "\n",
        "#         # Filter and sort\n",
        "#         rfp_opportunities = []\n",
        "#         for rfp in platform.rfp_data:\n",
        "#             fit_score = platform.calculate_opportunity_fit(rfp)\n",
        "#             if fit_score >= min_fit_score:\n",
        "#                 if agency_filter == \"All\" or rfp['agency'] == agency_filter:\n",
        "#                     rfp['fit_score'] = fit_score\n",
        "#                     rfp_opportunities.append(rfp)\n",
        "\n",
        "#         if sort_by == \"Fit Score\":\n",
        "#             rfp_opportunities.sort(key=lambda x: x['fit_score'], reverse=True)\n",
        "\n",
        "#         st.subheader(f\"📊 {len(rfp_opportunities)} Opportunities\")\n",
        "\n",
        "#         for i, rfp in enumerate(rfp_opportunities):\n",
        "#             with st.expander(f\"🎯 {rfp['title']} (Fit: {rfp['fit_score']}%)\"):\n",
        "#                 col1, col2 = st.columns(2)\n",
        "#                 with col1:\n",
        "#                     st.write(f\"**Agency:** {rfp['agency']}\")\n",
        "#                     st.write(f\"**Due Date:** {rfp['due_date']}\")\n",
        "#                     st.write(f\"**Value:** {rfp['contract_value']}\")\n",
        "#                 with col2:\n",
        "#                     st.metric(\"Fit Score\", f\"{rfp['fit_score']}%\")\n",
        "\n",
        "#                 if st.button(f\"Analyze\", key=f\"analyze_{i}\"):\n",
        "#                     st.session_state.selected_rfp = rfp\n",
        "#                     st.success(\"RFP selected!\")\n",
        "\n",
        "#     elif page == \"RFP Analysis\":\n",
        "#         st.header(\"🔍 RFP Analysis\")\n",
        "\n",
        "#         if 'selected_rfp' not in st.session_state:\n",
        "#             st.warning(\"Select an RFP from Dashboard first.\")\n",
        "#             return\n",
        "\n",
        "#         rfp = st.session_state.selected_rfp\n",
        "\n",
        "#         st.subheader(f\"📄 {rfp['title']}\")\n",
        "\n",
        "#         col1, col2, col3 = st.columns(3)\n",
        "#         with col1:\n",
        "#             st.metric(\"Fit Score\", f\"{rfp.get('fit_score', 'N/A')}%\")\n",
        "#         with col2:\n",
        "#             st.metric(\"Requirements\", len(rfp['requirements']))\n",
        "#         with col3:\n",
        "#             st.metric(\"Agency\", rfp['agency'])\n",
        "\n",
        "#         # Requirements\n",
        "#         st.subheader(\"📋 Requirements\")\n",
        "#         if rfp['requirements']:\n",
        "#             for req in rfp['requirements']:\n",
        "#                 st.write(f\"• {req}\")\n",
        "#         else:\n",
        "#             st.info(\"No requirements extracted.\")\n",
        "\n",
        "#         # Compliance Matrix\n",
        "#         st.subheader(\"✅ Compliance Matrix\")\n",
        "#         compliance_matrix = platform.generate_compliance_matrix(rfp)\n",
        "#         if compliance_matrix:\n",
        "#             st.dataframe(pd.DataFrame(compliance_matrix))\n",
        "\n",
        "#         # Q&A\n",
        "#         st.subheader(\"❓ Q&A Assistant\")\n",
        "#         question = st.text_input(\"Ask about this RFP:\")\n",
        "#         if question and st.button(\"Answer\"):\n",
        "#             sentences = rfp['text'].split('.')\n",
        "#             relevant = [s.strip() for s in sentences\n",
        "#                        if any(word in s.lower() for word in question.lower().split())]\n",
        "#             if relevant:\n",
        "#                 st.success(\"**Relevant content:**\")\n",
        "#                 for sentence in relevant[:3]:\n",
        "#                     st.write(f\"• {sentence}\")\n",
        "#             else:\n",
        "#                 st.warning(\"No relevant content found.\")\n",
        "\n",
        "#     elif page == \"Proposal Assistant\":\n",
        "#         st.header(\"✍️ Proposal Assistant\")\n",
        "\n",
        "#         if 'selected_rfp' not in st.session_state:\n",
        "#             st.warning(\"Select an RFP first.\")\n",
        "#             return\n",
        "\n",
        "#         rfp = st.session_state.selected_rfp\n",
        "#         st.subheader(f\"📝 Proposal for: {rfp['title']}\")\n",
        "\n",
        "#         if st.button(\"Generate Outline\", type=\"primary\"):\n",
        "#             outline = platform.generate_proposal_outline(rfp)\n",
        "#             st.session_state.proposal_outline = outline\n",
        "\n",
        "#         if 'proposal_outline' in st.session_state:\n",
        "#             st.subheader(\"📋 Proposal Outline\")\n",
        "#             outline = st.session_state.proposal_outline\n",
        "\n",
        "#             for section, details in outline.items():\n",
        "#                 with st.expander(f\"📄 {section}\"):\n",
        "#                     st.write(f\"**Description:** {details['description']}\")\n",
        "#                     st.write(f\"**Content:** {details['suggested_content']}\")\n",
        "\n",
        "#                     if st.button(f\"Generate Content\", key=f\"gen_{section}\"):\n",
        "#                         sample_content = f\"\"\"\n",
        "# **{section} - Draft Content:**\n",
        "\n",
        "# This section addresses the {section.lower()} requirements. A3 Consulting brings\n",
        "# extensive experience in delivering similar solutions for federal agencies.\n",
        "\n",
        "# Key points:\n",
        "# - Understanding of client needs\n",
        "# - Proven methodology\n",
        "# - Risk mitigation strategies\n",
        "# - Quality assurance\n",
        "\n",
        "# [AI-generated content would be more specific and tailored to RFP requirements]\n",
        "# \"\"\"\n",
        "#                         st.text_area(\"Generated Content:\", sample_content, height=200, key=f\"content_{section}\")\n",
        "\n",
        "#         # Similar Responses\n",
        "#         st.subheader(\"🔍 Find Similar Responses\")\n",
        "#         search_query = st.text_input(\"Search past responses:\")\n",
        "#         if search_query and st.button(\"Search\"):\n",
        "#             results = platform.search_similar_responses(search_query)\n",
        "#             if results:\n",
        "#                 for result in results:\n",
        "#                     with st.expander(f\"{result['type']}: {result['document'].get('filename', 'Unknown')}\"):\n",
        "#                         st.text(result['document']['text'][:500] + \"...\")\n",
        "#             else:\n",
        "#                 st.warning(\"No similar responses found.\")\n",
        "\n",
        "#     elif page == \"Knowledge Search\":\n",
        "#         st.header(\"🔍 Knowledge Search\")\n",
        "\n",
        "#         if not platform.response_data:\n",
        "#             st.warning(\"No response documents loaded.\")\n",
        "#             return\n",
        "\n",
        "#         st.subheader(\"🧠 Search Knowledge Base\")\n",
        "#         search_query = st.text_input(\"Search query:\")\n",
        "#         search_type = st.radio(\"Search Type:\", [\"Semantic Search\", \"Keyword Search\"])\n",
        "\n",
        "#         if search_query and st.button(\"Search\"):\n",
        "#             if search_type == \"Semantic Search\" and platform.embedder:\n",
        "#                 results = platform.search_similar_responses(search_query)\n",
        "#             else:\n",
        "#                 results = []\n",
        "#                 for i, doc in enumerate(platform.response_data):\n",
        "#                     if search_query.lower() in doc['text'].lower():\n",
        "#                         results.append({\n",
        "#                             'type': 'Response',\n",
        "#                             'document': doc,\n",
        "#                             'similarity_score': 1.0,\n",
        "#                             'rank': i + 1\n",
        "#                         })\n",
        "\n",
        "#             if results:\n",
        "#                 st.success(f\"Found {len(results)} documents:\")\n",
        "#                 for result in results:\n",
        "#                     with st.expander(f\"📄 {result['document']['filename']}\"):\n",
        "#                         st.text(result['document']['text'][:800] + \"...\")\n",
        "#             else:\n",
        "#                 st.warning(\"No documents found.\")\n",
        "\n",
        "#         # Statistics\n",
        "#         st.subheader(\"📊 Knowledge Base Stats\")\n",
        "#         col1, col2, col3 = st.columns(3)\n",
        "#         with col1:\n",
        "#             st.metric(\"Documents\", len(platform.response_data))\n",
        "#         with col2:\n",
        "#             total_words = sum(len(doc['text'].split()) for doc in platform.response_data)\n",
        "#             st.metric(\"Total Words\", f\"{total_words:,}\")\n",
        "#         with col3:\n",
        "#             avg_length = total_words // len(platform.response_data) if platform.response_data else 0\n",
        "#             st.metric(\"Avg Length\", f\"{avg_length:,} words\")\n",
        "\n",
        "#     elif page == \"Analytics\":\n",
        "#         st.header(\"📈 Analytics Dashboard\")\n",
        "\n",
        "#         analysis = platform.analyze_win_loss_patterns()\n",
        "\n",
        "#         col1, col2 = st.columns(2)\n",
        "\n",
        "#         with col1:\n",
        "#             st.subheader(\"🎯 Performance\")\n",
        "#             try:\n",
        "#                 fig = go.Figure(go.Indicator(\n",
        "#                     mode = \"gauge+number\",\n",
        "#                     value = analysis['overall_win_rate'] * 100,\n",
        "#                     title = {'text': \"Win Rate (%)\"},\n",
        "#                     gauge = {\n",
        "#                         'axis': {'range': [None, 100]},\n",
        "#                         'bar': {'color': \"darkblue\"},\n",
        "#                         'steps': [\n",
        "#                             {'range': [0, 50], 'color': \"lightgray\"},\n",
        "#                             {'range': [50, 100], 'color': \"green\"}\n",
        "#                         ]\n",
        "#                     }\n",
        "#                 ))\n",
        "#                 fig.update_layout(height=300)\n",
        "#                 st.plotly_chart(fig, use_container_width=True)\n",
        "#             except:\n",
        "#                 st.metric(\"Win Rate\", f\"{analysis['overall_win_rate']*100:.1f}%\")\n",
        "\n",
        "#             st.metric(\"Avg Proposal Time\", f\"{analysis['avg_proposal_time']} days\")\n",
        "\n",
        "#         with col2:\n",
        "#             st.subheader(\"🏛️ Win Rate by Agency\")\n",
        "#             try:\n",
        "#                 agencies = list(analysis['win_rate_by_agency'].keys())\n",
        "#                 rates = [r * 100 for r in analysis['win_rate_by_agency'].values()]\n",
        "#                 fig = px.bar(x=agencies, y=rates, title=\"Win Rate by Agency (%)\")\n",
        "#                 st.plotly_chart(fig, use_container_width=True)\n",
        "#             except:\n",
        "#                 agency_df = pd.DataFrame({\n",
        "#                     'Agency': list(analysis['win_rate_by_agency'].keys()),\n",
        "#                     'Win Rate': [f\"{r*100:.1f}%\" for r in analysis['win_rate_by_agency'].values()]\n",
        "#                 })\n",
        "#                 st.dataframe(agency_df)\n",
        "\n",
        "#         # Success factors\n",
        "#         col1, col2 = st.columns(2)\n",
        "#         with col1:\n",
        "#             st.subheader(\"✅ Success Factors\")\n",
        "#             for factor in analysis['success_factors']:\n",
        "#                 st.write(f\"• {factor}\")\n",
        "#         with col2:\n",
        "#             st.subheader(\"🎯 Improvement Areas\")\n",
        "#             for area in analysis['improvement_areas']:\n",
        "#                 st.write(f\"• {area}\")\n",
        "\n",
        "#         # RFP trends\n",
        "#         if platform.rfp_data:\n",
        "#             st.subheader(\"📊 RFP Trends\")\n",
        "\n",
        "#             # Agency distribution\n",
        "#             agency_counts = {}\n",
        "#             for rfp in platform.rfp_data:\n",
        "#                 agency = rfp['agency']\n",
        "#                 agency_counts[agency] = agency_counts.get(agency, 0) + 1\n",
        "\n",
        "#             if agency_counts:\n",
        "#                 try:\n",
        "#                     fig = px.pie(values=list(agency_counts.values()),\n",
        "#                                names=list(agency_counts.keys()), title=\"RFPs by Agency\")\n",
        "#                     st.plotly_chart(fig, use_container_width=True)\n",
        "#                 except:\n",
        "#                     st.dataframe(pd.DataFrame({\n",
        "#                         'Agency': list(agency_counts.keys()),\n",
        "#                         'Count': list(agency_counts.values())\n",
        "#                     }))\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     main()\n",
        "# '''\n",
        "\n",
        "# # Write the app file\n",
        "# with open('/content/rfp_app.py', 'w') as f:\n",
        "#     f.write(app_content)\n",
        "\n",
        "# print(\"✅ Main application file created at /content/rfp_app.py\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0A2ELDoPzvca",
        "outputId": "bb906a51-58b6-4441-e9f5-6eda03a4a5bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Creating main application file...\n",
            "✅ Main application file created at /content/rfp_app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# # ===== STEP 5: Create the Main Application File =====\n",
        "# print(\"\\nCreating main application file...\")\n",
        "\n",
        "# app_content = '''# RFP Proposal Intelligence Platform - Improved Version\n",
        "\n",
        "# import streamlit as st\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import os\n",
        "# import json\n",
        "# from datetime import datetime, timedelta\n",
        "# import re\n",
        "# from typing import List, Dict, Any, Optional\n",
        "# import logging\n",
        "# import google.generativeai as genai\n",
        "\n",
        "# # Document processing\n",
        "# try:\n",
        "#     import PyPDF2\n",
        "#     import docx\n",
        "# except ImportError:\n",
        "#     st.error(\"Please install: !pip install PyPDF2 python-docx\")\n",
        "\n",
        "# # ML components\n",
        "# try:\n",
        "#     from sentence_transformers import SentenceTransformer\n",
        "#     import faiss\n",
        "#     from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "#     from sklearn.metrics.pairwise import cosine_similarity\n",
        "# except ImportError:\n",
        "#     st.error(\"Please install: !pip install sentence-transformers faiss-cpu scikit-learn\")\n",
        "\n",
        "# # Visualization\n",
        "# try:\n",
        "#     import plotly.express as px\n",
        "#     import plotly.graph_objects as go\n",
        "# except ImportError:\n",
        "#     st.error(\"Please install: !pip install plotly\")\n",
        "\n",
        "# logging.basicConfig(level=logging.INFO)\n",
        "# logger = logging.getLogger(__name__)\n",
        "\n",
        "# class RFPPlatform:\n",
        "#     def __init__(self, drive_path=\"/content/drive/Shared drives/Leadership/rfp app\"):\n",
        "#         self.drive_path = drive_path\n",
        "#         self.rfps_path = os.path.join(drive_path, \"RFP\")  # Changed to \"RFP\" to match your setup\n",
        "#         self.responses_path = os.path.join(drive_path, \"Responses\")  # Changed to \"Responses\"\n",
        "\n",
        "#         try:\n",
        "#             self.embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "#             self.vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
        "#         except Exception as e:\n",
        "#             st.warning(f\"AI components not loaded: {e}\")\n",
        "#             self.embedder = None\n",
        "#             self.vectorizer = None\n",
        "\n",
        "#         self.rfp_data = []\n",
        "#         self.response_data = []\n",
        "#         self.embeddings = None\n",
        "#         self.index = None\n",
        "#         self.rfp_embeddings = None\n",
        "#         self.response_embeddings = None\n",
        "\n",
        "#         # Initialize Gemini\n",
        "#         try:\n",
        "#             from google.colab import userdata\n",
        "#             api_key = userdata.get('GEMINI_API_KEY')\n",
        "#             if api_key:\n",
        "#                 genai.configure(api_key=api_key)\n",
        "#                 self.model = genai.GenerativeModel('gemini-pro')\n",
        "#             else:\n",
        "#                 self.model = None\n",
        "#         except Exception as e:\n",
        "#             self.model = None\n",
        "#             st.warning(\"Gemini API not configured\")\n",
        "\n",
        "#         # Default company profile\n",
        "#         self.default_company_profile = {\n",
        "#             \"name\": \"A3 Consulting LLC\",\n",
        "#             \"naics_codes\": [\"541511\", \"541512\", \"541519\", \"541611\"],\n",
        "#             \"capabilities\": [\n",
        "#                 \"Management Consulting\", \"IT Consulting\", \"Strategic Planning\",\n",
        "#                 \"Process Improvement\", \"Data Analytics\", \"Project Management\",\n",
        "#                 \"Cybersecurity Consulting\", \"Digital Transformation\"\n",
        "#             ],\n",
        "#             \"certifications\": [\"ISO 9001\", \"CMMI Level 3\", \"FedRAMP\"],\n",
        "#             \"socioeconomic\": [\"Small Business\"],\n",
        "#             \"past_performance_keywords\": [\n",
        "#                 \"government consulting\", \"strategic planning\", \"process optimization\",\n",
        "#                 \"data analysis\", \"cloud migration\", \"cybersecurity\", \"IT modernization\"\n",
        "#             ]\n",
        "#         }\n",
        "\n",
        "#         # Load company profile from session state or use default\n",
        "#         if 'company_profile' not in st.session_state:\n",
        "#             st.session_state.company_profile = self.default_company_profile.copy()\n",
        "\n",
        "#         self.company_profile = st.session_state.company_profile\n",
        "\n",
        "#         self.setup_directories()\n",
        "\n",
        "#     def setup_directories(self):\n",
        "#         try:\n",
        "#             os.makedirs(self.rfps_path, exist_ok=True)\n",
        "#             os.makedirs(self.responses_path, exist_ok=True)\n",
        "#         except Exception as e:\n",
        "#             st.error(f\"Error creating directories: {e}\")\n",
        "\n",
        "#     def extract_text_from_pdf(self, file_path):\n",
        "#         try:\n",
        "#             with open(file_path, 'rb') as file:\n",
        "#                 pdf_reader = PyPDF2.PdfReader(file)\n",
        "#                 text = \"\"\n",
        "#                 for page in pdf_reader.pages:\n",
        "#                     text += page.extract_text() + \"\\\\n\" # Fixed: Escape the backslash\n",
        "#                 return text\n",
        "#         except Exception as e:\n",
        "#             logger.error(f\"Error extracting PDF text: {e}\")\n",
        "#             return \"\"\n",
        "\n",
        "#     def extract_text_from_docx(self, file_path):\n",
        "#         try:\n",
        "#             doc = docx.Document(file_path)\n",
        "#             text = \"\"\n",
        "#             for paragraph in doc.paragraphs:\n",
        "#                 text += paragraph.text + \"\\\\n\" # Fixed: Escape the backslash\n",
        "#             return text\n",
        "#         except Exception as e:\n",
        "#             logger.error(f\"Error extracting DOCX text: {e}\")\n",
        "#             return \"\"\n",
        "\n",
        "#     def load_documents(self):\n",
        "#         st.info(\"Loading documents...\")\n",
        "\n",
        "#         if not os.path.exists(self.drive_path):\n",
        "#             st.error(f\"Drive path not found: {self.drive_path}\")\n",
        "#             return\n",
        "\n",
        "#         # Load RFPs - FIXED: Better file discovery\n",
        "#         rfp_files = []\n",
        "#         if os.path.exists(self.rfps_path):\n",
        "#             for root, dirs, files in os.walk(self.rfps_path):\n",
        "#                 for file in files:\n",
        "#                     if file.endswith(('.pdf', '.docx', '.txt')) and not file.startswith('.'):\n",
        "#                         rfp_files.append(os.path.join(root, file))\n",
        "\n",
        "#         # Load responses - FIXED: Better file discovery\n",
        "#         response_files = []\n",
        "#         if os.path.exists(self.responses_path):\n",
        "#             for root, dirs, files in os.walk(self.responses_path):\n",
        "#                 for file in files:\n",
        "#                     if file.endswith(('.pdf', '.docx', '.txt')) and not file.startswith('.'):\n",
        "#                         response_files.append(os.path.join(root, file))\n",
        "\n",
        "#         # Process RFPs\n",
        "#         self.rfp_data = []\n",
        "#         for file_path in rfp_files:\n",
        "#             try:\n",
        "#                 file = os.path.basename(file_path)\n",
        "\n",
        "#                 if file.endswith('.pdf'):\n",
        "#                     text = self.extract_text_from_pdf(file_path)\n",
        "#                 elif file.endswith('.docx'):\n",
        "#                     text = self.extract_text_from_docx(file_path)\n",
        "#                 else:\n",
        "#                     with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
        "#                         text = f.read()\n",
        "\n",
        "#                 if text.strip():  # Only process non-empty files\n",
        "#                     rfp_info = self.parse_rfp_metadata(text, file)\n",
        "#                     rfp_info['file_path'] = file_path\n",
        "#                     rfp_info['text'] = text\n",
        "#                     self.rfp_data.append(rfp_info)\n",
        "#                     logger.info(f\"Loaded RFP: {file}\")\n",
        "#                 else:\n",
        "#                     logger.warning(f\"Empty file skipped: {file}\")\n",
        "\n",
        "#             except Exception as e:\n",
        "#                 st.warning(f\"Error processing {file}: {e}\")\n",
        "#                 logger.error(f\"Error processing {file}: {e}\")\n",
        "\n",
        "#         # Process responses\n",
        "#         self.response_data = []\n",
        "#         for file_path in response_files:\n",
        "#             try:\n",
        "#                 file = os.path.basename(file_path)\n",
        "\n",
        "#                 if file.endswith('.pdf'):\n",
        "#                     text = self.extract_text_from_pdf(file_path)\n",
        "#                 elif file.endswith('.docx'):\n",
        "#                     text = self.extract_text_from_docx(file_path)\n",
        "#                 else:\n",
        "#                     with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
        "#                         text = f.read()\n",
        "\n",
        "#                 if text.strip():  # Only process non-empty files\n",
        "#                     response_info = {\n",
        "#                         'filename': file,\n",
        "#                         'text': text,\n",
        "#                         'file_path': file_path,\n",
        "#                         'date_created': datetime.now()\n",
        "#                     }\n",
        "#                     self.response_data.append(response_info)\n",
        "#                     logger.info(f\"Loaded Response: {file}\")\n",
        "#                 else:\n",
        "#                     logger.warning(f\"Empty file skipped: {file}\")\n",
        "\n",
        "#             except Exception as e:\n",
        "#                 st.warning(f\"Error processing {file}: {e}\")\n",
        "#                 logger.error(f\"Error processing {file}: {e}\")\n",
        "\n",
        "#         st.success(f\"Loaded {len(self.rfp_data)} RFPs and {len(self.response_data)} responses\")\n",
        "\n",
        "#     def parse_rfp_metadata(self, text, filename):\n",
        "#         return {\n",
        "#             'title': filename.replace('.pdf', '').replace('.docx', '').replace('.txt', ''),\n",
        "#             'filename': filename,\n",
        "#             'agency': self.extract_agency(text),\n",
        "#             'due_date': self.extract_due_date(text),\n",
        "#             'naics_codes': self.extract_naics_codes(text),\n",
        "#             'contract_value': self.extract_contract_value(text),\n",
        "#             'requirements': self.extract_requirements(text),\n",
        "#             'evaluation_criteria': self.extract_evaluation_criteria(text),\n",
        "#             'date_loaded': datetime.now()\n",
        "#         }\n",
        "\n",
        "#     def extract_agency(self, text):\n",
        "#         agencies = ['DHS', 'DOD', 'GSA', 'VA', 'HHS', 'DOE', 'NASA', 'USDA',\n",
        "#                    'Department of Homeland Security', 'General Services Administration']\n",
        "#         text_upper = text.upper()\n",
        "#         for agency in agencies:\n",
        "#             if agency.upper() in text_upper:\n",
        "#                 if 'HOMELAND SECURITY' in agency.upper():\n",
        "#                     return 'DHS'\n",
        "#                 elif 'GENERAL SERVICES' in agency.upper():\n",
        "#                     return 'GSA'\n",
        "#                 else:\n",
        "#                     return agency\n",
        "#         return \"Unknown\"\n",
        "\n",
        "#     def extract_due_date(self, text):\n",
        "#         import re\n",
        "#         date_patterns = [\n",
        "#             r'\\\\b\\\\d{1,2}/\\\\d{1,2}/\\\\d{4}\\\\b',\n",
        "#             r'\\\\b\\\\d{1,2}-\\\\d{1,2}-\\\\d{4}\\\\b',\n",
        "#             r'\\\\b\\\\w+ \\\\d{1,2}, \\\\d{4}\\\\b'\n",
        "#         ]\n",
        "\n",
        "#         for pattern in date_patterns:\n",
        "#             matches = re.findall(pattern, text)\n",
        "#             if matches:\n",
        "#                 return matches[0]\n",
        "#         return \"Not found\"\n",
        "\n",
        "#     def extract_naics_codes(self, text):\n",
        "#         import re\n",
        "#         naics_pattern = r'\\\\b\\\\d{6}\\\\b'\n",
        "#         codes = re.findall(naics_pattern, text)\n",
        "#         return codes[:5]\n",
        "\n",
        "#     def extract_contract_value(self, text):\n",
        "#         import re\n",
        "#         value_patterns = [\n",
        "#             r'\\\\$[\\\\d,]+(?:\\\\.\\\\d{2})?',\n",
        "#             r'[\\\\d,]+ dollars?'\n",
        "#         ]\n",
        "\n",
        "#         for pattern in value_patterns:\n",
        "#             matches = re.findall(pattern, text, re.IGNORECASE)\n",
        "#             if matches:\n",
        "#                 return matches[0]\n",
        "#         return \"Not specified\"\n",
        "\n",
        "#     def extract_requirements(self, text):\n",
        "#         req_keywords = ['requirement', 'shall', 'must', 'mandatory', 'criteria']\n",
        "#         sentences = text.split('.')\n",
        "#         requirements = []\n",
        "\n",
        "#         for sentence in sentences:\n",
        "#             sentence_lower = sentence.lower()\n",
        "#             if any(keyword in sentence_lower for keyword in req_keywords):\n",
        "#                 if len(sentence.strip()) > 20:\n",
        "#                     requirements.append(sentence.strip())\n",
        "\n",
        "#         return requirements[:10]\n",
        "\n",
        "#     def extract_evaluation_criteria(self, text):\n",
        "#         criteria_keywords = ['evaluation', 'scoring', 'points', 'weight', 'factor']\n",
        "#         sentences = text.split('.')\n",
        "#         criteria = []\n",
        "\n",
        "#         for sentence in sentences:\n",
        "#             sentence_lower = sentence.lower()\n",
        "#             if any(keyword in sentence_lower for keyword in criteria_keywords):\n",
        "#                 if len(sentence.strip()) > 20:\n",
        "#                     criteria.append(sentence.strip())\n",
        "\n",
        "#         return criteria[:5]\n",
        "\n",
        "#     def build_embeddings(self):\n",
        "#         if not self.embedder:\n",
        "#             st.warning(\"Embedder not available\")\n",
        "#             return\n",
        "\n",
        "#         try:\n",
        "#             # Build separate embeddings for RFPs and responses\n",
        "#             if self.rfp_data:\n",
        "#                 rfp_texts = [rfp['text'] for rfp in self.rfp_data]\n",
        "#                 self.rfp_embeddings = self.embedder.encode(rfp_texts)\n",
        "\n",
        "#             if self.response_data:\n",
        "#                 response_texts = [response['text'] for response in self.response_data]\n",
        "#                 self.response_embeddings = self.embedder.encode(response_texts)\n",
        "\n",
        "#             # Build combined embeddings for general search\n",
        "#             all_texts = []\n",
        "#             if self.rfp_data:\n",
        "#                 all_texts.extend([rfp['text'] for rfp in self.rfp_data])\n",
        "#             if self.response_data:\n",
        "#                 all_texts.extend([response['text'] for response in self.response_data])\n",
        "\n",
        "#             if all_texts:\n",
        "#                 self.embeddings = self.embedder.encode(all_texts)\n",
        "#                 dimension = self.embeddings.shape[1]\n",
        "#                 self.index = faiss.IndexFlatIP(dimension)\n",
        "#                 self.index.add(self.embeddings.astype('float32'))\n",
        "#                 st.success(f\"Built embeddings for {len(all_texts)} documents\")\n",
        "\n",
        "#         except Exception as e:\n",
        "#             st.error(f\"Error building embeddings: {e}\")\n",
        "#             logger.error(f\"Error building embeddings: {e}\")\n",
        "\n",
        "#     def calculate_opportunity_fit(self, rfp_info):\n",
        "#         score = 0\n",
        "\n",
        "#         # NAICS code match (30 points)\n",
        "#         naics_match = any(code in self.company_profile['naics_codes']\n",
        "#                          for code in rfp_info['naics_codes'])\n",
        "#         if naics_match:\n",
        "#             score += 30\n",
        "\n",
        "#         # Capability keywords match (40 points)\n",
        "#         text_lower = rfp_info['text'].lower()\n",
        "#         capability_matches = sum(1 for cap in self.company_profile['capabilities']\n",
        "#                                if cap.lower() in text_lower)\n",
        "#         score += min(40, capability_matches * 8)\n",
        "\n",
        "#         # Past performance keywords (30 points)\n",
        "#         pp_matches = sum(1 for keyword in self.company_profile['past_performance_keywords']\n",
        "#                         if keyword in text_lower)\n",
        "#         score += min(30, pp_matches * 10)\n",
        "\n",
        "#         return min(score, 100)\n",
        "\n",
        "#     def generate_compliance_matrix(self, rfp_info):\n",
        "#         requirements = rfp_info['requirements']\n",
        "#         matrix = []\n",
        "\n",
        "#         for i, req in enumerate(requirements):\n",
        "#             compliant = any(cap.lower() in req.lower()\n",
        "#                           for cap in self.company_profile['capabilities'])\n",
        "\n",
        "#             matrix.append({\n",
        "#                 'requirement': req[:100] + \"...\" if len(req) > 100 else req,\n",
        "#                 'compliant': 'Yes' if compliant else 'Needs Review',\n",
        "#                 'response_section': f\"Section {i+1}\"\n",
        "#             })\n",
        "\n",
        "#         return matrix\n",
        "\n",
        "#     def search_similar_responses_improved(self, query, top_k=5):\n",
        "#         \"\"\"Improved semantic search using embeddings\"\"\"\n",
        "#         if not self.response_embeddings is not None or not self.embedder:\n",
        "#             return []\n",
        "\n",
        "#         try:\n",
        "#             query_embedding = self.embedder.encode([query])\n",
        "\n",
        "#             # Calculate cosine similarity\n",
        "#             similarities = cosine_similarity(query_embedding, self.response_embeddings)[0]\n",
        "\n",
        "#             # Get top k results\n",
        "#             top_indices = np.argsort(similarities)[::-1][:top_k]\n",
        "\n",
        "#             results = []\n",
        "#             for i, idx in enumerate(top_indices):\n",
        "#                 if similarities[idx] > 0.1:  # Threshold for relevance\n",
        "#                     results.append({\n",
        "#                         'type': \"Response\",\n",
        "#                         'document': self.response_data[idx],\n",
        "#                         'similarity_score': float(similarities[idx]),\n",
        "#                         'rank': i + 1\n",
        "#                     })\n",
        "\n",
        "#             return results\n",
        "#         except Exception as e:\n",
        "#             logger.error(f\"Error in semantic search: {e}\")\n",
        "#             return []\n",
        "\n",
        "#     def get_all_responses_with_scores(self, rfp_text):\n",
        "#         \"\"\"Get all responses with similarity scores to RFP\"\"\"\n",
        "#         if not self.response_embeddings is not None or not self.embedder:\n",
        "#             return []\n",
        "\n",
        "#         try:\n",
        "#             rfp_embedding = self.embedder.encode([rfp_text])\n",
        "#             similarities = cosine_similarity(rfp_embedding, self.response_embeddings)[0]\n",
        "\n",
        "#             results = []\n",
        "#             for idx, score in enumerate(similarities):\n",
        "#                 results.append({\n",
        "#                     'document': self.response_data[idx],\n",
        "#                     'similarity_score': float(score),\n",
        "#                     'filename': self.response_data[idx]['filename']\n",
        "#                 })\n",
        "\n",
        "#             # Sort by similarity score\n",
        "#             results.sort(key=lambda x: x['similarity_score'], reverse=True)\n",
        "#             return results\n",
        "\n",
        "#         except Exception as e:\n",
        "#             logger.error(f\"Error getting response scores: {e}\")\n",
        "#             return []\n",
        "\n",
        "#     def ask_gemini_about_rfp(self, question, rfp_info):\n",
        "#         \"\"\"Use Gemini to answer questions about RFP\"\"\"\n",
        "#         if not self.model:\n",
        "#             return \"Gemini API not configured. Please add GEMINI_API_KEY to Colab secrets.\"\n",
        "\n",
        "#         try:\n",
        "#             prompt = f\"\"\"\n",
        "#             You are an expert RFP analyst helping A3 Consulting LLC understand an RFP.\n",
        "\n",
        "#             RFP Title: {rfp_info['title']}\n",
        "#             Agency: {rfp_info['agency']}\n",
        "\n",
        "#             RFP Content:\n",
        "#             {rfp_info['text'][:4000]}  # Limit content to avoid token limits\n",
        "\n",
        "#             Company Profile:\n",
        "#             - Name: {self.company_profile['name']}\n",
        "#             - Capabilities: {', '.join(self.company_profile['capabilities'])}\n",
        "#             - NAICS Codes: {', '.join(self.company_profile['naics_codes'])}\n",
        "\n",
        "#             Question: {question}\n",
        "\n",
        "#             Please provide a helpful, specific answer based on the RFP content and how it relates to A3 Consulting's capabilities.\n",
        "#             \"\"\"\n",
        "\n",
        "#             response = self.model.generate_content(prompt)\n",
        "#             return response.text\n",
        "\n",
        "#         except Exception as e:\n",
        "#             return f\"Error getting AI response: {e}\"\n",
        "\n",
        "#     def generate_content_with_gemini(self, section, rfp_info):\n",
        "#         \"\"\"Generate proposal content using Gemini and similar responses\"\"\"\n",
        "#         if not self.model:\n",
        "#             return \"Gemini API not configured. Please add GEMINI_API_KEY to Colab secrets.\"\n",
        "\n",
        "#         try:\n",
        "#             # Get similar responses for context\n",
        "#             similar_responses = self.get_all_responses_with_scores(rfp_info['text'])[:3]\n",
        "#             context = \"\"\n",
        "\n",
        "#             for resp in similar_responses:\n",
        "#                 context += f\"\\n--- Similar Response Example ---\\\\n{resp['document']['text'][:1000]}...\\\\n\" # Fixed: Escape backslashes\n",
        "\n",
        "#             prompt = \"\"\n",
        "#             You are writing a {section} section for A3 Consulting LLC's proposal response.\n",
        "\n",
        "#             RFP Details:\n",
        "#             - Title: {rfp_info['title']}\n",
        "#             - Agency: {rfp_info['agency']}\n",
        "#             - Requirements: {rfp_info['requirements'][:3]}  # Top 3 requirements\n",
        "\n",
        "#             Company Profile:\n",
        "#             - Name: {self.company_profile['name']}\n",
        "#             - Capabilities: {', '.join(self.company_profile['capabilities'])}\n",
        "#             - Certifications: {', '.join(self.company_profile['certifications'])}\n",
        "\n",
        "#             Context from Similar Past Responses:\n",
        "#             {context}\n",
        "\n",
        "#             Please write a professional {section} section that:\n",
        "#             1. Addresses the RFP requirements\n",
        "#             2. Highlights A3 Consulting's relevant capabilities\n",
        "#             3. Uses a similar tone and structure to the example responses\n",
        "#             4. Is specific and compelling\n",
        "\n",
        "#             Write 3-4 paragraphs for this section.\n",
        "#             \"\"\"\n",
        "\n",
        "#             response = self.model.generate_content(prompt)\n",
        "#             return response.text\n",
        "\n",
        "#         except Exception as e:\n",
        "#             return f\"Error generating content: {e}\"\n",
        "\n",
        "#     def generate_proposal_outline(self, rfp_info):\n",
        "#         outline = {\n",
        "#             \"Executive Summary\": {\n",
        "#                 \"description\": \"Overview of our approach and key win themes\",\n",
        "#                 \"suggested_content\": \"Highlight A3's unique qualifications\"\n",
        "#             },\n",
        "#             \"Technical Approach\": {\n",
        "#                 \"description\": \"Detailed methodology and approach\",\n",
        "#                 \"suggested_content\": \"Address each technical requirement\"\n",
        "#             },\n",
        "#             \"Management Plan\": {\n",
        "#                 \"description\": \"Project management and organization\",\n",
        "#                 \"suggested_content\": \"Show project structure and timeline\"\n",
        "#             },\n",
        "#             \"Past Performance\": {\n",
        "#                 \"description\": \"Relevant experience and references\",\n",
        "#                 \"suggested_content\": \"Include similar projects\"\n",
        "#             }\n",
        "#         }\n",
        "\n",
        "#         requirements = rfp_info['requirements']\n",
        "#         custom_sections = []\n",
        "\n",
        "#         for req in requirements:\n",
        "#             if 'security' in req.lower():\n",
        "#                 custom_sections.append(\"Security Approach\")\n",
        "#             elif 'quality' in req.lower():\n",
        "#                 custom_sections.append(\"Quality Assurance\")\n",
        "\n",
        "#         for section in set(custom_sections):\n",
        "#             outline[section] = {\n",
        "#                 \"description\": f\"Address {section.lower()} requirements\",\n",
        "#                 \"suggested_content\": f\"Detail our {section.lower()} approach\"\n",
        "#             }\n",
        "\n",
        "#         return outline\n",
        "\n",
        "#     def analyze_win_loss_patterns(self):\n",
        "#         return {\n",
        "#             'overall_win_rate': 0.45,\n",
        "#             'win_rate_by_agency': {'DHS': 0.6, 'GSA': 0.4, 'DOD': 0.5, 'VA': 0.3},\n",
        "#             'avg_proposal_time': 25,\n",
        "#             'success_factors': [\n",
        "#                 'Strong past performance alignment',\n",
        "#                 'Competitive pricing',\n",
        "#                 'Clear technical approach'\n",
        "#             ],\n",
        "#             'improvement_areas': [\n",
        "#                 'Faster response time',\n",
        "#                 'Better capture intelligence'\n",
        "#             ]\n",
        "#         }\n",
        "\n",
        "# def display_company_profile():\n",
        "#     \"\"\"Display and edit company profile\"\"\"\n",
        "#     st.subheader(\"🏢 Company Profile\")\n",
        "\n",
        "#     if 'edit_profile' not in st.session_state:\n",
        "#         st.session_state.edit_profile = False\n",
        "\n",
        "#     col1, col2 = st.columns([3, 1])\n",
        "\n",
        "#     with col2:\n",
        "#         if st.button(\"✏️ Edit Profile\" if not st.session_state.edit_profile else \"💾 Save Profile\"):\n",
        "#             st.session_state.edit_profile = not st.session_state.edit_profile\n",
        "#             if not st.session_state.edit_profile:\n",
        "#                 st.success(\"Profile saved!\")\n",
        "\n",
        "#     with col1:\n",
        "#         if st.session_state.edit_profile:\n",
        "#             # Edit mode\n",
        "#             st.session_state.company_profile['name'] = st.text_input(\n",
        "#                 \"Company Name\", st.session_state.company_profile['name'])\n",
        "\n",
        "#             st.session_state.company_profile['naics_codes'] = st.text_area(\n",
        "#                 \"NAICS Codes (comma-separated)\",\n",
        "#                 ', '.join(st.session_state.company_profile['naics_codes'])).split(', ')\n",
        "\n",
        "#             st.session_state.company_profile['capabilities'] = st.text_area(\n",
        "#                 \"Capabilities (comma-separated)\",\n",
        "#                 ', '.join(st.session_state.company_profile['capabilities'])).split(', ')\n",
        "\n",
        "#             st.session_state.company_profile['certifications'] = st.text_area(\n",
        "#                 \"Certifications (comma-separated)\",\n",
        "#                 ', '.join(st.session_state.company_profile['certifications'])).split(', ')\n",
        "\n",
        "#         else:\n",
        "#             # Display mode\n",
        "#             profile = st.session_state.company_profile\n",
        "#             st.write(f\"**Company:** {profile['name']}\")\n",
        "#             st.write(f\"**NAICS Codes:** {', '.join(profile['naics_codes'])}\")\n",
        "#             st.write(f\"**Capabilities:** {', '.join(profile['capabilities'])}\")\n",
        "#             st.write(f\"**Certifications:** {', '.join(profile['certifications'])}\")\n",
        "\n",
        "# def create_sample_data():\n",
        "#     sample_rfps = [\n",
        "#         {\n",
        "#             'title': 'IT_Modernization_Services',\n",
        "#             'filename': 'DHS_IT_Modernization_RFP.txt',\n",
        "#             'agency': 'DHS',\n",
        "#             'due_date': '2024-08-15',\n",
        "#             'naics_codes': ['541511', '541512'],\n",
        "#             'contract_value': '$2,500,000',\n",
        "#             'text': 'Department of Homeland Security requires IT modernization including cloud migration, cybersecurity assessment, and system integration. Must have quality assurance processes.',\n",
        "#             'requirements': [\n",
        "#                 'Must have federal cloud migration experience',\n",
        "#                 'Shall provide 24/7 technical support',\n",
        "#                 'Must maintain FedRAMP compliance'\n",
        "#             ],\n",
        "#             'evaluation_criteria': [\n",
        "#                 'Technical approach weighted 40%',\n",
        "#                 'Past performance weighted 30%'\n",
        "#             ],\n",
        "#             'date_loaded': datetime.now()\n",
        "#         }\n",
        "#     ]\n",
        "\n",
        "#     sample_responses = [\n",
        "#         {\n",
        "#             'filename': 'A3_IT_Modernization_Response.txt',\n",
        "#             'text': 'A3 Consulting has extensive federal IT modernization experience with 15+ successful cloud migrations. Our quality assurance processes ensure reliable delivery.',\n",
        "#             'date_created': datetime.now()\n",
        "#         }\n",
        "#     ]\n",
        "\n",
        "#     return sample_rfps, sample_responses\n",
        "\n",
        "# def setup_sample_environment():\n",
        "#     st.info(\"Setting up sample environment...\")\n",
        "#     sample_rfps, sample_responses = create_sample_data()\n",
        "\n",
        "#     platform = RFPPlatform()\n",
        "#     platform.rfp_data = sample_rfps\n",
        "#     platform.response_data = sample_responses\n",
        "\n",
        "#     try:\n",
        "#         platform.build_embeddings()\n",
        "#     except Exception as e:\n",
        "#         st.warning(f\"Could not build embeddings: {e}\")\n",
        "\n",
        "#     st.session_state.platform = platform\n",
        "#     st.success(\"Sample environment ready!\")\n",
        "#     return platform\n",
        "\n",
        "# def main():\n",
        "#     st.set_page_config(\n",
        "#         page_title=\"RFP Intelligence Platform\",\n",
        "#         page_icon=\"📄\",\n",
        "#         layout=\"wide\"\n",
        "#     )\n",
        "\n",
        "#     st.title(\"🚀 RFP Proposal Intelligence Platform\")\n",
        "#     st.markdown(\"### AI-Powered Proposal Development for A3 Consulting LLC\")\n",
        "\n",
        "#     if 'platform' not in st.session_state:\n",
        "#         st.session_state.platform = RFPPlatform()\n",
        "\n",
        "#     platform = st.session_state.platform\n",
        "\n",
        "#     # Sidebar\n",
        "#     st.sidebar.title(\"Navigation\")\n",
        "\n",
        "#     # Show available pages based on data loaded\n",
        "#     available_pages = [\"Setup & Data Loading\"]\n",
        "#     if platform.rfp_data:\n",
        "#         available_pages.extend([\"Opportunity Dashboard\", \"RFP Analysis\", \"Proposal Assistant\"])\n",
        "#     if platform.response_data:\n",
        "#         available_pages.append(\"Knowledge Search\")\n",
        "#     available_pages.append(\"Analytics\")\n",
        "\n",
        "#     page = st.sidebar.selectbox(\"Choose a page:\", available_pages)\n",
        "\n",
        "#     st.sidebar.markdown(\"---\")\n",
        "#     st.sidebar.subheader(\"🧪 Demo Mode\")\n",
        "\n",
        "#     if st.sidebar.button(\"Load Sample Data\"):\n",
        "#         setup_sample_environment()\n",
        "#         st.rerun()\n",
        "\n",
        "#     if st.sidebar.button(\"Reset\"):\n",
        "#         for key in list(st.session_state.keys()):\n",
        "#             del st.session_state[key]\n",
        "#         st.rerun()\n",
        "\n",
        "#     # Pages\n",
        "#     if page == \"Setup & Data Loading\":\n",
        "#         st.header(\"🔧 Setup & Data Loading\")\n",
        "\n",
        "#         col1, col2 = st.columns(2)\n",
        "\n",
        "#         with col1:\n",
        "#             st.subheader(\"Google Drive Connection\")\n",
        "#             drive_path = st.text_input(\"Drive Path\", platform.drive_path)\n",
        "\n",
        "#             if drive_path != platform.drive_path:\n",
        "#                 platform.drive_path = drive_path\n",
        "#                 platform.rfps_path = os.path.join(drive_path, \"RFP\")\n",
        "#                 platform.responses_path = os.path.join(drive_path, \"Responses\")\n",
        "\n",
        "#             if os.path.exists(drive_path):\n",
        "#                 st.success(\"✅ Drive path found\")\n",
        "\n",
        "#                 # Show directory contents\n",
        "#                 if os.path.exists(platform.rfps_path):\n",
        "#                     rfp_files = [f for f in os.listdir(platform.rfps_path)\n",
        "#                                 if f.endswith(('.pdf', '.docx', '.txt'))]\n",
        "#                     st.info(f\"📁 RFP folder: {len(rfp_files)} files found\")\n",
        "\n",
        "#                 if os.path.exists(platform.responses_path):\n",
        "#                     response_files = [f for f in os.listdir(platform.responses_path)\n",
        "#                                      if f.endswith(('.pdf', '.docx', '.txt'))]\n",
        "#                     st.info(f\"📁 Responses folder: {len(response_files)} files found\")\n",
        "#             else:\n",
        "#                 st.error(\"❌ Drive path not found\")\n",
        "\n",
        "#         with col2:\n",
        "#             st.subheader(\"Data Loading\")\n",
        "#             if st.button(\"🔄 Load Documents\", type=\"primary\"):\n",
        "#                 with st.spinner(\"Loading documents...\"):\n",
        "#                     platform.load_documents()\n",
        "#                     platform.build_embeddings()\n",
        "#                 st.rerun()  # Refresh to show new navigation options\n",
        "\n",
        "#             st.info(f\"\"\"\n",
        "#             **Status:**\n",
        "#             - RFPs: {len(platform.rfp_data)}\n",
        "#             - Responses: {len(platform.response_data)}\n",
        "#             - Embeddings: {'Yes' if platform.embeddings is not None else 'No'}\n",
        "#             \"\"\")\n",
        "\n",
        "#         # Company Profile\n",
        "#         display_company_profile()\n",
        "\n",
        "#     elif page == \"Opportunity Dashboard\":\n",
        "#         st.header(\"🎯 Opportunity Dashboard\")\n",
        "\n",
        "#         if not platform.rfp_data:\n",
        "#             st.warning(\"No RFPs loaded. Use Setup page or Sample Data.\")\n",
        "#             return\n",
        "\n",
        "#         # Filters\n",
        "#         col1, col2, col3 = st.columns(3)\n",
        "#         with col1:\n",
        "#             agency_filter = st.selectbox(\"Agency\", [\"All\"] + list(set([rfp['agency'] for rfp in platform.rfp_data])))\n",
        "#         with col2:\n",
        "#             min_fit_score = st.slider(\"Min Fit Score\", 0, 100, 50)\n",
        "#         with col3:\n",
        "#             sort_by = st.selectbox(\"Sort by\", [\"Fit Score\", \"Date\", \"Agency\"])\n",
        "\n",
        "#         # Filter and sort\n",
        "#         rfp_opportunities = []\n",
        "#         for rfp in platform.rfp_data:\n",
        "#             fit_score = platform.calculate_opportunity_fit(rfp)\n",
        "#             if fit_score >= min_fit_score:\n",
        "#                 if agency_filter == \"All\" or rfp['agency'] == agency_filter:\n",
        "#                     rfp['fit_score'] = fit_score\n",
        "#                     rfp_opportunities.append(rfp)\n",
        "\n",
        "#         if sort_by == \"Fit Score\":\n",
        "#             rfp_opportunities.sort(key=lambda x: x['fit_score'], reverse=True)\n",
        "\n",
        "#         st.subheader(f\"📊 {len(rfp_opportunities)} Opportunities\")\n",
        "\n",
        "#         for i, rfp in enumerate(rfp_opportunities):\n",
        "#             with st.expander(f\"🎯 {rfp['title']} (Fit: {rfp['fit_score']}%)\"):\n",
        "#                 col1, col2 = st.columns(2)\n",
        "#                 with col1:\n",
        "#                     st.write(f\"**Agency:** {rfp['agency']}\")\n",
        "#                     st.write(f\"**Due Date:** {rfp['due_date']}\")\n",
        "#                     st.write(f\"**Value:** {rfp['contract_value']}\")\n",
        "#                 with col2:\n",
        "#                     st.metric(\"Fit Score\", f\"{rfp['fit_score']}%\")\n",
        "\n",
        "#                 # FIXED: Navigate to RFP Analysis when analyze is clicked\n",
        "#                 if st.button(f\"📊 Analyze\", key=f\"analyze_{i}\"):\n",
        "#                     st.session_state.selected_rfp = rfp\n",
        "#                     st.session_state.page = \"RFP Analysis\"\n",
        "#                     st.success(\"RFP selected! Switching to analysis...\")\n",
        "#                     st.rerun()\n",
        "\n",
        "#     elif page == \"RFP Analysis\":\n",
        "#         st.header(\"🔍 RFP Analysis\")\n",
        "\n",
        "#         if 'selected_rfp' not in st.session_state:\n",
        "#             st.warning(\"Select an RFP from Dashboard first.\")\n",
        "#             return\n",
        "\n",
        "#         rfp = st.session_state.selected_rfp\n",
        "\n",
        "#         st.subheader(f\"📄 {rfp['title']}\")\n",
        "\n",
        "#         col1, col2, col3 = st.columns(3)\n",
        "#         with col1:\n",
        "#             st.metric(\"Fit Score\", f\"{rfp.get('fit_score', 'N/A')}%\")\n",
        "#         with col2:\n",
        "#             st.metric(\"Requirements\", len(rfp['requirements']))\n",
        "#         with col3:\n",
        "#             st.metric(\"Agency\", rfp['agency'])\n",
        "\n",
        "#         # Requirements\n",
        "#         st.subheader(\"📋 Requirements\")\n",
        "#         if rfp['requirements']:\n",
        "#             for req in rfp['requirements']:\n",
        "#                 st.write(f\"• {req}\")\n",
        "#         else:\n",
        "#             st.info(\"No requirements extracted.\")\n",
        "\n",
        "#         # Compliance Matrix\n",
        "#         st.subheader(\"✅ Compliance Matrix\")\n",
        "#         compliance_matrix = platform.generate_compliance_matrix(rfp)\n",
        "#         if compliance_matrix:\n",
        "#             st.dataframe(pd.DataFrame(compliance_matrix))\n",
        "\n",
        "#         # IMPROVED: Chat-style Q&A Assistant with Gemini\n",
        "#         st.subheader(\"🤖 AI Q&A Assistant\")\n",
        "\n",
        "#         # Initialize chat history\n",
        "#         if 'chat_history' not in st.session_state:\n",
        "#             st.session_state.chat_history = []\n",
        "\n",
        "#         # Display chat history\n",
        "#         for message in st.session_state.chat_history:\n",
        "#             if message['role'] == 'user':\n",
        "#                 st.chat_message(\"user\").write(message['content'])\n",
        "#             else:\n",
        "#                 st.chat_message(\"assistant\").write(message['content'])\n",
        "\n",
        "#         # Chat input\n",
        "#         if question := st.chat_input(\"Ask about this RFP...\"):\n",
        "#             # Add user message to chat\n",
        "#             st.session_state.chat_history.append({\"role\": \"user\", \"content\": question})\n",
        "#             st.chat_message(\"user\").write(question)\n",
        "\n",
        "#             # Get AI response\n",
        "#             with st.chat_message(\"assistant\"):\n",
        "#                 with st.spinner(\"Thinking...\"):\n",
        "#                     response = platform.ask_gemini_about_rfp(question, rfp)\n",
        "#                 st.write(response)\n",
        "\n",
        "#             # Add assistant response to chat\n",
        "#             st.session_state.chat_history.append({\"role\": \"assistant\", \"content\": response})\n",
        "\n",
        "#         # Clear chat button\n",
        "#         if st.button(\"🗑️ Clear Chat\"):\n",
        "#             st.session_state.chat_history = []\n",
        "#             st.rerun()\n",
        "\n",
        "#     elif page == \"Proposal Assistant\":\n",
        "#         st.header(\"✍️ Proposal Assistant\")\n",
        "\n",
        "#         if 'selected_rfp' not in st.session_state:\n",
        "#             st.warning(\"Select an RFP first.\")\n",
        "#             return\n",
        "\n",
        "#         rfp = st.session_state.selected_rfp\n",
        "#         st.subheader(f\"📝 Proposal for: {rfp['title']}\")\n",
        "\n",
        "#         if st.button(\"Generate Outline\", type=\"primary\"):\n",
        "#             outline = platform.generate_proposal_outline(rfp)\n",
        "#             st.session_state.proposal_outline = outline\n",
        "\n",
        "#         if 'proposal_outline' in st.session_state:\n",
        "#             st.subheader(\"📋 Proposal Outline\")\n",
        "#             outline = st.session_state.proposal_outline\n",
        "\n",
        "#             for section, details in outline.items():\n",
        "#                 with st.expander(f\"📄 {section}\"):\n",
        "#                     st.write(f\"**Description:** {details['description']}\")\n",
        "#                     st.write(f\"**Content:** {details['suggested_content']}\")\n",
        "\n",
        "#                     # IMPROVED: Generate content using Gemini\n",
        "#                     if st.button(f\"🤖 Generate AI Content\", key=f\"gen_{section}\"):\n",
        "#                         with st.spinner(\"Generating content...\"):\n",
        "#                             content = platform.generate_content_with_gemini(section, rfp)\n",
        "\n",
        "#                         st.text_area(\"Generated Content:\", content, height=300, key=f\"content_{section}\")\n",
        "\n",
        "#         # IMPROVED: All Similar Responses (collapsible instead of search)\n",
        "#         st.subheader(\"📚 All Similar Responses\")\n",
        "\n",
        "#         if platform.response_data:\n",
        "#             similar_responses = platform.get_all_responses_with_scores(rfp['text'])\n",
        "\n",
        "#             if similar_responses:\n",
        "#                 st.info(f\"Found {len(similar_responses)} responses, sorted by relevance\")\n",
        "\n",
        "#                 for i, result in enumerate(similar_responses):\n",
        "#                     similarity_percent = result['similarity_score'] * 100\n",
        "#                     with st.expander(f\"📄 {result['filename']} (Similarity: {similarity_percent:.1f}%)\"):\n",
        "#                         st.write(f\"**Relevance Score:** {similarity_percent:.1f}%\")\n",
        "\n",
        "#                         # Show preview\n",
        "#                         preview = result['document']['text'][:800]\n",
        "#                         st.text_area(\"Content Preview:\", preview, height=200, key=f\"preview_{i}\")\n",
        "\n",
        "#                         # Option to view full content\n",
        "#                         if st.button(f\"View Full Content\", key=f\"full_{i}\"):\n",
        "#                             st.text_area(\"Full Content:\", result['document']['text'], height=400, key=f\"fullcontent_{i}\")\n",
        "#             else:\n",
        "#                 st.warning(\"No similar responses found.\")\n",
        "#         else:\n",
        "#             st.warning(\"No response documents loaded.\")\n",
        "\n",
        "#     elif page == \"Knowledge Search\":\n",
        "#         st.header(\"🔍 Knowledge Search\")\n",
        "\n",
        "#         if not platform.response_data:\n",
        "#             st.warning(\"No response documents loaded.\")\n",
        "#             return\n",
        "\n",
        "#         st.subheader(\"🧠 Search Knowledge Base\")\n",
        "#         search_query = st.text_input(\"Search query:\")\n",
        "#         search_type = st.radio(\"Search Type:\", [\"Semantic Search\", \"Keyword Search\"])\n",
        "\n",
        "#         if search_query and st.button(\"Search\"):\n",
        "#             if search_type == \"Semantic Search\":\n",
        "#                 # IMPROVED: Better semantic search\n",
        "#                 results = platform.search_similar_responses_improved(search_query)\n",
        "#             else:\n",
        "#                 # Keyword search\n",
        "#                 results = []\n",
        "#                 for i, doc in enumerate(platform.response_data):\n",
        "#                     if search_query.lower() in doc['text'].lower():\n",
        "#                         results.append({\n",
        "#                             'type': 'Response',\n",
        "#                             'document': doc,\n",
        "#                             'similarity_score': 1.0,\n",
        "#                             'rank': i + 1\n",
        "#                         })\n",
        "\n",
        "#             if results:\n",
        "#                 st.success(f\"Found {len(results)} documents:\")\n",
        "#                 for result in results:\n",
        "#                     similarity_percent = result['similarity_score'] * 100 if 'similarity_score' in result else 100\n",
        "#                     with st.expander(f\"📄 {result['document']['filename']} (Relevance: {similarity_percent:.1f}%)\"):\n",
        "#                         # Highlight search terms in preview\n",
        "#                         preview_text = result['document']['text'][:800]\n",
        "#                         if search_type == \"Keyword Search\":\n",
        "#                             # Simple highlighting for keyword search\n",
        "#                             highlighted = preview_text.replace(\n",
        "#                                 search_query, f\"**{search_query}**\"\n",
        "#                             )\n",
        "#                             st.markdown(highlighted)\n",
        "#                         else:\n",
        "#                             st.text(preview_text)\n",
        "\n",
        "#                         if st.button(f\"View Full Document\", key=f\"view_{result['document']['filename']}\"):\n",
        "#                             st.text_area(\"Full Content:\", result['document']['text'], height=400, key=f\"full_{result['document']['filename']}\")\n",
        "#             else:\n",
        "#                 st.warning(\"No documents found.\")\n",
        "\n",
        "#         # Statistics\n",
        "#         st.subheader(\"📊 Knowledge Base Stats\")\n",
        "#         col1, col2, col3 = st.columns(3)\n",
        "#         with col1:\n",
        "#             st.metric(\"Documents\", len(platform.response_data))\n",
        "#         with col2:\n",
        "#             total_words = sum(len(doc['text'].split()) for doc in platform.response_data)\n",
        "#             st.metric(\"Total Words\", f\"{total_words:,}\")\n",
        "#         with col3:\n",
        "#             avg_length = total_words // len(platform.response_data) if platform.response_data else 0\n",
        "#             st.metric(\"Avg Length\", f\"{avg_length:,} words\")\n",
        "\n",
        "#         # Document list\n",
        "#         st.subheader(\"📋 All Documents\")\n",
        "#         for doc in platform.response_data:\n",
        "#             with st.expander(f\"📄 {doc['filename']}\"):\n",
        "#                 word_count = len(doc['text'].split())\n",
        "#                 st.write(f\"**Word Count:** {word_count:,}\")\n",
        "#                 st.write(f\"**Date:** {doc['date_created'].strftime('%Y-%m-%d')}\")\n",
        "#                 st.text_area(\"Preview:\", doc['text'][:500] + \"...\", height=100, key=f\"docprev_{doc['filename']}\")\n",
        "\n",
        "#     elif page == \"Analytics\":\n",
        "#         st.header(\"📈 Analytics Dashboard\")\n",
        "\n",
        "#         analysis = platform.analyze_win_loss_patterns()\n",
        "\n",
        "#         col1, col2 = st.columns(2)\n",
        "\n",
        "#         with col1:\n",
        "#             st.subheader(\"🎯 Performance\")\n",
        "#             try:\n",
        "#                 fig = go.Figure(go.Indicator(\n",
        "#                     mode = \"gauge+number\",\n",
        "#                     value = analysis['overall_win_rate'] * 100,\n",
        "#                     title = {'text': \"Win Rate (%)\"},\n",
        "#                     gauge = {\n",
        "#                         'axis': {'range': [None, 100]},\n",
        "#                         'bar': {'color': \"darkblue\"},\n",
        "#                         'steps': [\n",
        "#                             {'range': [0, 50], 'color': \"lightgray\"},\n",
        "#                             {'range': [50, 100], 'color': \"green\"}\n",
        "#                         ]\n",
        "#                     }\n",
        "#                 ))\n",
        "#                 fig.update_layout(height=300)\n",
        "#                 st.plotly_chart(fig, use_container_width=True)\n",
        "#             except:\n",
        "#                 st.metric(\"Win Rate\", f\"{analysis['overall_win_rate']*100:.1f}%\")\n",
        "\n",
        "#             st.metric(\"Avg Proposal Time\", f\"{analysis['avg_proposal_time']} days\")\n",
        "\n",
        "#         with col2:\n",
        "#             st.subheader(\"🏛️ Win Rate by Agency\")\n",
        "#             try:\n",
        "#                 agencies = list(analysis['win_rate_by_agency'].keys())\n",
        "#                 rates = [r * 100 for r in analysis['win_rate_by_agency'].values()]\n",
        "#                 fig = px.bar(x=agencies, y=rates, title=\"Win Rate by Agency (%)\")\n",
        "#                 st.plotly_chart(fig, use_container_width=True)\n",
        "#             except:\n",
        "#                 agency_df = pd.DataFrame({\n",
        "#                     'Agency': list(analysis['win_rate_by_agency'].keys()),\n",
        "#                     'Win Rate': [f\"{r*100:.1f}%\" for r in analysis['win_rate_by_agency'].values()]\n",
        "#                 })\n",
        "#                 st.dataframe(agency_df)\n",
        "\n",
        "#         # Success factors\n",
        "#         col1, col2 = st.columns(2)\n",
        "#         with col1:\n",
        "#             st.subheader(\"✅ Success Factors\")\n",
        "#             for factor in analysis['success_factors']:\n",
        "#                 st.write(f\"• {factor}\")\n",
        "#         with col2:\n",
        "#             st.subheader(\"🎯 Improvement Areas\")\n",
        "#             for area in analysis['improvement_areas']:\n",
        "#                 st.write(f\"• {area}\")\n",
        "\n",
        "#         # RFP trends\n",
        "#         if platform.rfp_data:\n",
        "#             st.subheader(\"📊 RFP Trends\")\n",
        "\n",
        "#             # Agency distribution\n",
        "#             agency_counts = {}\n",
        "#             for rfp in platform.rfp_data:\n",
        "#                 agency = rfp['agency']\n",
        "#                 agency_counts[agency] = agency_counts.get(agency, 0) + 1\n",
        "\n",
        "#             if agency_counts:\n",
        "#                 try:\n",
        "#                     fig = px.pie(values=list(agency_counts.values()),\n",
        "#                                names=list(agency_counts.keys()), title=\"RFPs by Agency\")\n",
        "#                     st.plotly_chart(fig, use_container_width=True)\n",
        "#                 except:\n",
        "#                     st.dataframe(pd.DataFrame({\n",
        "#                         'Agency': list(agency_counts.keys()),\n",
        "#                         'Count': list(agency_counts.values())\n",
        "#                     }))\n",
        "\n",
        "#             # Fit score distribution\n",
        "#             if hasattr(platform, 'rfp_data') and platform.rfp_data:\n",
        "#                 fit_scores = []\n",
        "#                 for rfp in platform.rfp_data:\n",
        "#                     score = platform.calculate_opportunity_fit(rfp)\n",
        "#                     fit_scores.append(score)\n",
        "\n",
        "#                 try:\n",
        "#                     fig = px.histogram(x=fit_scores, nbins=10, title=\"Distribution of Opportunity Fit Scores\")\n",
        "#                     fig.update_xaxis(title=\"Fit Score (%)\")\n",
        "#                     fig.update_yaxis(title=\"Number of RFPs\")\n",
        "#                     st.plotly_chart(fig, use_container_width=True)\n",
        "#                 except:\n",
        "#                     st.write(f\"Average Fit Score: {np.mean(fit_scores):.1f}%\")\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     main()\n",
        "\n",
        "# '''\n",
        "\n",
        "# # Write the app file\n",
        "# with open('/content/rfp_app.py', 'w') as f:\n",
        "#     f.write(app_content)\n",
        "\n",
        "# print(\"✅ Main application file created at /content/rfp_app.py\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40YZjtMyLcRo",
        "outputId": "06b21a16-5ecd-4108-c377-7bf6720011a6",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Creating main application file...\n",
            "✅ Main application file created at /content/rfp_app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kqx3caf8Pp2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== STEP 5: Create the Main Application File =====\n",
        "print(\"\\nCreating main application file...\")\n",
        "\n",
        "app_content = '''# RFP Proposal Intelligence Platform - Improved Version\n",
        "\n",
        "# RFP Proposal Intelligence Platform - Improved Version\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import json\n",
        "from datetime import datetime, timedelta\n",
        "import re\n",
        "from typing import List, Dict, Any, Optional\n",
        "import logging\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Document processing\n",
        "try:\n",
        "    import PyPDF2\n",
        "    import docx\n",
        "except ImportError:\n",
        "    st.error(\"Please install: !pip install PyPDF2 python-docx\")\n",
        "\n",
        "# ML components\n",
        "try:\n",
        "    from sentence_transformers import SentenceTransformer\n",
        "    import faiss\n",
        "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "    from sklearn.metrics.pairwise import cosine_similarity\n",
        "except ImportError:\n",
        "    st.error(\"Please install: !pip install sentence-transformers faiss-cpu scikit-learn\")\n",
        "\n",
        "# Visualization\n",
        "try:\n",
        "    import plotly.express as px\n",
        "    import plotly.graph_objects as go\n",
        "except ImportError:\n",
        "    st.error(\"Please install: !pip install plotly\")\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class RFPPlatform:\n",
        "    def __init__(self, drive_path=\"/content/drive/Shared drives/Leadership/rfp app\"):\n",
        "        self.drive_path = drive_path\n",
        "        self.rfps_path = os.path.join(drive_path, \"RFP\")  # Changed to \"RFP\" to match your setup\n",
        "        self.responses_path = os.path.join(drive_path, \"Responses\")  # Changed to \"Responses\"\n",
        "\n",
        "        try:\n",
        "            self.embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "            self.vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
        "        except Exception as e:\n",
        "            st.warning(f\"AI components not loaded: {e}\")\n",
        "            self.embedder = None\n",
        "            self.vectorizer = None\n",
        "\n",
        "        self.rfp_data = []\n",
        "        self.response_data = []\n",
        "        self.embeddings = None\n",
        "        self.index = None\n",
        "        self.rfp_embeddings = None\n",
        "        self.response_embeddings = None\n",
        "\n",
        "        # Initialize Gemini\n",
        "        try:\n",
        "            from google.colab import userdata\n",
        "            api_key = userdata.get('GEMINI_API_KEY')\n",
        "            if api_key:\n",
        "                genai.configure(api_key=api_key)\n",
        "                self.model = genai.GenerativeModel('gemini-pro')\n",
        "            else:\n",
        "                self.model = None\n",
        "        except Exception as e:\n",
        "            self.model = None\n",
        "            st.warning(\"Gemini API not configured\")\n",
        "\n",
        "        # Default company profile\n",
        "        self.default_company_profile = {\n",
        "            \"name\": \"A3 Consulting LLC\",\n",
        "            \"naics_codes\": [\"541511\", \"541512\", \"541519\", \"541611\"],\n",
        "            \"capabilities\": [\n",
        "                \"Management Consulting\", \"IT Consulting\", \"Strategic Planning\",\n",
        "                \"Process Improvement\", \"Data Analytics\", \"Project Management\",\n",
        "                \"Cybersecurity Consulting\", \"Digital Transformation\"\n",
        "            ],\n",
        "            \"certifications\": [\"ISO 9001\", \"CMMI Level 3\", \"FedRAMP\"],\n",
        "            \"socioeconomic\": [\"Small Business\"],\n",
        "            \"past_performance_keywords\": [\n",
        "                \"government consulting\", \"strategic planning\", \"process optimization\",\n",
        "                \"data analysis\", \"cloud migration\", \"cybersecurity\", \"IT modernization\"\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        # Load company profile from session state or use default\n",
        "        if 'company_profile' not in st.session_state:\n",
        "            st.session_state.company_profile = self.default_company_profile.copy()\n",
        "\n",
        "        self.company_profile = st.session_state.company_profile\n",
        "\n",
        "        self.setup_directories()\n",
        "\n",
        "    def setup_directories(self):\n",
        "        try:\n",
        "            os.makedirs(self.rfps_path, exist_ok=True)\n",
        "            os.makedirs(self.responses_path, exist_ok=True)\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error creating directories: {e}\")\n",
        "\n",
        "    def extract_text_from_pdf(self, file_path):\n",
        "        try:\n",
        "            with open(file_path, 'rb') as file:\n",
        "                pdf_reader = PyPDF2.PdfReader(file)\n",
        "                text = \"\"\n",
        "                for page in pdf_reader.pages:\n",
        "                    text += page.extract_text() + \"\\\\n\" # Fixed: Escape the backslash\n",
        "                return text\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error extracting PDF text: {e}\")\n",
        "            return \"\"\n",
        "\n",
        "    def extract_text_from_docx(self, file_path):\n",
        "        try:\n",
        "            doc = docx.Document(file_path)\n",
        "            text = \"\"\n",
        "            for paragraph in doc.paragraphs:\n",
        "                text += paragraph.text + \"\\\\n\" # Fixed: Escape the backslash\n",
        "            return text\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error extracting DOCX text: {e}\")\n",
        "            return \"\"\n",
        "\n",
        "    def load_documents(self):\n",
        "        st.info(\"Loading documents...\")\n",
        "\n",
        "        if not os.path.exists(self.drive_path):\n",
        "            st.error(f\"Drive path not found: {self.drive_path}\")\n",
        "            return\n",
        "\n",
        "        # Load RFPs - FIXED: Better file discovery\n",
        "        rfp_files = []\n",
        "        if os.path.exists(self.rfps_path):\n",
        "            for root, dirs, files in os.walk(self.rfps_path):\n",
        "                for file in files:\n",
        "                    if file.endswith(('.pdf', '.docx', '.txt')) and not file.startswith('.'):\n",
        "                        rfp_files.append(os.path.join(root, file))\n",
        "\n",
        "        # Load responses - FIXED: Better file discovery\n",
        "        response_files = []\n",
        "        if os.path.exists(self.responses_path):\n",
        "            for root, dirs, files in os.walk(self.responses_path):\n",
        "                for file in files:\n",
        "                    if file.endswith(('.pdf', '.docx', '.txt')) and not file.startswith('.'):\n",
        "                        response_files.append(os.path.join(root, file))\n",
        "\n",
        "        # Process RFPs\n",
        "        self.rfp_data = []\n",
        "        for file_path in rfp_files:\n",
        "            try:\n",
        "                file = os.path.basename(file_path)\n",
        "\n",
        "                if file.endswith('.pdf'):\n",
        "                    text = self.extract_text_from_pdf(file_path)\n",
        "                elif file.endswith('.docx'):\n",
        "                    text = self.extract_text_from_docx(file_path)\n",
        "                else:\n",
        "                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
        "                        text = f.read()\n",
        "\n",
        "                if text.strip():  # Only process non-empty files\n",
        "                    rfp_info = self.parse_rfp_metadata(text, file)\n",
        "                    rfp_info['file_path'] = file_path\n",
        "                    rfp_info['text'] = text\n",
        "                    self.rfp_data.append(rfp_info)\n",
        "                    logger.info(f\"Loaded RFP: {file}\")\n",
        "                else:\n",
        "                    logger.warning(f\"Empty file skipped: {file}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                st.warning(f\"Error processing {file}: {e}\")\n",
        "                logger.error(f\"Error processing {file}: {e}\")\n",
        "\n",
        "        # Process responses\n",
        "        self.response_data = []\n",
        "        for file_path in response_files:\n",
        "            try:\n",
        "                file = os.path.basename(file_path)\n",
        "\n",
        "                if file.endswith('.pdf'):\n",
        "                    text = self.extract_text_from_pdf(file_path)\n",
        "                elif file.endswith('.docx'):\n",
        "                    text = self.extract_text_from_docx(file_path)\n",
        "                else:\n",
        "                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
        "                        text = f.read()\n",
        "\n",
        "                if text.strip():  # Only process non-empty files\n",
        "                    response_info = {\n",
        "                        'filename': file,\n",
        "                        'text': text,\n",
        "                        'file_path': file_path,\n",
        "                        'date_created': datetime.now()\n",
        "                    }\n",
        "                    self.response_data.append(response_info)\n",
        "                    logger.info(f\"Loaded Response: {file}\")\n",
        "                else:\n",
        "                    logger.warning(f\"Empty file skipped: {file}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                st.warning(f\"Error processing {file}: {e}\")\n",
        "                logger.error(f\"Error processing {file}: {e}\")\n",
        "\n",
        "        st.success(f\"Loaded {len(self.rfp_data)} RFPs and {len(self.response_data)} responses\")\n",
        "\n",
        "\n",
        "def debug_file_loading(self):\n",
        "    \"\"\"Debug function to see what files are being processed\"\"\"\n",
        "    st.subheader(\"🔍 File Loading Debug\")\n",
        "\n",
        "    # Check RFP directory\n",
        "    st.write(\"**RFP Directory Analysis:**\")\n",
        "    if os.path.exists(self.rfps_path):\n",
        "        st.write(f\"📁 Path: {self.rfps_path}\")\n",
        "\n",
        "        for root, dirs, files in os.walk(self.rfps_path):\n",
        "            st.write(f\"📂 Scanning: {root}\")\n",
        "\n",
        "            for file in files:\n",
        "                file_path = os.path.join(root, file)\n",
        "                file_size = os.path.getsize(file_path)\n",
        "\n",
        "                # Check if file meets criteria\n",
        "                is_valid_ext = file.endswith(('.pdf', '.docx', '.txt'))\n",
        "                is_hidden = file.startswith('.')\n",
        "\n",
        "                status = \"✅ Will Process\" if (is_valid_ext and not is_hidden) else \"❌ Will Skip\"\n",
        "                reason = \"\"\n",
        "\n",
        "                if not is_valid_ext:\n",
        "                    reason = \"(Invalid extension)\"\n",
        "                elif is_hidden:\n",
        "                    reason = \"(Hidden file)\"\n",
        "\n",
        "                st.write(f\"   📄 {file} - {file_size} bytes - {status} {reason}\")\n",
        "\n",
        "                # Try to extract text and show preview\n",
        "                if is_valid_ext and not is_hidden:\n",
        "                    try:\n",
        "                        if file.endswith('.pdf'):\n",
        "                            text = self.extract_text_from_pdf(file_path)\n",
        "                        elif file.endswith('.docx'):\n",
        "                            text = self.extract_text_from_docx(file_path)\n",
        "                        else:\n",
        "                            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
        "                                text = f.read()\n",
        "\n",
        "                        text_preview = text[:200] + \"...\" if len(text) > 200 else text\n",
        "                        st.text_area(f\"Preview of {file}:\", text_preview, height=100, key=f\"preview_rfp_{file}\")\n",
        "\n",
        "                        if not text.strip():\n",
        "                            st.warning(f\"⚠️ {file} appears to be empty after text extraction!\")\n",
        "\n",
        "                    except Exception as e:\n",
        "                        st.error(f\"❌ Error reading {file}: {e}\")\n",
        "\n",
        "    st.write(\"---\")\n",
        "\n",
        "    # Check Responses directory\n",
        "    st.write(\"**Responses Directory Analysis:**\")\n",
        "    if os.path.exists(self.responses_path):\n",
        "        st.write(f\"📁 Path: {self.responses_path}\")\n",
        "\n",
        "        for root, dirs, files in os.walk(self.responses_path):\n",
        "            st.write(f\"📂 Scanning: {root}\")\n",
        "\n",
        "            for file in files:\n",
        "                file_path = os.path.join(root, file)\n",
        "                file_size = os.path.getsize(file_path)\n",
        "\n",
        "                # Check if file meets criteria\n",
        "                is_valid_ext = file.endswith(('.pdf', '.docx', '.txt'))\n",
        "                is_hidden = file.startswith('.')\n",
        "\n",
        "                status = \"✅ Will Process\" if (is_valid_ext and not is_hidden) else \"❌ Will Skip\"\n",
        "                reason = \"\"\n",
        "\n",
        "                if not is_valid_ext:\n",
        "                    reason = \"(Invalid extension)\"\n",
        "                elif is_hidden:\n",
        "                    reason = \"(Hidden file)\"\n",
        "\n",
        "                st.write(f\"   📄 {file} - {file_size} bytes - {status} {reason}\")\n",
        "\n",
        "                # Try to extract text and show preview\n",
        "                if is_valid_ext and not is_hidden:\n",
        "                    try:\n",
        "                        if file.endswith('.pdf'):\n",
        "                            text = self.extract_text_from_pdf(file_path)\n",
        "                        elif file.endswith('.docx'):\n",
        "                            text = self.extract_text_from_docx(file_path)\n",
        "                        else:\n",
        "                            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
        "                                text = f.read()\n",
        "\n",
        "                        text_preview = text[:200] + \"...\" if len(text) > 200 else text\n",
        "                        st.text_area(f\"Preview of {file}:\", text_preview, height=100, key=f\"preview_resp_{file}\")\n",
        "\n",
        "                        if not text.strip():\n",
        "                            st.warning(f\"⚠️ {file} appears to be empty after text extraction!\")\n",
        "\n",
        "                    except Exception as e:\n",
        "                        st.error(f\"❌ Error reading {file}: {e}\")S\n",
        "\n",
        "\n",
        "    def parse_rfp_metadata(self, text, filename):\n",
        "        return {\n",
        "            'title': filename.replace('.pdf', '').replace('.docx', '').replace('.txt', ''),\n",
        "            'filename': filename,\n",
        "            'agency': self.extract_agency(text),\n",
        "            'due_date': self.extract_due_date(text),\n",
        "            'naics_codes': self.extract_naics_codes(text),\n",
        "            'contract_value': self.extract_contract_value(text),\n",
        "            'requirements': self.extract_requirements(text),\n",
        "            'evaluation_criteria': self.extract_evaluation_criteria(text),\n",
        "            'date_loaded': datetime.now()\n",
        "        }\n",
        "\n",
        "    def extract_agency(self, text):\n",
        "        agencies = ['DHS', 'DOD', 'GSA', 'VA', 'HHS', 'DOE', 'NASA', 'USDA',\n",
        "                   'Department of Homeland Security', 'General Services Administration']\n",
        "        text_upper = text.upper()\n",
        "        for agency in agencies:\n",
        "            if agency.upper() in text_upper:\n",
        "                if 'HOMELAND SECURITY' in agency.upper():\n",
        "                    return 'DHS'\n",
        "                elif 'GENERAL SERVICES' in agency.upper():\n",
        "                    return 'GSA'\n",
        "                else:\n",
        "                    return agency\n",
        "        return \"Unknown\"\n",
        "\n",
        "    def extract_due_date(self, text):\n",
        "        import re\n",
        "        date_patterns = [\n",
        "            r'\\\\b\\\\d{1,2}/\\\\d{1,2}/\\\\d{4}\\\\b',\n",
        "            r'\\\\b\\\\d{1,2}-\\\\d{1,2}-\\\\d{4}\\\\b',\n",
        "            r'\\\\b\\\\w+ \\\\d{1,2}, \\\\d{4}\\\\b'\n",
        "        ]\n",
        "\n",
        "        for pattern in date_patterns:\n",
        "            matches = re.findall(pattern, text)\n",
        "            if matches:\n",
        "                return matches[0]\n",
        "        return \"Not found\"\n",
        "\n",
        "    def extract_naics_codes(self, text):\n",
        "        import re\n",
        "        naics_pattern = r'\\\\b\\\\d{6}\\\\b'\n",
        "        codes = re.findall(naics_pattern, text)\n",
        "        return codes[:5]\n",
        "\n",
        "    def extract_contract_value(self, text):\n",
        "        import re\n",
        "        value_patterns = [\n",
        "            r'\\\\$[\\\\d,]+(?:\\\\.\\\\d{2})?',\n",
        "            r'[\\\\d,]+ dollars?'\n",
        "        ]\n",
        "\n",
        "        for pattern in value_patterns:\n",
        "            matches = re.findall(pattern, text, re.IGNORECASE)\n",
        "            if matches:\n",
        "                return matches[0]\n",
        "        return \"Not specified\"\n",
        "\n",
        "    def extract_requirements(self, text):\n",
        "        req_keywords = ['requirement', 'shall', 'must', 'mandatory', 'criteria']\n",
        "        sentences = text.split('.')\n",
        "        requirements = []\n",
        "\n",
        "        for sentence in sentences:\n",
        "            sentence_lower = sentence.lower()\n",
        "            if any(keyword in sentence_lower for keyword in req_keywords):\n",
        "                if len(sentence.strip()) > 20:\n",
        "                    requirements.append(sentence.strip())\n",
        "\n",
        "        return requirements[:10]\n",
        "\n",
        "    def extract_evaluation_criteria(self, text):\n",
        "        criteria_keywords = ['evaluation', 'scoring', 'points', 'weight', 'factor']\n",
        "        sentences = text.split('.')\n",
        "        criteria = []\n",
        "\n",
        "        for sentence in sentences:\n",
        "            sentence_lower = sentence.lower()\n",
        "            if any(keyword in sentence_lower for keyword in criteria_keywords):\n",
        "                if len(sentence.strip()) > 20:\n",
        "                    criteria.append(sentence.strip())\n",
        "\n",
        "        return criteria[:5]\n",
        "\n",
        "    def build_embeddings(self):\n",
        "        if not self.embedder:\n",
        "            st.warning(\"Embedder not available\")\n",
        "            return\n",
        "\n",
        "        try:\n",
        "            # Build separate embeddings for RFPs and responses\n",
        "            if self.rfp_data:\n",
        "                rfp_texts = [rfp['text'] for rfp in self.rfp_data]\n",
        "                self.rfp_embeddings = self.embedder.encode(rfp_texts)\n",
        "\n",
        "            if self.response_data:\n",
        "                response_texts = [response['text'] for response in self.response_data]\n",
        "                self.response_embeddings = self.embedder.encode(response_texts)\n",
        "\n",
        "            # Build combined embeddings for general search\n",
        "            all_texts = []\n",
        "            if self.rfp_data:\n",
        "                all_texts.extend([rfp['text'] for rfp in self.rfp_data])\n",
        "            if self.response_data:\n",
        "                all_texts.extend([response['text'] for response in self.response_data])\n",
        "\n",
        "            if all_texts:\n",
        "                self.embeddings = self.embedder.encode(all_texts)\n",
        "                dimension = self.embeddings.shape[1]\n",
        "                self.index = faiss.IndexFlatIP(dimension)\n",
        "                self.index.add(self.embeddings.astype('float32'))\n",
        "                st.success(f\"Built embeddings for {len(all_texts)} documents\")\n",
        "\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error building embeddings: {e}\")\n",
        "            logger.error(f\"Error building embeddings: {e}\")\n",
        "\n",
        "    def calculate_opportunity_fit(self, rfp_info):\n",
        "        score = 0\n",
        "\n",
        "        # NAICS code match (30 points)\n",
        "        naics_match = any(code in self.company_profile['naics_codes']\n",
        "                         for code in rfp_info['naics_codes'])\n",
        "        if naics_match:\n",
        "            score += 30\n",
        "\n",
        "        # Capability keywords match (40 points)\n",
        "        text_lower = rfp_info['text'].lower()\n",
        "        capability_matches = sum(1 for cap in self.company_profile['capabilities']\n",
        "                               if cap.lower() in text_lower)\n",
        "        score += min(40, capability_matches * 8)\n",
        "\n",
        "        # Past performance keywords (30 points)\n",
        "        pp_matches = sum(1 for keyword in self.company_profile['past_performance_keywords']\n",
        "                        if keyword in text_lower)\n",
        "        score += min(30, pp_matches * 10)\n",
        "\n",
        "        return min(score, 100)\n",
        "\n",
        "    def generate_compliance_matrix(self, rfp_info):\n",
        "        requirements = rfp_info['requirements']\n",
        "        matrix = []\n",
        "\n",
        "        for i, req in enumerate(requirements):\n",
        "            compliant = any(cap.lower() in req.lower()\n",
        "                          for cap in self.company_profile['capabilities'])\n",
        "\n",
        "            matrix.append({\n",
        "                'requirement': req[:100] + \"...\" if len(req) > 100 else req,\n",
        "                'compliant': 'Yes' if compliant else 'Needs Review',\n",
        "                'response_section': f\"Section {i+1}\"\n",
        "            })\n",
        "\n",
        "        return matrix\n",
        "\n",
        "    def search_similar_responses_improved(self, query, top_k=5):\n",
        "        \"\"\"Improved semantic search using embeddings\"\"\"\n",
        "        if not self.response_embeddings is not None or not self.embedder:\n",
        "            return []\n",
        "\n",
        "        try:\n",
        "            query_embedding = self.embedder.encode([query])\n",
        "\n",
        "            # Calculate cosine similarity\n",
        "            similarities = cosine_similarity(query_embedding, self.response_embeddings)[0]\n",
        "\n",
        "            # Get top k results\n",
        "            top_indices = np.argsort(similarities)[::-1][:top_k]\n",
        "\n",
        "            results = []\n",
        "            for i, idx in enumerate(top_indices):\n",
        "                if similarities[idx] > 0.1:  # Threshold for relevance\n",
        "                    results.append({\n",
        "                        'type': \"Response\",\n",
        "                        'document': self.response_data[idx],\n",
        "                        'similarity_score': float(similarities[idx]),\n",
        "                        'rank': i + 1\n",
        "                    })\n",
        "\n",
        "            return results\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error in semantic search: {e}\")\n",
        "            return []\n",
        "\n",
        "    def get_all_responses_with_scores(self, rfp_text):\n",
        "        \"\"\"Get all responses with similarity scores to RFP\"\"\"\n",
        "        if not self.response_embeddings is not None or not self.embedder:\n",
        "            return []\n",
        "\n",
        "        try:\n",
        "            rfp_embedding = self.embedder.encode([rfp_text])\n",
        "            similarities = cosine_similarity(rfp_embedding, self.response_embeddings)[0]\n",
        "\n",
        "            results = []\n",
        "            for idx, score in enumerate(similarities):\n",
        "                results.append({\n",
        "                    'document': self.response_data[idx],\n",
        "                    'similarity_score': float(score),\n",
        "                    'filename': self.response_data[idx]['filename']\n",
        "                })\n",
        "\n",
        "            # Sort by similarity score\n",
        "            results.sort(key=lambda x: x['similarity_score'], reverse=True)\n",
        "            return results\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error getting response scores: {e}\")\n",
        "            return []\n",
        "\n",
        "    def ask_gemini_about_rfp(self, question, rfp_info):\n",
        "        \"\"\"Use Gemini to answer questions about RFP\"\"\"\n",
        "        if not self.model:\n",
        "            return \"Gemini API not configured. Please add GEMINI_API_KEY to Colab secrets.\"\n",
        "\n",
        "        try:\n",
        "            prompt = f\"\"\"\n",
        "            You are an expert RFP analyst helping A3 Consulting LLC understand an RFP.\n",
        "\n",
        "            RFP Title: {rfp_info['title']}\n",
        "            Agency: {rfp_info['agency']}\n",
        "\n",
        "            RFP Content:\n",
        "            {rfp_info['text'][:4000]}  # Limit content to avoid token limits\n",
        "\n",
        "            Company Profile:\n",
        "            - Name: {self.company_profile['name']}\n",
        "            - Capabilities: {', '.join(self.company_profile['capabilities'])}\n",
        "            - NAICS Codes: {', '.join(self.company_profile['naics_codes'])}\n",
        "\n",
        "            Question: {question}\n",
        "\n",
        "            Please provide a helpful, specific answer based on the RFP content and how it relates to A3 Consulting's capabilities.\n",
        "            \"\"\"\n",
        "\n",
        "            response = self.model.generate_content(prompt)\n",
        "            return response.text\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"Error getting AI response: {e}\"\n",
        "\n",
        "    def generate_content_with_gemini(self, section, rfp_info):\n",
        "        \"\"\"Generate proposal content using Gemini and similar responses\"\"\"\n",
        "        if not self.model:\n",
        "            return \"Gemini API not configured. Please add GEMINI_API_KEY to Colab secrets.\"\n",
        "\n",
        "        try:\n",
        "            # Get similar responses for context\n",
        "            similar_responses = self.get_all_responses_with_scores(rfp_info['text'])[:3]\n",
        "            context = \"\"\n",
        "\n",
        "            for resp in similar_responses:\n",
        "                context += f\"\\\\n--- Similar Response Example ---\\\\n{resp['document']['text'][:1000]}...\\\\n\" # Fixed: Escape backslashes\n",
        "\n",
        "            prompt = \"\"\"\n",
        "            You are writing a {section} section for A3 Consulting LLC's proposal response.\n",
        "\n",
        "            RFP Details:\n",
        "            - Title: {rfp_info['title']}\n",
        "            - Agency: {rfp_info['agency']}\n",
        "            - Requirements: {rfp_info['requirements'][:3]}  # Top 3 requirements\n",
        "\n",
        "            Company Profile:\n",
        "            - Name: {self.company_profile['name']}\n",
        "            - Capabilities: {', '.join(self.company_profile['capabilities'])}\n",
        "            - Certifications: {', '.join(self.company_profile['certifications'])}\n",
        "\n",
        "            Context from Similar Past Responses:\n",
        "            {context}\n",
        "\n",
        "            Please write a professional {section} section that:\n",
        "            1. Addresses the RFP requirements\n",
        "            2. Highlights A3 Consulting's relevant capabilities\n",
        "            3. Uses a similar tone and structure to the example responses\n",
        "            4. Is specific and compelling\n",
        "\n",
        "            Write 3-4 paragraphs for this section.\n",
        "            \"\"\"\n",
        "\n",
        "            response = self.model.generate_content(prompt)\n",
        "            return response.text\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"Error generating content: {e}\"\n",
        "\n",
        "    def generate_proposal_outline(self, rfp_info):\n",
        "        outline = {\n",
        "            \"Executive Summary\": {\n",
        "                \"description\": \"Overview of our approach and key win themes\",\n",
        "                \"suggested_content\": \"Highlight A3's unique qualifications\"\n",
        "            },\n",
        "            \"Technical Approach\": {\n",
        "                \"description\": \"Detailed methodology and approach\",\n",
        "                \"suggested_content\": \"Address each technical requirement\"\n",
        "            },\n",
        "            \"Management Plan\": {\n",
        "                \"description\": \"Project management and organization\",\n",
        "                \"suggested_content\": \"Show project structure and timeline\"\n",
        "            },\n",
        "            \"Past Performance\": {\n",
        "                \"description\": \"Relevant experience and references\",\n",
        "                \"suggested_content\": \"Include similar projects\"\n",
        "            }\n",
        "        }\n",
        "\n",
        "        requirements = rfp_info['requirements']\n",
        "        custom_sections = []\n",
        "\n",
        "        for req in requirements:\n",
        "            if 'security' in req.lower():\n",
        "                custom_sections.append(\"Security Approach\")\n",
        "            elif 'quality' in req.lower():\n",
        "                custom_sections.append(\"Quality Assurance\")\n",
        "\n",
        "        for section in set(custom_sections):\n",
        "            outline[section] = {\n",
        "                \"description\": f\"Address {section.lower()} requirements\",\n",
        "                \"suggested_content\": f\"Detail our {section.lower()} approach\"\n",
        "            }\n",
        "\n",
        "        return outline\n",
        "\n",
        "    def analyze_win_loss_patterns(self):\n",
        "        return {\n",
        "            'overall_win_rate': 0.45,\n",
        "            'win_rate_by_agency': {'DHS': 0.6, 'GSA': 0.4, 'DOD': 0.5, 'VA': 0.3},\n",
        "            'avg_proposal_time': 25,\n",
        "            'success_factors': [\n",
        "                'Strong past performance alignment',\n",
        "                'Competitive pricing',\n",
        "                'Clear technical approach'\n",
        "            ],\n",
        "            'improvement_areas': [\n",
        "                'Faster response time',\n",
        "                'Better capture intelligence'\n",
        "            ]\n",
        "        }\n",
        "\n",
        "def display_company_profile():\n",
        "    \"\"\"Display and edit company profile\"\"\"\n",
        "    st.subheader(\"🏢 Company INFO Profile\")\n",
        "\n",
        "    if 'edit_profile' not in st.session_state:\n",
        "        st.session_state.edit_profile = False\n",
        "\n",
        "    col1, col2 = st.columns([3, 1])\n",
        "\n",
        "    with col2:\n",
        "        if st.button(\"✏️ Edit Profile\" if not st.session_state.edit_profile else \"💾 Save Profile\"):\n",
        "            st.session_state.edit_profile = not st.session_state.edit_profile\n",
        "            if not st.session_state.edit_profile:\n",
        "                st.success(\"Profile saved!\")\n",
        "\n",
        "    with col1:\n",
        "        if st.session_state.edit_profile:\n",
        "            # Edit mode\n",
        "            st.session_state.company_profile['name'] = st.text_input(\n",
        "                \"Company Name\", st.session_state.company_profile['name'])\n",
        "\n",
        "            st.session_state.company_profile['naics_codes'] = st.text_area(\n",
        "                \"NAICS Codes (comma-separated)\",\n",
        "                ', '.join(st.session_state.company_profile['naics_codes'])).split(', ')\n",
        "\n",
        "            st.session_state.company_profile['capabilities'] = st.text_area(\n",
        "                \"Capabilities (comma-separated)\",\n",
        "                ', '.join(st.session_state.company_profile['capabilities'])).split(', ')\n",
        "\n",
        "            st.session_state.company_profile['certifications'] = st.text_area(\n",
        "                \"Certifications (comma-separated)\",\n",
        "                ', '.join(st.session_state.company_profile['certifications'])).split(', ')\n",
        "\n",
        "        else:\n",
        "            # Display mode\n",
        "            profile = st.session_state.company_profile\n",
        "            st.write(f\"**Company:** {profile['name']}\")\n",
        "            st.write(f\"**NAICS Codes:** {', '.join(profile['naics_codes'])}\")\n",
        "            st.write(f\"**Capabilities:** {', '.join(profile['capabilities'])}\")\n",
        "            st.write(f\"**Certifications:** {', '.join(profile['certifications'])}\")\n",
        "\n",
        "def create_sample_data():\n",
        "    sample_rfps = [\n",
        "        {\n",
        "            'title': 'IT_Modernization_Services',\n",
        "            'filename': 'DHS_IT_Modernization_RFP.txt',\n",
        "            'agency': 'DHS',\n",
        "            'due_date': '2024-08-15',\n",
        "            'naics_codes': ['541511', '541512'],\n",
        "            'contract_value': '$2,500,000',\n",
        "            'text': 'Department of Homeland Security requires IT modernization including cloud migration, cybersecurity assessment, and system integration. Must have quality assurance processes.',\n",
        "            'requirements': [\n",
        "                'Must have federal cloud migration experience',\n",
        "                'Shall provide 24/7 technical support',\n",
        "                'Must maintain FedRAMP compliance'\n",
        "            ],\n",
        "            'evaluation_criteria': [\n",
        "                'Technical approach weighted 40%',\n",
        "                'Past performance weighted 30%'\n",
        "            ],\n",
        "            'date_loaded': datetime.now()\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    sample_responses = [\n",
        "        {\n",
        "            'filename': 'A3_IT_Modernization_Response.txt',\n",
        "            'text': 'A3 Consulting has extensive federal IT modernization experience with 15+ successful cloud migrations. Our quality assurance processes ensure reliable delivery.',\n",
        "            'date_created': datetime.now()\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    return sample_rfps, sample_responses\n",
        "\n",
        "def setup_sample_environment():\n",
        "    st.info(\"Setting up sample environment...\")\n",
        "    sample_rfps, sample_responses = create_sample_data()\n",
        "\n",
        "    platform = RFPPlatform()\n",
        "    platform.rfp_data = sample_rfps\n",
        "    platform.response_data = sample_responses\n",
        "\n",
        "    try:\n",
        "        platform.build_embeddings()\n",
        "    except Exception as e:\n",
        "        st.warning(f\"Could not build embeddings: {e}\")\n",
        "\n",
        "    st.session_state.platform = platform\n",
        "    st.success(\"Sample environment ready!\")\n",
        "    return platform\n",
        "\n",
        "\n",
        "def main():\n",
        "    st.set_page_config(\n",
        "        page_title=\"RFP Intelligence Platform\",\n",
        "        page_icon=\"📄\",\n",
        "        layout=\"wide\"\n",
        "    )\n",
        "\n",
        "    st.title(\"🚀 RFP Proposal Intelligence Platform\")\n",
        "    st.markdown(\"### AI-Powered Proposal Development for A3 Consulting LLC\")\n",
        "\n",
        "    if 'platform' not in st.session_state:\n",
        "        st.session_state.platform = RFPPlatform()\n",
        "\n",
        "    platform = st.session_state.platform\n",
        "\n",
        "    # Sidebar\n",
        "    st.sidebar.title(\"Navigation\")\n",
        "\n",
        "    # Show available pages based on data loaded\n",
        "    available_pages = [\"Setup & Data Loading\"]\n",
        "    if platform.rfp_data:\n",
        "        available_pages.extend([\"Opportunity Dashboard\", \"RFP Analysis\", \"Proposal Assistant\"])\n",
        "    if platform.response_data:\n",
        "        available_pages.append(\"Knowledge Search\")\n",
        "    available_pages.append(\"Analytics\")\n",
        "\n",
        "    page = st.sidebar.selectbox(\"Choose a page:\", available_pages)\n",
        "\n",
        "    st.sidebar.markdown(\"---\")\n",
        "    st.sidebar.subheader(\"🧪 --DemoK Mode\")\n",
        "\n",
        "    if st.button(\"🔍 1Debug File Loading\"):\n",
        "              platform.debug_file_loading()\n",
        "\n",
        "    if st.sidebar.button(\"Load Sample Data\"):\n",
        "        setup_sample_environment()\n",
        "        st.rerun()\n",
        "\n",
        "    if st.sidebar.button(\"Reset\"):\n",
        "        for key in list(st.session_state.keys()):\n",
        "            del st.session_state[key]\n",
        "        st.rerun()\n",
        "\n",
        "    # Pages\n",
        "    if page == \"Setup & Data Loading\":\n",
        "        st.header(\"🔧 Setup & --Data Loading\")\n",
        "        if st.button(\"🔍 2Debug File Loading\"):\n",
        "              platform.debug_file_loading()\n",
        "\n",
        "\n",
        "        col1, col2 = st.columns(2)\n",
        "\n",
        "        with col1:\n",
        "            st.subheader(\"Google Drive Connection\")\n",
        "            drive_path = st.text_input(\"Drive Path\", platform.drive_path)\n",
        "\n",
        "            if drive_path != platform.drive_path:\n",
        "                platform.drive_path = drive_path\n",
        "                platform.rfps_path = os.path.join(drive_path, \"RFP\")\n",
        "                platform.responses_path = os.path.join(drive_path, \"Responses\")\n",
        "\n",
        "            if os.path.exists(drive_path):\n",
        "                st.success(\"✅ Drive path found\")\n",
        "\n",
        "                # Show directory contents\n",
        "                if os.path.exists(platform.rfps_path):\n",
        "                    rfp_files = [f for f in os.listdir(platform.rfps_path)\n",
        "                                if f.endswith(('.pdf', '.docx', '.txt'))]\n",
        "                    st.info(f\"📁 RFP folder: {len(rfp_files)} files found\")\n",
        "\n",
        "                if os.path.exists(platform.responses_path):\n",
        "                    response_files = [f for f in os.listdir(platform.responses_path)\n",
        "                                     if f.endswith(('.pdf', '.docx', '.txt'))]\n",
        "                    st.info(f\"📁 Responses folder: {len(response_files)} files found\")\n",
        "            else:\n",
        "                st.error(\"❌ Drive path not found\")\n",
        "\n",
        "        with col2:\n",
        "            st.subheader(\"Data Loading\")\n",
        "            if st.button(\"🔄 Load Documents\", type=\"primary\"):\n",
        "                with st.spinner(\"Loading documents...\"):\n",
        "                    platform.load_documents()\n",
        "                    platform.build_embeddings()\n",
        "                st.rerun()  # Refresh to show new navigation options\n",
        "\n",
        "            st.info(f\"\"\"\n",
        "            **Status:**\n",
        "            - RFPs: {len(platform.rfp_data)}\n",
        "            - Responses: {len(platform.response_data)}\n",
        "            - Embeddings: {'Yes' if platform.embeddings is not None else 'No'}\n",
        "            \"\"\")\n",
        "\n",
        "        # Company Profile\n",
        "        display_company_profile()\n",
        "\n",
        "    elif page == \"Opportunity Dashboard\":\n",
        "        st.header(\"🎯 Opportunity Dashboard\")\n",
        "\n",
        "        if not platform.rfp_data:\n",
        "            st.warning(\"No RFPs loaded. Use Setup page or Sample Data.\")\n",
        "            return\n",
        "\n",
        "        # Filters\n",
        "        col1, col2, col3 = st.columns(3)\n",
        "        with col1:\n",
        "            agency_filter = st.selectbox(\"Agency\", [\"All\"] + list(set([rfp['agency'] for rfp in platform.rfp_data])))\n",
        "        with col2:\n",
        "            min_fit_score = st.slider(\"Min Fit Score\", 0, 100, 50)\n",
        "        with col3:\n",
        "            sort_by = st.selectbox(\"Sort by\", [\"Fit Score\", \"Date\", \"Agency\"])\n",
        "\n",
        "        # Filter and sort\n",
        "        rfp_opportunities = []\n",
        "        for rfp in platform.rfp_data:\n",
        "            fit_score = platform.calculate_opportunity_fit(rfp)\n",
        "            if fit_score >= min_fit_score:\n",
        "                if agency_filter == \"All\" or rfp['agency'] == agency_filter:\n",
        "                    rfp['fit_score'] = fit_score\n",
        "                    rfp_opportunities.append(rfp)\n",
        "\n",
        "        if sort_by == \"Fit Score\":\n",
        "            rfp_opportunities.sort(key=lambda x: x['fit_score'], reverse=True)\n",
        "\n",
        "        st.subheader(f\"📊 {len(rfp_opportunities)} Opportunities\")\n",
        "\n",
        "        for i, rfp in enumerate(rfp_opportunities):\n",
        "            with st.expander(f\"🎯 {rfp['title']} (Fit: {rfp['fit_score']}%)\"):\n",
        "                col1, col2 = st.columns(2)\n",
        "                with col1:\n",
        "                    st.write(f\"**Agency:** {rfp['agency']}\")\n",
        "                    st.write(f\"**Due Date:** {rfp['due_date']}\")\n",
        "                    st.write(f\"**Value:** {rfp['contract_value']}\")\n",
        "                with col2:\n",
        "                    st.metric(\"Fit Score\", f\"{rfp['fit_score']}%\")\n",
        "\n",
        "                # FIXED: Navigate to RFP Analysis when analyze is clicked\n",
        "                if st.button(f\"📊 Analyze\", key=f\"analyze_{i}\"):\n",
        "                    st.session_state.selected_rfp = rfp\n",
        "                    st.session_state.page = \"RFP Analysis\"\n",
        "                    st.success(\"RFP selected! Switching to analysis...\")\n",
        "                    st.rerun()\n",
        "\n",
        "    elif page == \"RFP Analysis\":\n",
        "        st.header(\"🔍 RFP Analysis\")\n",
        "\n",
        "        if 'selected_rfp' not in st.session_state:\n",
        "            st.warning(\"Select an RFP from Dashboard first.\")\n",
        "            return\n",
        "\n",
        "        rfp = st.session_state.selected_rfp\n",
        "\n",
        "        st.subheader(f\"📄 {rfp['title']}\")\n",
        "\n",
        "        col1, col2, col3 = st.columns(3)\n",
        "        with col1:\n",
        "            st.metric(\"Fit Score\", f\"{rfp.get('fit_score', 'N/A')}%\")\n",
        "        with col2:\n",
        "            st.metric(\"Requirements\", len(rfp['requirements']))\n",
        "        with col3:\n",
        "            st.metric(\"Agency\", rfp['agency'])\n",
        "\n",
        "        # Requirements\n",
        "        st.subheader(\"📋 Requirements\")\n",
        "        if rfp['requirements']:\n",
        "            for req in rfp['requirements']:\n",
        "                st.write(f\"• {req}\")\n",
        "        else:\n",
        "            st.info(\"No requirements extracted.\")\n",
        "\n",
        "        # Compliance Matrix\n",
        "        st.subheader(\"✅ Compliance Matrix\")\n",
        "        compliance_matrix = platform.generate_compliance_matrix(rfp)\n",
        "        if compliance_matrix:\n",
        "            st.dataframe(pd.DataFrame(compliance_matrix))\n",
        "\n",
        "        # IMPROVED: Chat-style Q&A Assistant with Gemini\n",
        "        st.subheader(\"🤖 AI Q&A Assistant\")\n",
        "\n",
        "        # Initialize chat history\n",
        "        if 'chat_history' not in st.session_state:\n",
        "            st.session_state.chat_history = []\n",
        "\n",
        "        # Display chat history\n",
        "        for message in st.session_state.chat_history:\n",
        "            if message['role'] == 'user':\n",
        "                st.chat_message(\"user\").write(message['content'])\n",
        "            else:\n",
        "                st.chat_message(\"assistant\").write(message['content'])\n",
        "\n",
        "        # Chat input\n",
        "        if question := st.chat_input(\"Ask about this RFP...\"):\n",
        "            # Add user message to chat\n",
        "            st.session_state.chat_history.append({\"role\": \"user\", \"content\": question})\n",
        "            st.chat_message(\"user\").write(question)\n",
        "\n",
        "            # Get AI response\n",
        "            with st.chat_message(\"assistant\"):\n",
        "                with st.spinner(\"Thinking...\"):\n",
        "                    response = platform.ask_gemini_about_rfp(question, rfp)\n",
        "                st.write(response)\n",
        "\n",
        "            # Add assistant response to chat\n",
        "            st.session_state.chat_history.append({\"role\": \"assistant\", \"content\": response})\n",
        "\n",
        "        # Clear chat button\n",
        "        if st.button(\"🗑️ Clear Chat\"):\n",
        "            st.session_state.chat_history = []\n",
        "            st.rerun()\n",
        "\n",
        "    elif page == \"Proposal Assistant\":\n",
        "        st.header(\"✍️ Proposal Assistant\")\n",
        "\n",
        "        if 'selected_rfp' not in st.session_state:\n",
        "            st.warning(\"Select an RFP first.\")\n",
        "            return\n",
        "\n",
        "        rfp = st.session_state.selected_rfp\n",
        "        st.subheader(f\"📝 Proposal for: {rfp['title']}\")\n",
        "\n",
        "        if st.button(\"Generate Outline\", type=\"primary\"):\n",
        "            outline = platform.generate_proposal_outline(rfp)\n",
        "            st.session_state.proposal_outline = outline\n",
        "\n",
        "        if 'proposal_outline' in st.session_state:\n",
        "            st.subheader(\"📋 Proposal Outline\")\n",
        "            outline = st.session_state.proposal_outline\n",
        "\n",
        "            for section, details in outline.items():\n",
        "                with st.expander(f\"📄 {section}\"):\n",
        "                    st.write(f\"**Description:** {details['description']}\")\n",
        "                    st.write(f\"**Content:** {details['suggested_content']}\")\n",
        "\n",
        "                    # IMPROVED: Generate content using Gemini\n",
        "                    if st.button(f\"🤖 Generate AI Content\", key=f\"gen_{section}\"):\n",
        "                        with st.spinner(\"Generating content...\"):\n",
        "                            content = platform.generate_content_with_gemini(section, rfp)\n",
        "\n",
        "                        st.text_area(\"Generated Content:\", content, height=300, key=f\"content_{section}\")\n",
        "\n",
        "        # IMPROVED: All Similar Responses (collapsible instead of search)\n",
        "        st.subheader(\"📚 All Similar Responses\")\n",
        "\n",
        "        if platform.response_data:\n",
        "            similar_responses = platform.get_all_responses_with_scores(rfp['text'])\n",
        "\n",
        "            if similar_responses:\n",
        "                st.info(f\"Found {len(similar_responses)} responses, sorted by relevance\")\n",
        "\n",
        "                for i, result in enumerate(similar_responses):\n",
        "                    similarity_percent = result['similarity_score'] * 100\n",
        "                    with st.expander(f\"📄 {result['filename']} (Similarity: {similarity_percent:.1f}%)\"):\n",
        "                        st.write(f\"**Relevance Score:** {similarity_percent:.1f}%\")\n",
        "\n",
        "                        # Show preview\n",
        "                        preview = result['document']['text'][:800]\n",
        "                        st.text_area(\"Content Preview:\", preview, height=200, key=f\"preview_{i}\")\n",
        "\n",
        "                        # Option to view full content\n",
        "                        if st.button(f\"View Full Content\", key=f\"full_{i}\"):\n",
        "                            st.text_area(\"Full Content:\", result['document']['text'], height=400, key=f\"fullcontent_{i}\")\n",
        "            else:\n",
        "                st.warning(\"No similar responses found.\")\n",
        "        else:\n",
        "            st.warning(\"No response documents loaded.\")\n",
        "\n",
        "    elif page == \"Knowledge Search\":\n",
        "        st.header(\"🔍 Knowledge Search\")\n",
        "\n",
        "        if not platform.response_data:\n",
        "            st.warning(\"No response documents loaded.\")\n",
        "            return\n",
        "\n",
        "        st.subheader(\"🧠 Search Knowledge Base\")\n",
        "        search_query = st.text_input(\"Search query:\")\n",
        "        search_type = st.radio(\"Search Type:\", [\"Semantic Search\", \"Keyword Search\"])\n",
        "\n",
        "        if search_query and st.button(\"Search\"):\n",
        "            if search_type == \"Semantic Search\":\n",
        "                # IMPROVED: Better semantic search\n",
        "                results = platform.search_similar_responses_improved(search_query)\n",
        "            else:\n",
        "                # Keyword search\n",
        "                results = []\n",
        "                for i, doc in enumerate(platform.response_data):\n",
        "                    if search_query.lower() in doc['text'].lower():\n",
        "                        results.append({\n",
        "                            'type': 'Response',\n",
        "                            'document': doc,\n",
        "                            'similarity_score': 1.0,\n",
        "                            'rank': i + 1\n",
        "                        })\n",
        "\n",
        "            if results:\n",
        "                st.success(f\"Found {len(results)} documents:\")\n",
        "                for result in results:\n",
        "                    similarity_percent = result['similarity_score'] * 100 if 'similarity_score' in result else 100\n",
        "                    with st.expander(f\"📄 {result['document']['filename']} (Relevance: {similarity_percent:.1f}%)\"):\n",
        "                        # Highlight search terms in preview\n",
        "                        preview_text = result['document']['text'][:800]\n",
        "                        if search_type == \"Keyword Search\":\n",
        "                            # Simple highlighting for keyword search\n",
        "                            highlighted = preview_text.replace(\n",
        "                                search_query, f\"**{search_query}**\"\n",
        "                            )\n",
        "                            st.markdown(highlighted)\n",
        "                        else:\n",
        "                            st.text(preview_text)\n",
        "\n",
        "                        if st.button(f\"View Full Document\", key=f\"view_{result['document']['filename']}\"):\n",
        "                            st.text_area(\"Full Content:\", result['document']['text'], height=400, key=f\"full_{result['document']['filename']}\")\n",
        "            else:\n",
        "                st.warning(\"No documents found.\")\n",
        "\n",
        "        # Statistics\n",
        "        st.subheader(\"📊 Knowledge Base Stats\")\n",
        "        col1, col2, col3 = st.columns(3)\n",
        "        with col1:\n",
        "            st.metric(\"Documents\", len(platform.response_data))\n",
        "        with col2:\n",
        "            total_words = sum(len(doc['text'].split()) for doc in platform.response_data)\n",
        "            st.metric(\"Total Words\", f\"{total_words:,}\")\n",
        "        with col3:\n",
        "            avg_length = total_words // len(platform.response_data) if platform.response_data else 0\n",
        "            st.metric(\"Avg Length\", f\"{avg_length:,} words\")\n",
        "\n",
        "        # Document list\n",
        "        st.subheader(\"📋 All Documents\")\n",
        "        for doc in platform.response_data:\n",
        "            with st.expander(f\"📄 {doc['filename']}\"):\n",
        "                word_count = len(doc['text'].split())\n",
        "                st.write(f\"**Word Count:** {word_count:,}\")\n",
        "                st.write(f\"**Date:** {doc['date_created'].strftime('%Y-%m-%d')}\")\n",
        "                st.text_area(\"Preview:\", doc['text'][:500] + \"...\", height=100, key=f\"docprev_{doc['filename']}\")\n",
        "\n",
        "    elif page == \"Analytics\":\n",
        "        st.header(\"📈 Analytics Dashboard\")\n",
        "\n",
        "        analysis = platform.analyze_win_loss_patterns()\n",
        "\n",
        "        col1, col2 = st.columns(2)\n",
        "\n",
        "        with col1:\n",
        "            st.subheader(\"🎯 Performance\")\n",
        "            try:\n",
        "                fig = go.Figure(go.Indicator(\n",
        "                    mode = \"gauge+number\",\n",
        "                    value = analysis['overall_win_rate'] * 100,\n",
        "                    title = {'text': \"Win Rate (%)\"},\n",
        "                    gauge = {\n",
        "                        'axis': {'range': [None, 100]},\n",
        "                        'bar': {'color': \"darkblue\"},\n",
        "                        'steps': [\n",
        "                            {'range': [0, 50], 'color': \"lightgray\"},\n",
        "                            {'range': [50, 100], 'color': \"green\"}\n",
        "                        ]\n",
        "                    }\n",
        "                ))\n",
        "                fig.update_layout(height=300)\n",
        "                st.plotly_chart(fig, use_container_width=True)\n",
        "            except:\n",
        "                st.metric(\"Win Rate\", f\"{analysis['overall_win_rate']*100:.1f}%\")\n",
        "\n",
        "            st.metric(\"Avg Proposal Time\", f\"{analysis['avg_proposal_time']} days\")\n",
        "\n",
        "        with col2:\n",
        "            st.subheader(\"🏛️ Win Rate by Agency\")\n",
        "            try:\n",
        "                agencies = list(analysis['win_rate_by_agency'].keys())\n",
        "                rates = [r * 100 for r in analysis['win_rate_by_agency'].values()]\n",
        "                fig = px.bar(x=agencies, y=rates, title=\"Win Rate by Agency (%)\")\n",
        "                st.plotly_chart(fig, use_container_width=True)\n",
        "            except:\n",
        "                agency_df = pd.DataFrame({\n",
        "                    'Agency': list(analysis['win_rate_by_agency'].keys()),\n",
        "                    'Win Rate': [f\"{r*100:.1f}%\" for r in analysis['win_rate_by_agency'].values()]\n",
        "                })\n",
        "                st.dataframe(agency_df)\n",
        "\n",
        "        # Success factors\n",
        "        col1, col2 = st.columns(2)\n",
        "        with col1:\n",
        "            st.subheader(\"✅ Success Factors\")\n",
        "            for factor in analysis['success_factors']:\n",
        "                st.write(f\"• {factor}\")\n",
        "        with col2:\n",
        "            st.subheader(\"🎯 Improvement Areas\")\n",
        "            for area in analysis['improvement_areas']:\n",
        "                st.write(f\"• {area}\")\n",
        "\n",
        "        # RFP trends\n",
        "        if platform.rfp_data:\n",
        "            st.subheader(\"📊 RFP Trends\")\n",
        "\n",
        "            # Agency distribution\n",
        "            agency_counts = {}\n",
        "            for rfp in platform.rfp_data:\n",
        "                agency = rfp['agency']\n",
        "                agency_counts[agency] = agency_counts.get(agency, 0) + 1\n",
        "\n",
        "            if agency_counts:\n",
        "                try:\n",
        "                    fig = px.pie(values=list(agency_counts.values()),\n",
        "                               names=list(agency_counts.keys()), title=\"RFPs by Agency\")\n",
        "                    st.plotly_chart(fig, use_container_width=True)\n",
        "                except:\n",
        "                    st.dataframe(pd.DataFrame({\n",
        "                        'Agency': list(agency_counts.keys()),\n",
        "                        'Count': list(agency_counts.values())\n",
        "                    }))\n",
        "\n",
        "            # Fit score distribution\n",
        "            if hasattr(platform, 'rfp_data') and platform.rfp_data:\n",
        "                fit_scores = []\n",
        "                for rfp in platform.rfp_data:\n",
        "                    score = platform.calculate_opportunity_fit(rfp)\n",
        "                    fit_scores.append(score)\n",
        "\n",
        "                try:\n",
        "                    fig = px.histogram(x=fit_scores, nbins=10, title=\"Distribution of Opportunity Fit Scores\")\n",
        "                    fig.update_xaxis(title=\"Fit Score (%)\")\n",
        "                    fig.update_yaxis(title=\"Number of RFPs\")\n",
        "                    st.plotly_chart(fig, use_container_width=True)\n",
        "                except:\n",
        "                    st.write(f\"Average Fit Score: {np.mean(fit_scores):.1f}%\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "'''\n",
        "\n",
        "# Write the app file\n",
        "with open('/content/rfp_app.py', 'w') as f:\n",
        "    f.write(app_content)\n",
        "\n",
        "print(\"✅ Main application file created at /content/rfp_app.py\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maW5xUxePHAe",
        "outputId": "d7bee6c7-7fb0-4680-e83f-876bda86ee6c"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Creating main application file...\n",
            "✅ Main application file created at /content/rfp_app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====  IMPORTS - ADD THESE AT THE TOP =====\n",
        "import os\n",
        "import json\n",
        "import threading\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "\n",
        "# ===== STEP 6: Setup Ngrok and Launch (FIXED) =====\n",
        "print(\"\\n🌐 Setting up public access...\")\n",
        "\n",
        "def run_streamlit():\n",
        "    subprocess.run([\n",
        "        \"streamlit\", \"run\", \"/content/rfp_app.py\",\n",
        "        \"--server.port\", \"8501\",\n",
        "        \"--server.address\", \"0.0.0.0\",\n",
        "        \"--server.headless\", \"true\",\n",
        "        \"--server.fileWatcherType\", \"none\"\n",
        "    ])\n",
        "\n",
        "# Start Streamlit\n",
        "print(\"🚀 Starting Streamlit...\")\n",
        "streamlit_thread = threading.Thread(target=run_streamlit, daemon=True)\n",
        "streamlit_thread.start()\n",
        "\n",
        "# Wait for startup\n",
        "# time.sleep(15)\n",
        "\n",
        "# Setup ngrok with authentication\n",
        "try:\n",
        "    from pyngrok import ngrok\n",
        "    from google.colab import userdata\n",
        "\n",
        "    GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "\n",
        "    # Get your ngrok authtoken from Colab secrets\n",
        "    try:\n",
        "        NGROK_API_KEY = userdata.get('NGROK_API_KEY')\n",
        "    except:\n",
        "        # Fallback - replace with your actual token\n",
        "        NGROK_API_KEY = \"YOUR_ACTUAL_NGROK_TOKEN_HERE\"  # Replace this!\n",
        "\n",
        "    if not NGROK_API_KEY or NGROK_API_KEY == \"YOUR_ACTUAL_NGROK_TOKEN_HERE\":\n",
        "        print(\"⚠️  Please add your ngrok token to Colab secrets or update the code\")\n",
        "        print(\"🔧 Running without ngrok...\")\n",
        "        print(\"📱 Streamlit is running on http://localhost:8501\")\n",
        "    else:\n",
        "        print(\"🔐 Authenticating with ngrok...\")\n",
        "        ngrok.set_auth_token(NGROK_API_KEY)\n",
        "\n",
        "        print(\"🌐 Creating public tunnel...\")\n",
        "        public_url = ngrok.connect(8501)\n",
        "\n",
        "        print(f\"\\n🎉 SUCCESS! Your RFP Platform is ready!\")\n",
        "        print(f\"🌐 Access your platform at: {public_url}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n⚠️  Ngrok issue: {e}\")\n",
        "    print(\"🔧 Try accessing via Colab's port forwarding instead\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ajGAl_31xcm",
        "outputId": "64c43ccf-9b1b-4741-ef85-370c4a42dc2b"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🌐 Setting up public access...\n",
            "🚀 Starting Streamlit...\n",
            "🔐 Authenticating with ngrok...\n",
            "🌐 Creating public tunnel...\n",
            "\n",
            "🎉 SUCCESS! Your RFP Platform is ready!\n",
            "🌐 Access your platform at: NgrokTunnel: \"https://b041-34-80-174-69.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== IMPROVED COLAB RFP APP LAUNCHER =====\n",
        "# Run this cell to launch your RFP Intelligence Platform in Google Colab\n",
        "\n",
        "import os\n",
        "import json\n",
        "import threading\n",
        "import subprocess\n",
        "import time\n",
        "import sys\n",
        "from IPython.display import display, HTML, clear_output\n",
        "import requests\n",
        "\n",
        "# ===== STEP 1: Enhanced Setup Function =====\n",
        "def setup_environment():\n",
        "    \"\"\"Setup the complete environment with better error handling\"\"\"\n",
        "    print(\"🔧 Setting up RFP Intelligence Platform...\")\n",
        "\n",
        "    # Install required packages\n",
        "    packages = [\n",
        "        \"streamlit>=1.28.0\",\n",
        "        \"sentence-transformers\",\n",
        "        \"faiss-cpu\",\n",
        "        \"PyPDF2\",\n",
        "        \"python-docx\",\n",
        "        \"plotly\",\n",
        "        \"google-generativeai\",\n",
        "        \"scikit-learn\"\n",
        "    ]\n",
        "\n",
        "    print(\"📦 Installing packages...\")\n",
        "    for package in packages:\n",
        "        try:\n",
        "            subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package],\n",
        "                         check=True, capture_output=True)\n",
        "            print(f\"✅ {package}\")\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(f\"❌ Failed to install {package}: {e}\")\n",
        "\n",
        "    # Try to install pyngrok (optional)\n",
        "    try:\n",
        "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"pyngrok\"],\n",
        "                     check=True, capture_output=True)\n",
        "        print(\"✅ pyngrok (for public access)\")\n",
        "    except:\n",
        "        print(\"⚠️ pyngrok not installed - will use Colab port forwarding\")\n",
        "\n",
        "    print(\"✅ Environment setup complete!\")\n",
        "\n",
        "# ===== STEP 2: Check API Keys =====\n",
        "def check_api_keys():\n",
        "    \"\"\"Check if required API keys are configured\"\"\"\n",
        "    print(\"\\n🔐 Checking API configuration...\")\n",
        "\n",
        "    try:\n",
        "        from google.colab import userdata\n",
        "\n",
        "        # Check Gemini API Key\n",
        "        try:\n",
        "            gemini_key = userdata.get('GEMINI_API_KEY')\n",
        "            if gemini_key:\n",
        "                print(\"✅ GEMINI_API_KEY found\")\n",
        "            else:\n",
        "                print(\"⚠️ GEMINI_API_KEY not found\")\n",
        "        except:\n",
        "            print(\"❌ GEMINI_API_KEY not configured\")\n",
        "\n",
        "        # Check Ngrok API Key (optional)\n",
        "        try:\n",
        "            ngrok_key = userdata.get('NGROK_API_KEY')\n",
        "            if ngrok_key:\n",
        "                print(\"✅ NGROK_API_KEY found (public access available)\")\n",
        "            else:\n",
        "                print(\"ℹ️ NGROK_API_KEY not found (will use Colab port forwarding)\")\n",
        "        except:\n",
        "            print(\"ℹ️ NGROK_API_KEY not configured (will use Colab port forwarding)\")\n",
        "\n",
        "    except ImportError:\n",
        "        print(\"❌ Cannot access Colab userdata\")\n",
        "\n",
        "# ===== STEP 3: Improved Streamlit Runner =====\n",
        "class StreamlitRunner:\n",
        "    def __init__(self):\n",
        "        self.process = None\n",
        "        self.port = 8501\n",
        "        self.is_running = False\n",
        "\n",
        "    def start(self):\n",
        "        \"\"\"Start Streamlit server with better error handling\"\"\"\n",
        "        print(f\"🚀 Starting Streamlit on port {self.port}...\")\n",
        "\n",
        "        try:\n",
        "            # Kill any existing processes on the port\n",
        "            subprocess.run([\n",
        "                \"lsof\", \"-ti\", f\":{self.port}\"\n",
        "            ], capture_output=True)\n",
        "\n",
        "            # Start Streamlit\n",
        "            self.process = subprocess.Popen([\n",
        "                \"streamlit\", \"run\", \"/content/rfp_app.py\",\n",
        "                \"--server.port\", str(self.port),\n",
        "                \"--server.address\", \"0.0.0.0\",\n",
        "                \"--server.headless\", \"true\",\n",
        "                \"--server.fileWatcherType\", \"none\",\n",
        "                \"--server.enableCORS\", \"false\",\n",
        "                \"--server.enableXsrfProtection\", \"false\"\n",
        "            ], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "\n",
        "            # Wait for startup\n",
        "            print(\"⏳ Waiting for Streamlit to start...\")\n",
        "            time.sleep(10)\n",
        "\n",
        "            # Check if server is responding\n",
        "            if self.is_server_ready():\n",
        "                self.is_running = True\n",
        "                print(\"✅ Streamlit server is running!\")\n",
        "                return True\n",
        "            else:\n",
        "                print(\"❌ Streamlit server failed to start properly\")\n",
        "                return False\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error starting Streamlit: {e}\")\n",
        "            return False\n",
        "\n",
        "    def is_server_ready(self):\n",
        "        \"\"\"Check if Streamlit server is ready\"\"\"\n",
        "        try:\n",
        "            response = requests.get(f\"http://localhost:{self.port}\", timeout=5)\n",
        "            return response.status_code == 200\n",
        "        except:\n",
        "            return False\n",
        "\n",
        "    def stop(self):\n",
        "        \"\"\"Stop the Streamlit server\"\"\"\n",
        "        if self.process:\n",
        "            self.process.terminate()\n",
        "            self.is_running = False\n",
        "            print(\"🛑 Streamlit server stopped\")\n",
        "\n",
        "# ===== STEP 4: Multiple Access Methods =====\n",
        "def setup_access_methods(port=8501):\n",
        "    \"\"\"Setup multiple ways to access the app\"\"\"\n",
        "    print(f\"\\n🌐 Setting up access methods...\")\n",
        "\n",
        "    access_methods = []\n",
        "\n",
        "    # Method 1: Colab Port Forwarding (Always available)\n",
        "    colab_url = f\"https://colab.research.google.com/drive/YOUR_NOTEBOOK_ID\"  # This gets auto-generated\n",
        "    access_methods.append({\n",
        "        'method': 'Colab Port Forwarding',\n",
        "        'url': f'Use Colab\\'s \"Open in new tab\" button for port {port}',\n",
        "        'status': 'Available',\n",
        "        'description': 'Click the port forwarding button in Colab'\n",
        "    })\n",
        "\n",
        "    # Method 2: Ngrok (If available)\n",
        "    try:\n",
        "        from pyngrok import ngrok\n",
        "        from google.colab import userdata\n",
        "\n",
        "        ngrok_token = userdata.get('NGROK_API_KEY')\n",
        "        if ngrok_token and ngrok_token != \"YOUR_ACTUAL_NGROK_TOKEN_HERE\":\n",
        "            print(\"🔐 Setting up ngrok tunnel...\")\n",
        "            ngrok.set_auth_token(ngrok_token)\n",
        "\n",
        "            # Kill any existing tunnels\n",
        "            ngrok.kill()\n",
        "\n",
        "            # Create new tunnel\n",
        "            public_url = ngrok.connect(port)\n",
        "            access_methods.append({\n",
        "                'method': 'Ngrok Public URL',\n",
        "                'url': str(public_url),\n",
        "                'status': 'Active',\n",
        "                'description': 'Accessible from anywhere'\n",
        "            })\n",
        "            print(f\"✅ Public URL: {public_url}\")\n",
        "\n",
        "        else:\n",
        "            access_methods.append({\n",
        "                'method': 'Ngrok Public URL',\n",
        "                'url': 'Not configured',\n",
        "                'status': 'Needs Setup',\n",
        "                'description': 'Add NGROK_API_KEY to Colab secrets'\n",
        "            })\n",
        "\n",
        "    except Exception as e:\n",
        "        access_methods.append({\n",
        "            'method': 'Ngrok Public URL',\n",
        "            'url': 'Error',\n",
        "            'status': f'Failed: {e}',\n",
        "            'description': 'Ngrok setup failed'\n",
        "        })\n",
        "\n",
        "    # Method 3: Direct localhost (for debugging)\n",
        "    access_methods.append({\n",
        "        'method': 'Direct Localhost',\n",
        "        'url': f'http://localhost:{port}',\n",
        "        'status': 'Available',\n",
        "        'description': 'Only works within Colab environment'\n",
        "    })\n",
        "\n",
        "    return access_methods\n",
        "\n",
        "# ===== STEP 5: Status Dashboard =====\n",
        "def display_status_dashboard(streamlit_runner, access_methods):\n",
        "    \"\"\"Display a nice status dashboard\"\"\"\n",
        "    clear_output(wait=True)\n",
        "\n",
        "    dashboard_html = f\"\"\"\n",
        "    <div style=\"border: 2px solid #4CAF50; border-radius: 10px; padding: 20px; margin: 10px 0; background: #f9f9f9;\">\n",
        "        <h2 style=\"color: #4CAF50; margin: 0 0 15px 0;\">🚀 RFP Intelligence Platform Status</h2>\n",
        "\n",
        "        <div style=\"margin-bottom: 15px;\">\n",
        "            <strong>Streamlit Server:</strong>\n",
        "            <span style=\"color: {'green' if streamlit_runner.is_running else 'red'};\">\n",
        "                {'🟢 Running' if streamlit_runner.is_running else '🔴 Stopped'}\n",
        "            </span>\n",
        "        </div>\n",
        "\n",
        "        <div style=\"margin-bottom: 15px;\">\n",
        "            <strong>Port:</strong> {streamlit_runner.port}\n",
        "        </div>\n",
        "\n",
        "        <h3 style=\"color: #2196F3; margin: 20px 0 10px 0;\">📡 Access Methods:</h3>\n",
        "        <table style=\"width: 100%; border-collapse: collapse;\">\n",
        "            <tr style=\"background-color: #e3f2fd;\">\n",
        "                <th style=\"border: 1px solid #ddd; padding: 8px; text-align: left;\">Method</th>\n",
        "                <th style=\"border: 1px solid #ddd; padding: 8px; text-align: left;\">URL</th>\n",
        "                <th style=\"border: 1px solid #ddd; padding: 8px; text-align: left;\">Status</th>\n",
        "            </tr>\n",
        "    \"\"\"\n",
        "\n",
        "    for method in access_methods:\n",
        "        status_color = {\n",
        "            'Available': 'green',\n",
        "            'Active': 'green',\n",
        "            'Needs Setup': 'orange',\n",
        "            'Error': 'red'\n",
        "        }.get(method['status'].split(':')[0], 'black')\n",
        "\n",
        "        dashboard_html += f\"\"\"\n",
        "            <tr>\n",
        "                <td style=\"border: 1px solid #ddd; padding: 8px;\"><strong>{method['method']}</strong><br>\n",
        "                    <small style=\"color: #666;\">{method['description']}</small></td>\n",
        "                <td style=\"border: 1px solid #ddd; padding: 8px; font-family: monospace;\">\n",
        "                    {'<a href=\"' + method['url'] + '\" target=\"_blank\">' + method['url'] + '</a>' if method['url'].startswith('http') else method['url']}\n",
        "                </td>\n",
        "                <td style=\"border: 1px solid #ddd; padding: 8px; color: {status_color};\">\n",
        "                    <strong>{method['status']}</strong>\n",
        "                </td>\n",
        "            </tr>\n",
        "        \"\"\"\n",
        "\n",
        "    dashboard_html += \"\"\"\n",
        "        </table>\n",
        "\n",
        "        <div style=\"margin-top: 20px; padding: 15px; background-color: #e8f5e8; border-radius: 5px;\">\n",
        "            <h4 style=\"margin: 0 0 10px 0; color: #2e7d32;\">💡 Quick Access Tips:</h4>\n",
        "            <ul style=\"margin: 0; padding-left: 20px;\">\n",
        "                <li><strong>Colab Port Forwarding:</strong> Look for the \"port forwarding\" icon in the Colab toolbar and click it</li>\n",
        "                <li><strong>Public URL:</strong> Share the ngrok URL with team members for external access</li>\n",
        "                <li><strong>Refresh:</strong> If the app doesn't load, wait 30 seconds and refresh</li>\n",
        "            </ul>\n",
        "        </div>\n",
        "\n",
        "        <div style=\"margin-top: 15px; text-align: center;\">\n",
        "            <button onclick=\"window.open('http://localhost:8501', '_blank')\"\n",
        "                    style=\"background-color: #4CAF50; color: white; padding: 10px 20px; border: none; border-radius: 5px; cursor: pointer; font-size: 16px;\">\n",
        "                🚀 Open App in New Tab\n",
        "            </button>\n",
        "        </div>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "\n",
        "    display(HTML(dashboard_html))\n",
        "\n",
        "# ===== STEP 6: Main Launcher Function =====\n",
        "def launch_rfp_platform():\n",
        "    \"\"\"Main function to launch the RFP platform\"\"\"\n",
        "    print(\"🎯 Launching RFP Intelligence Platform...\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Setup environment\n",
        "    setup_environment()\n",
        "\n",
        "    # Check API keys\n",
        "    check_api_keys()\n",
        "\n",
        "    # Check if app file exists\n",
        "    if not os.path.exists('/content/rfp_app.py'):\n",
        "        print(\"❌ RFP app file not found at /content/rfp_app.py\")\n",
        "        print(\"Please make sure you've created the main app file first!\")\n",
        "        return\n",
        "\n",
        "    # Start Streamlit\n",
        "    runner = StreamlitRunner()\n",
        "    if not runner.start():\n",
        "        print(\"❌ Failed to start Streamlit server\")\n",
        "        return\n",
        "\n",
        "    # Setup access methods\n",
        "    access_methods = setup_access_methods(runner.port)\n",
        "\n",
        "    # Display dashboard\n",
        "    display_status_dashboard(runner, access_methods)\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"🎉 RFP Platform is ready!\")\n",
        "    print(\"Use the access methods above to open your app\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    return runner\n",
        "\n",
        "# # ===== STEP 7: Quick Setup Commands =====\n",
        "# def quick_setup_secrets():\n",
        "#     \"\"\"Display instructions for setting up secrets\"\"\"\n",
        "#     instructions_html = \"\"\"\n",
        "#     <div style=\"border: 2px solid #FF9800; border-radius: 10px; padding: 20px; margin: 10px 0; background: #fff3e0;\">\n",
        "#         <h3 style=\"color: #F57C00; margin: 0 0 15px 0;\">🔑 API Keys Setup</h3>\n",
        "\n",
        "#         <p><strong>To enable all features, add these to your Colab secrets:</strong></p>\n",
        "\n",
        "#         <ol>\n",
        "#             <li>Click the <strong>🔑 key icon</strong> in the left sidebar of Colab</li>\n",
        "#             <li>Add these secrets:</li>\n",
        "#         </ol>\n",
        "\n",
        "#         <table style=\"width: 100%; border-collapse: collapse; margin: 15px 0;\">\n",
        "#             <tr style=\"background-color: #f5f5f5;\">\n",
        "#                 <th style=\"border: 1px solid #ddd; padding: 10px; text-align: left;\">Secret Name</th>\n",
        "#                 <th style=\"border: 1px solid #ddd; padding: 10px; text-align: left;\">Description</th>\n",
        "#                 <th style=\"border: 1px solid #ddd; padding: 10px; text-align: left;\">Required?</th>\n",
        "#             </tr>\n",
        "#             <tr>\n",
        "#                 <td style=\"border: 1px solid #ddd; padding: 10px; font-family: monospace;\">GEMINI_API_KEY</td>\n",
        "#                 <td style=\"border: 1px solid #ddd; padding: 10px;\">Google Gemini API key for AI features</td>\n",
        "#                 <td style=\"border: 1px solid #ddd; padding: 10px; color: red;\"><strong>Required</strong></td>\n",
        "#             </tr>\n",
        "#             <tr>\n",
        "#                 <td style=\"border: 1px solid #ddd; padding: 10px; font-family: monospace;\">NGROK_API_KEY</td>\n",
        "#                 <td style=\"border: 1px solid #ddd; padding: 10px;\">Ngrok token for public URL access</td>\n",
        "#                 <td style=\"border: 1px solid #ddd; padding: 10px; color: orange;\">Optional</td>\n",
        "#             </tr>\n",
        "#         </table>\n",
        "\n",
        "#         <div style=\"background-color: #e3f2fd; padding: 15px; border-radius: 5px; margin: 15px 0;\">\n",
        "#             <h4 style=\"margin: 0 0 10px 0; color: #1976d2;\">🔗 Getting API Keys:</h4>\n",
        "#             <ul style=\"margin: 0; padding-left: 20px;\">\n",
        "#                 <li><strong>Gemini API:</strong> Visit <a href=\"https://aistudio.google.com/app/apikey\" target=\"_blank\">Google AI Studio</a></li>\n",
        "#                 <li><strong>Ngrok:</strong> Sign up at <a href=\"https://ngrok.com/\" target=\"_blank\">ngrok.com</a> and get your authtoken</li>\n",
        "#             </ul>\n",
        "#         </div>\n",
        "#     </div>\n",
        "#     \"\"\"\n",
        "\n",
        "#     display(HTML(instructions_html))\n",
        "\n",
        "# ===== STEP 8: Control Functions =====\n",
        "def stop_platform():\n",
        "    \"\"\"Stop the running platform\"\"\"\n",
        "    try:\n",
        "        # Kill streamlit processes\n",
        "        subprocess.run([\"pkill\", \"-f\", \"streamlit\"], capture_output=True)\n",
        "\n",
        "        # Kill ngrok\n",
        "        try:\n",
        "            from pyngrok import ngrok\n",
        "            ngrok.kill()\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        print(\"🛑 Platform stopped successfully\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Error stopping platform: {e}\")\n",
        "\n",
        "def restart_platform():\n",
        "    \"\"\"Restart the platform\"\"\"\n",
        "    print(\"🔄 Restarting platform...\")\n",
        "    stop_platform()\n",
        "    time.sleep(3)\n",
        "    return launch_rfp_platform()\n",
        "\n",
        "# ===== STEP 9: Easy Launch Commands =====\n",
        "print(\"🚀 RFP Platform Launcher Loaded!\")\n",
        "print(\"=\" * 40)\n",
        "print(\"Available commands:\")\n",
        "print(\"• launch_rfp_platform()     - Start the app\")\n",
        "# print(\"• quick_setup_secrets()     - Setup instructions\")\n",
        "print(\"• stop_platform()           - Stop the app\")\n",
        "print(\"• restart_platform()        - Restart the app\")\n",
        "print(\"=\" * 40)\n",
        "print(\"💡 Run: launch_rfp_platform() to get started!\")\n",
        "\n",
        "# Auto-display setup instructions\n",
        "# quick_setup_secrets()\n",
        "launch_rfp_platform()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 703
        },
        "id": "pSKWWXsBakQH",
        "outputId": "ad591127-f30e-4fdb-c800-8b8f2f40e8ba"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"border: 2px solid #4CAF50; border-radius: 10px; padding: 20px; margin: 10px 0; background: #f9f9f9;\">\n",
              "        <h2 style=\"color: #4CAF50; margin: 0 0 15px 0;\">🚀 RFP Intelligence Platform Status</h2>\n",
              "        \n",
              "        <div style=\"margin-bottom: 15px;\">\n",
              "            <strong>Streamlit Server:</strong> \n",
              "            <span style=\"color: green;\">\n",
              "                🟢 Running\n",
              "            </span>\n",
              "        </div>\n",
              "        \n",
              "        <div style=\"margin-bottom: 15px;\">\n",
              "            <strong>Port:</strong> 8501\n",
              "        </div>\n",
              "        \n",
              "        <h3 style=\"color: #2196F3; margin: 20px 0 10px 0;\">📡 Access Methods:</h3>\n",
              "        <table style=\"width: 100%; border-collapse: collapse;\">\n",
              "            <tr style=\"background-color: #e3f2fd;\">\n",
              "                <th style=\"border: 1px solid #ddd; padding: 8px; text-align: left;\">Method</th>\n",
              "                <th style=\"border: 1px solid #ddd; padding: 8px; text-align: left;\">URL</th>\n",
              "                <th style=\"border: 1px solid #ddd; padding: 8px; text-align: left;\">Status</th>\n",
              "            </tr>\n",
              "    \n",
              "            <tr>\n",
              "                <td style=\"border: 1px solid #ddd; padding: 8px;\"><strong>Colab Port Forwarding</strong><br>\n",
              "                    <small style=\"color: #666;\">Click the port forwarding button in Colab</small></td>\n",
              "                <td style=\"border: 1px solid #ddd; padding: 8px; font-family: monospace;\">\n",
              "                    Use Colab's \"Open in new tab\" button for port 8501\n",
              "                </td>\n",
              "                <td style=\"border: 1px solid #ddd; padding: 8px; color: green;\">\n",
              "                    <strong>Available</strong>\n",
              "                </td>\n",
              "            </tr>\n",
              "        \n",
              "            <tr>\n",
              "                <td style=\"border: 1px solid #ddd; padding: 8px;\"><strong>Ngrok Public URL</strong><br>\n",
              "                    <small style=\"color: #666;\">Accessible from anywhere</small></td>\n",
              "                <td style=\"border: 1px solid #ddd; padding: 8px; font-family: monospace;\">\n",
              "                    NgrokTunnel: \"https://7f84-34-80-174-69.ngrok-free.app\" -> \"http://localhost:8501\"\n",
              "                </td>\n",
              "                <td style=\"border: 1px solid #ddd; padding: 8px; color: green;\">\n",
              "                    <strong>Active</strong>\n",
              "                </td>\n",
              "            </tr>\n",
              "        \n",
              "            <tr>\n",
              "                <td style=\"border: 1px solid #ddd; padding: 8px;\"><strong>Direct Localhost</strong><br>\n",
              "                    <small style=\"color: #666;\">Only works within Colab environment</small></td>\n",
              "                <td style=\"border: 1px solid #ddd; padding: 8px; font-family: monospace;\">\n",
              "                    <a href=\"http://localhost:8501\" target=\"_blank\">http://localhost:8501</a>\n",
              "                </td>\n",
              "                <td style=\"border: 1px solid #ddd; padding: 8px; color: green;\">\n",
              "                    <strong>Available</strong>\n",
              "                </td>\n",
              "            </tr>\n",
              "        \n",
              "        </table>\n",
              "        \n",
              "        <div style=\"margin-top: 20px; padding: 15px; background-color: #e8f5e8; border-radius: 5px;\">\n",
              "            <h4 style=\"margin: 0 0 10px 0; color: #2e7d32;\">💡 Quick Access Tips:</h4>\n",
              "            <ul style=\"margin: 0; padding-left: 20px;\">\n",
              "                <li><strong>Colab Port Forwarding:</strong> Look for the \"port forwarding\" icon in the Colab toolbar and click it</li>\n",
              "                <li><strong>Public URL:</strong> Share the ngrok URL with team members for external access</li>\n",
              "                <li><strong>Refresh:</strong> If the app doesn't load, wait 30 seconds and refresh</li>\n",
              "            </ul>\n",
              "        </div>\n",
              "        \n",
              "        <div style=\"margin-top: 15px; text-align: center;\">\n",
              "            <button onclick=\"window.open('http://localhost:8501', '_blank')\" \n",
              "                    style=\"background-color: #4CAF50; color: white; padding: 10px 20px; border: none; border-radius: 5px; cursor: pointer; font-size: 16px;\">\n",
              "                🚀 Open App in New Tab\n",
              "            </button>\n",
              "        </div>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "🎉 RFP Platform is ready!\n",
            "Use the access methods above to open your app\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.StreamlitRunner at 0x78109f5b0950>"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run /content/rfp_app.py --server.port 8502"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qnoZ8DfbkL9",
        "outputId": "a6a54157-0cee-4756-818e-988cce2f2e78"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8502\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8502\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.80.174.69:8502\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install -g localtunnel\n",
        "!wget -q -O - https://loca.lt/mytunnelpassword\n",
        "!lt --port 8503"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAB7zygwdY6r",
        "outputId": "71ce0ddc-3c93-4633-d80f-738f970c2950"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K\n",
            "changed 22 packages in 818ms\n",
            "\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K34.80.174.69your url is: https://green-boats-lay.loca.lt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhjDpAondpxB",
        "outputId": "3cf56362-d2d2-4886-d90a-acd245bd372a"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.80.174.69"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4o8Pivkje44X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}